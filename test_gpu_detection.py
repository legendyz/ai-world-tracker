"""æµ‹è¯• GPU è‡ªåŠ¨æ£€æµ‹ä¸è‡ªé€‚åº”é…ç½®"""
from llm_classifier import detect_gpu, LLMClassifier, OllamaOptions
import time

print("=" * 60)
print("ğŸ” GPU æ£€æµ‹ä¸è‡ªé€‚åº”é…ç½®æµ‹è¯•")
print("=" * 60)

# 1. ç‹¬ç«‹æµ‹è¯•GPUæ£€æµ‹
print("\nğŸ“Š GPU æ£€æµ‹ç»“æœ:")
gpu_info = detect_gpu()
print(f"   GPUå¯ç”¨: {gpu_info.available}")
print(f"   GPUç±»å‹: {gpu_info.gpu_type}")
print(f"   GPUåç§°: {gpu_info.gpu_name}")
print(f"   æ˜¾å­˜: {gpu_info.vram_mb} MB")
print(f"   é©±åŠ¨ç‰ˆæœ¬: {gpu_info.driver_version}")
print(f"   CUDAæ”¯æŒ: {gpu_info.cuda_available}")
print(f"   ROCmæ”¯æŒ: {gpu_info.rocm_available}")
print(f"   Metalæ”¯æŒ: {gpu_info.metal_available}")
print(f"   Ollama GPUæ”¯æŒ: {gpu_info.ollama_gpu_supported}")

# 2. æµ‹è¯•è‡ªé€‚åº”é…ç½®
print("\nâš™ï¸ è‡ªé€‚åº”é…ç½®:")
options = OllamaOptions.auto_configure(gpu_info)
print(f"   num_gpu: {options.num_gpu}")
print(f"   num_ctx: {options.num_ctx}")
print(f"   num_predict: {options.num_predict}")
print(f"   num_thread: {options.num_thread}")
print(f"   temperature: {options.temperature}")

# 3. æµ‹è¯• LLM åˆ†ç±»å™¨åˆå§‹åŒ–
print("\n" + "=" * 60)
print("ğŸ¤– åˆå§‹åŒ– LLM åˆ†ç±»å™¨ (è‡ªåŠ¨æ£€æµ‹GPU)")
print("=" * 60)

classifier = LLMClassifier(
    provider='ollama',
    model='qwen3:8b',
    enable_cache=True,
    auto_detect_gpu=True
)

# 4. æµ‹è¯•åˆ†ç±»
print("\n" + "=" * 60)
print("ğŸ“ æµ‹è¯•åˆ†ç±»")
print("=" * 60)

test_item = {
    'title': 'OpenAI releases GPT-5 with breakthrough capabilities',
    'summary': 'OpenAI announces GPT-5 featuring advanced reasoning and multimodal understanding',
    'source': 'TechCrunch'
}

start = time.time()
result = classifier.classify_item(test_item)
elapsed = time.time() - start

print(f"\n   ç±»åˆ«: {result.get('content_type')}")
print(f"   ç½®ä¿¡åº¦: {result.get('confidence', 0):.0%}")
print(f"   è€—æ—¶: {elapsed:.1f}s")
print(f"   åˆ†ç±»å™¨: {result.get('classified_by')}")

# 5. æ˜¾ç¤ºæœ€ç»ˆé…ç½®ä¿¡æ¯
print("\n" + "=" * 60)
print("ğŸ“‹ é…ç½®æ€»ç»“")
print("=" * 60)
if classifier.gpu_info:
    if classifier.gpu_info.ollama_gpu_supported:
        print("   âœ… GPUåŠ é€Ÿå·²å¯ç”¨")
        print(f"   ğŸš€ ä½¿ç”¨ {classifier.gpu_info.gpu_name}")
    else:
        print("   ğŸ’» CPUæ¨¡å¼è¿è¡Œ")
        print(f"   â„¹ï¸  GPU ({classifier.gpu_info.gpu_name}) ä¸å— Ollama æ”¯æŒ")
        print(f"   ä¼˜åŒ–: å¤šçº¿ç¨‹={classifier.ollama_options.num_thread}, ä¸Šä¸‹æ–‡={classifier.ollama_options.num_ctx}")

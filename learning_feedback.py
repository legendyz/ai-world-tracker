"""
å­¦ä¹ åé¦ˆç³»ç»Ÿ - Learning Feedback System
ä»äººå·¥å®¡æ ¸ç»“æœä¸­å­¦ä¹ ï¼Œä¼˜åŒ–åˆ†ç±»æ¨¡å‹

åŠŸèƒ½:
1. åˆ†æäººå·¥å®¡æ ¸æ¨¡å¼
2. æå–å…³é”®ç‰¹å¾
3. åŠ¨æ€è°ƒæ•´åˆ†ç±»æƒé‡
4. ç”Ÿæˆæ”¹è¿›å»ºè®®
"""

import json
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from collections import Counter, defaultdict
import re


class LearningFeedback:
    """å­¦ä¹ åé¦ˆç³»ç»Ÿ"""
    
    def __init__(self):
        self.review_patterns = defaultdict(list)
        self.correction_stats = {
            'total_corrections': 0,
            'by_original_category': defaultdict(int),
            'by_new_category': defaultdict(int),
            'category_transitions': defaultdict(int)
        }
        self.keyword_adjustments = defaultdict(float)
        self.improvement_suggestions = []
    
    def analyze_review_history(self, review_history: List[Dict]) -> Dict:
        """
        åˆ†æå®¡æ ¸å†å²ï¼Œæå–å­¦ä¹ æ¨¡å¼
        
        Args:
            review_history: å®¡æ ¸å†å²è®°å½•åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        print("\nğŸ“Š æ­£åœ¨åˆ†æå®¡æ ¸å†å²...")
        
        for record in review_history:
            action = record.get('action', '')
            
            # æå–åˆ†ç±»å˜æ›´
            if 'ä¿®æ”¹åˆ†ç±»:' in action or 'â†’' in action:
                self._extract_category_change(record)
            
            # ç»Ÿè®¡å…¶ä»–æ“ä½œ
            if 'æ ‡è®°ä¸ºåƒåœ¾' in action:
                self.correction_stats['spam_count'] = \
                    self.correction_stats.get('spam_count', 0) + 1
            elif 'ä¿æŒåˆ†ç±»' in action:
                self.correction_stats['confirmed_count'] = \
                    self.correction_stats.get('confirmed_count', 0) + 1
        
        return self._generate_analysis_report()
    
    def _extract_category_change(self, record: Dict):
        """æå–åˆ†ç±»å˜æ›´ä¿¡æ¯"""
        action = record.get('action', '')
        title = record.get('title', '')
        
        # è§£æ "ä¿®æ”¹åˆ†ç±»: old â†’ new" æ ¼å¼
        if 'â†’' in action:
            parts = action.split('â†’')
            if len(parts) == 2:
                old_cat = parts[0].split(':')[-1].strip()
                new_cat = parts[1].strip()
                
                self.correction_stats['total_corrections'] += 1
                self.correction_stats['by_original_category'][old_cat] += 1
                self.correction_stats['by_new_category'][new_cat] += 1
                
                transition = f"{old_cat} â†’ {new_cat}"
                self.correction_stats['category_transitions'][transition] += 1
                
                # è®°å½•æ ‡é¢˜æ¨¡å¼
                self.review_patterns[transition].append(title)
    
    def _generate_analysis_report(self) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        return {
            'total_reviews': self.correction_stats.get('total_corrections', 0) + \
                           self.correction_stats.get('confirmed_count', 0) + \
                           self.correction_stats.get('spam_count', 0),
            'corrections': self.correction_stats['total_corrections'],
            'confirmations': self.correction_stats.get('confirmed_count', 0),
            'spam_removed': self.correction_stats.get('spam_count', 0),
            'most_corrected_from': self._get_top_items(self.correction_stats['by_original_category']),
            'most_corrected_to': self._get_top_items(self.correction_stats['by_new_category']),
            'common_transitions': self._get_top_items(self.correction_stats['category_transitions'])
        }
    
    def _get_top_items(self, counter_dict: Dict, top_n: int = 3) -> List[Tuple[str, int]]:
        """è·å–å‰Nä¸ªæœ€å¸¸è§çš„é¡¹"""
        return sorted(counter_dict.items(), key=lambda x: x[1], reverse=True)[:top_n]
    
    def extract_keyword_patterns(self, reviewed_items: List[Dict]) -> Dict[str, List[str]]:
        """
        ä»å®¡æ ¸åçš„æ•°æ®ä¸­æå–å…³é”®è¯æ¨¡å¼
        
        Args:
            reviewed_items: å®¡æ ¸åçš„å†…å®¹åˆ—è¡¨
            
        Returns:
            å„åˆ†ç±»çš„ç‰¹å¾å…³é”®è¯
        """
        print("\nğŸ” æ­£åœ¨æå–å…³é”®è¯æ¨¡å¼...")
        
        category_keywords = defaultdict(lambda: defaultdict(int))
        
        for item in reviewed_items:
            if not item.get('manually_reviewed'):
                continue
            
            category = item.get('content_type')
            text = f"{item.get('title', '')} {item.get('summary', '')}".lower()
            
            # æå–å…³é”®è¯ï¼ˆç®€å•çš„è¯é¢‘ç»Ÿè®¡ï¼‰
            words = re.findall(r'\b\w{3,}\b', text)  # è‡³å°‘3ä¸ªå­—ç¬¦çš„å•è¯
            
            for word in words:
                if word not in ['the', 'and', 'for', 'with', 'from', 'that', 'this']:
                    category_keywords[category][word] += 1
        
        # ä¸ºæ¯ä¸ªåˆ†ç±»æ‰¾å‡ºæœ€å…·ä»£è¡¨æ€§çš„å…³é”®è¯
        representative_keywords = {}
        for category, words in category_keywords.items():
            # é€‰æ‹©é¢‘ç‡æœ€é«˜çš„å‰10ä¸ªè¯
            top_words = sorted(words.items(), key=lambda x: x[1], reverse=True)[:10]
            representative_keywords[category] = [word for word, count in top_words]
        
        return representative_keywords
    
    def generate_weight_adjustments(self, analysis: Dict) -> Dict[str, Dict[str, float]]:
        """
        æ ¹æ®åˆ†æç»“æœç”Ÿæˆæƒé‡è°ƒæ•´å»ºè®®
        
        Args:
            analysis: åˆ†ææŠ¥å‘Š
            
        Returns:
            æƒé‡è°ƒæ•´å»ºè®®
        """
        print("\nâš™ï¸ ç”Ÿæˆæƒé‡è°ƒæ•´å»ºè®®...")
        
        adjustments = {
            'category_thresholds': {},
            'keyword_boosts': {},
            'confidence_adjustments': {}
        }
        
        # åˆ†æå¸¸è§é”™è¯¯è½¬æ¢
        common_transitions = analysis.get('common_transitions', [])
        
        for transition, count in common_transitions:
            if ' â†’ ' in transition:
                old_cat, new_cat = transition.split(' â†’ ')
                
                # å¦‚æœæŸä¸ªåˆ†ç±»ç»å¸¸è¢«æ”¹ä¸ºå¦ä¸€ä¸ªï¼Œè¯´æ˜åˆ†ç±»é˜ˆå€¼å¯èƒ½éœ€è¦è°ƒæ•´
                if count >= 3:
                    adjustments['category_thresholds'][old_cat] = {
                        'issue': f'ç»å¸¸è¢«ä¿®æ”¹ä¸º {new_cat}',
                        'suggestion': 'è€ƒè™‘é™ä½è¯¥åˆ†ç±»çš„æƒé‡æˆ–æé«˜é˜ˆå€¼',
                        'frequency': count
                    }
        
        # åˆ†ææœ€å¸¸è¢«çº æ­£çš„åˆ†ç±»
        most_corrected = analysis.get('most_corrected_from', [])
        for category, count in most_corrected:
            if count >= 5:
                adjustments['confidence_adjustments'][category] = {
                    'issue': f'è¯¥åˆ†ç±»æœ‰ {count} æ¬¡è¢«ä¿®æ­£',
                    'suggestion': 'è¯¥åˆ†ç±»å¯èƒ½éœ€è¦æ›´ä¸¥æ ¼çš„åˆ¤å®šæ¡ä»¶',
                    'recommended_action': 'å¢åŠ å…³é”®è¯æƒé‡æˆ–æ·»åŠ æ›´å¤šç‰¹å¾'
                }
        
        return adjustments
    
    def apply_learning(self, classifier, reviewed_items: List[Dict], 
                      auto_apply: bool = False) -> Dict:
        """
        å°†å­¦ä¹ æˆæœåº”ç”¨åˆ°åˆ†ç±»å™¨
        
        Args:
            classifier: ContentClassifierå®ä¾‹
            reviewed_items: å®¡æ ¸åçš„æ•°æ®
            auto_apply: æ˜¯å¦è‡ªåŠ¨åº”ç”¨ï¼ˆå¦åˆ™åªç”Ÿæˆå»ºè®®ï¼‰
            
        Returns:
            åº”ç”¨ç»“æœæŠ¥å‘Š
        """
        print("\nğŸ“ æ­£åœ¨åº”ç”¨å­¦ä¹ æˆæœ...")
        
        # æå–å…³é”®è¯æ¨¡å¼
        patterns = self.extract_keyword_patterns(reviewed_items)
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        suggestions = []
        
        for category, keywords in patterns.items():
            # æ‰¾å‡ºå½“å‰åˆ†ç±»å™¨ä¸­æ²¡æœ‰çš„é«˜é¢‘å…³é”®è¯
            current_keywords = self._get_classifier_keywords(classifier, category)
            new_keywords = [kw for kw in keywords if kw not in current_keywords]
            
            if new_keywords:
                suggestions.append({
                    'category': category,
                    'type': 'add_keywords',
                    'keywords': new_keywords[:5],  # å»ºè®®æ·»åŠ å‰5ä¸ª
                    'reason': f'åœ¨äººå·¥å®¡æ ¸çš„ {category} ç±»å†…å®¹ä¸­é«˜é¢‘å‡ºç°'
                })
        
        # åˆ†æé”™è¯¯æ¨¡å¼
        error_patterns = self._analyze_error_patterns(reviewed_items)
        suggestions.extend(error_patterns)
        
        self.improvement_suggestions = suggestions
        
        if auto_apply:
            print("âš ï¸  è‡ªåŠ¨åº”ç”¨åŠŸèƒ½éœ€è¦é‡å¯ç¨‹åºæ‰èƒ½ç”Ÿæ•ˆ")
            print("å½“å‰ç‰ˆæœ¬å°†å»ºè®®ä¿å­˜åˆ°æ–‡ä»¶ä¸­ï¼Œä¾›æ‰‹åŠ¨å®¡æŸ¥")
        
        return {
            'suggestions_count': len(suggestions),
            'suggestions': suggestions,
            'patterns': patterns
        }
    
    def _get_classifier_keywords(self, classifier, category: str) -> set:
        """è·å–åˆ†ç±»å™¨å½“å‰ä½¿ç”¨çš„å…³é”®è¯"""
        keyword_map = {
            'research': classifier.research_keywords,
            'developer': classifier.developer_keywords,
            'product': classifier.product_keywords,
            'market': classifier.market_keywords,
            'leader': classifier.leader_keywords
        }
        
        keywords_dict = keyword_map.get(category, {})
        return set(keywords_dict.keys()) if isinstance(keywords_dict, dict) else set(keywords_dict)
    
    def _analyze_error_patterns(self, reviewed_items: List[Dict]) -> List[Dict]:
        """åˆ†æå¸¸è§é”™è¯¯æ¨¡å¼"""
        patterns = []
        
        # ç»Ÿè®¡ä½ç½®ä¿¡åº¦ä½†è¢«ç¡®è®¤çš„æƒ…å†µ
        low_conf_confirmed = [
            item for item in reviewed_items
            if item.get('manually_reviewed') and 
               item.get('confidence', 1.0) < 0.6 and
               not ('ä¿®æ”¹åˆ†ç±»' in str(item.get('reviewed_action', '')))
        ]
        
        if len(low_conf_confirmed) >= 3:
            patterns.append({
                'type': 'threshold_adjustment',
                'issue': f'{len(low_conf_confirmed)} æ¡ä½ç½®ä¿¡åº¦å†…å®¹è¢«ç¡®è®¤ä¸ºæ­£ç¡®åˆ†ç±»',
                'suggestion': 'è€ƒè™‘é™ä½ç½®ä¿¡åº¦é˜ˆå€¼è¦æ±‚æˆ–è°ƒæ•´å…³é”®è¯æƒé‡',
                'affected_items': len(low_conf_confirmed)
            })
        
        # ç»Ÿè®¡é«˜ç½®ä¿¡åº¦ä½†è¢«ä¿®æ”¹çš„æƒ…å†µ
        high_conf_corrected = [
            item for item in reviewed_items
            if item.get('manually_reviewed') and 
               item.get('original_confidence', 1.0) > 0.7 and
               'ä¿®æ”¹åˆ†ç±»' in str(item.get('reviewed_action', ''))
        ]
        
        if len(high_conf_corrected) >= 2:
            patterns.append({
                'type': 'false_positive',
                'issue': f'{len(high_conf_corrected)} æ¡é«˜ç½®ä¿¡åº¦å†…å®¹è¢«ä¿®æ­£',
                'suggestion': 'å­˜åœ¨ç³»ç»Ÿæ€§è¯¯åˆ¤ï¼Œéœ€è¦æ£€æŸ¥åˆ†ç±»è§„åˆ™',
                'severity': 'high',
                'affected_items': len(high_conf_corrected)
            })
        
        return patterns
    
    def save_learning_report(self, filename: str = None):
        """ä¿å­˜å­¦ä¹ æŠ¥å‘Š"""
        if not filename:
            filename = f"learning_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'correction_stats': dict(self.correction_stats),
            'improvement_suggestions': self.improvement_suggestions,
            'summary': {
                'total_suggestions': len(self.improvement_suggestions),
                'high_priority': len([s for s in self.improvement_suggestions 
                                     if s.get('severity') == 'high']),
                'keyword_additions': len([s for s in self.improvement_suggestions 
                                         if s.get('type') == 'add_keywords'])
            }
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… å­¦ä¹ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename
    
    def print_learning_summary(self, analysis: Dict, learning_result: Dict):
        """æ‰“å°å­¦ä¹ æ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“ å­¦ä¹ åé¦ˆæ‘˜è¦")
        print("="*70)
        
        print(f"\nğŸ“Š å®¡æ ¸ç»Ÿè®¡:")
        print(f"   æ€»å®¡æ ¸æ•°: {analysis.get('total_reviews', 0)}")
        print(f"   ä¿®æ­£æ¬¡æ•°: {analysis.get('corrections', 0)}")
        print(f"   ç¡®è®¤æ¬¡æ•°: {analysis.get('confirmations', 0)}")
        print(f"   åˆ é™¤åƒåœ¾: {analysis.get('spam_removed', 0)}")
        
        print(f"\nğŸ”„ å¸¸è§ä¿®æ­£:")
        for transition, count in analysis.get('common_transitions', [])[:3]:
            print(f"   {transition}: {count} æ¬¡")
        
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®: {learning_result.get('suggestions_count', 0)} æ¡")
        
        for i, suggestion in enumerate(learning_result.get('suggestions', [])[:5], 1):
            print(f"\n   å»ºè®® {i}:")
            print(f"   - ç±»å‹: {suggestion.get('type')}")
            if suggestion.get('category'):
                print(f"   - åˆ†ç±»: {suggestion.get('category')}")
            print(f"   - å»ºè®®: {suggestion.get('suggestion', suggestion.get('reason'))}")
            if suggestion.get('keywords'):
                print(f"   - å…³é”®è¯: {', '.join(suggestion['keywords'][:3])}...")
        
        if learning_result.get('suggestions_count', 0) > 5:
            print(f"\n   ... è¿˜æœ‰ {learning_result['suggestions_count'] - 5} æ¡å»ºè®®ï¼ˆè¯¦è§æŠ¥å‘Šæ–‡ä»¶ï¼‰")
        
        print("\n" + "="*70)


def create_feedback_loop(review_history_file: str, 
                        reviewed_data_file: str,
                        classifier) -> str:
    """
    å®Œæ•´çš„åé¦ˆå­¦ä¹ æµç¨‹
    
    Args:
        review_history_file: å®¡æ ¸å†å²æ–‡ä»¶è·¯å¾„
        reviewed_data_file: å®¡æ ¸åæ•°æ®æ–‡ä»¶è·¯å¾„
        classifier: ContentClassifierå®ä¾‹
        
    Returns:
        å­¦ä¹ æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    print("\nğŸ”„ å¯åŠ¨å­¦ä¹ åé¦ˆå¾ªç¯...")
    
    # åŠ è½½å®¡æ ¸å†å²
    with open(review_history_file, 'r', encoding='utf-8') as f:
        review_history = json.load(f)
    
    # åŠ è½½å®¡æ ¸åçš„æ•°æ®
    with open(reviewed_data_file, 'r', encoding='utf-8') as f:
        reviewed_data = json.load(f)
        reviewed_items = reviewed_data.get('data', [])
    
    # åˆ›å»ºå­¦ä¹ ç³»ç»Ÿ
    learner = LearningFeedback()
    
    # åˆ†æå®¡æ ¸å†å²
    analysis = learner.analyze_review_history(review_history)
    
    # åº”ç”¨å­¦ä¹ 
    learning_result = learner.apply_learning(classifier, reviewed_items)
    
    # ç”Ÿæˆæƒé‡è°ƒæ•´å»ºè®®
    adjustments = learner.generate_weight_adjustments(analysis)
    learning_result['weight_adjustments'] = adjustments
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = learner.save_learning_report()
    
    # æ‰“å°æ‘˜è¦
    learner.print_learning_summary(analysis, learning_result)
    
    return report_file


if __name__ == "__main__":
    print("ğŸ“ å­¦ä¹ åé¦ˆç³»ç»Ÿ")
    print("="*70)
    print("\nè¯¥æ¨¡å—ä»äººå·¥å®¡æ ¸ç»“æœä¸­å­¦ä¹ ï¼Œä¼˜åŒ–åˆ†ç±»æ¨¡å‹ã€‚")
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("  1. å®Œæˆäººå·¥å®¡æ ¸ï¼ˆä¼šç”Ÿæˆå®¡æ ¸å†å²æ–‡ä»¶ï¼‰")
    print("  2. è°ƒç”¨ create_feedback_loop() åˆ†æå­¦ä¹ ")
    print("  3. æŸ¥çœ‹ç”Ÿæˆçš„å­¦ä¹ æŠ¥å‘Š")
    print("  4. æ ¹æ®å»ºè®®ä¼˜åŒ–åˆ†ç±»å™¨é…ç½®")
    print("\nç¤ºä¾‹:")
    print("  from learning_feedback import create_feedback_loop")
    print("  from content_classifier import ContentClassifier")
    print("  ")
    print("  classifier = ContentClassifier()")
    print("  report = create_feedback_loop(")
    print("      'review_history_xxx.json',")
    print("      'ai_tracker_data_reviewed_xxx.json',")
    print("      classifier")
    print("  )")

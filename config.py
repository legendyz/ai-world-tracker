"""
é…ç½®ç®¡ç†æ¨¡å— - Config Manager
ç»Ÿä¸€ç®¡ç†LLMå’Œåº”ç”¨é…ç½®

æ”¯æŒå¤šç§é…ç½®æº:
- YAMLé…ç½®æ–‡ä»¶ (config.yaml)
- ç¯å¢ƒå˜é‡
- .envæ–‡ä»¶
- é»˜è®¤å€¼

ä¼˜å…ˆçº§: ç¯å¢ƒå˜é‡ > .envæ–‡ä»¶ > YAMLé…ç½® > é»˜è®¤å€¼
"""

import os
import yaml
from typing import Optional, Dict, Any
from dataclasses import dataclass, field
from pathlib import Path
from logger import get_log_helper

# æ¨¡å—æ—¥å¿—å™¨
log = get_log_helper('config')


@dataclass
class OllamaConfig:
    """Ollamaé…ç½®"""
    base_url: str = "http://localhost:11434"
    default_model: str = "qwen3:8b"
    timeout: int = 60
    num_predict: int = 300
    num_ctx: int = 2048
    temperature: float = 0.1


@dataclass
class OpenAIConfig:
    """OpenAIé…ç½®"""
    api_key: Optional[str] = None
    default_model: str = "gpt-4o-mini"
    timeout: int = 30
    max_tokens: int = 300
    temperature: float = 0.1


@dataclass
class AzureOpenAIConfig:
    """Azure OpenAIé…ç½®"""
    api_key: Optional[str] = None
    endpoint: Optional[str] = None  # Azureç«¯ç‚¹URLï¼Œå¦‚ https://xxx.openai.azure.com/
    api_version: str = "2024-02-15-preview"
    deployment_name: str = "gpt-4o-mini"  # Azureéƒ¨ç½²åç§°
    timeout: int = 30
    max_tokens: int = 300
    temperature: float = 0.1


@dataclass
class ClassifierConfig:
    """åˆ†ç±»å™¨é…ç½®"""
    # é»˜è®¤æ¨¡å¼: 'llm' æˆ– 'rule'
    default_mode: str = "rule"
    
    # LLMé…ç½®
    llm_provider: str = "ollama"
    llm_model: str = "qwen3:8b"
    
    # ç¼“å­˜é…ç½®
    enable_cache: bool = True
    cache_file: str = "llm_classification_cache.json"
    
    # å¹¶å‘é…ç½®
    max_workers: int = 3
    
    # è‡ªåŠ¨é™çº§
    auto_fallback: bool = True


@dataclass 
class CollectorConfig:
    """æ•°æ®é‡‡é›†é…ç½®"""
    product_count: int = 10
    community_count: int = 10
    leader_count: int = 15
    research_count: int = 15
    developer_count: int = 20
    news_count: int = 25
    max_total: int = 100
    timeout: int = 30
    data_retention_days: int = 7  # æ•°æ®é‡‡é›†æ—¶é—´çª—å£ï¼ˆå¤©ï¼‰


@dataclass 
class AppConfig:
    """åº”ç”¨æ€»é…ç½®"""
    ollama: OllamaConfig = field(default_factory=OllamaConfig)
    openai: OpenAIConfig = field(default_factory=OpenAIConfig)
    azure_openai: AzureOpenAIConfig = field(default_factory=AzureOpenAIConfig)
    classifier: ClassifierConfig = field(default_factory=ClassifierConfig)
    collector: CollectorConfig = field(default_factory=CollectorConfig)
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "."
    web_output_dir: str = "web_output"
    visualization_dir: str = "visualizations"


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰é…ç½®
    
    æ”¯æŒå¤šç§é…ç½®æºï¼Œä¼˜å…ˆçº§: ç¯å¢ƒå˜é‡ > .envæ–‡ä»¶ > YAMLé…ç½® > é»˜è®¤å€¼
    """
    
    _instance = None
    _config: AppConfig = None
    _yaml_config: Dict = None
    
    def __new__(cls, config_path: str = 'config.yaml'):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._config_path = config_path
            cls._instance._load_config()
        return cls._instance
    
    def _load_yaml_config(self) -> Dict:
        """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
        config_file = Path(self._config_path)
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f) or {}
            except Exception as e:
                log.warning(f"åŠ è½½YAMLé…ç½®å¤±è´¥: {e}")
        return {}
    
    def _get_yaml_value(self, key_path: str, default: Any = None) -> Any:
        """ä»YAMLé…ç½®è·å–å€¼ï¼Œæ”¯æŒç‚¹å·è·¯å¾„"""
        if not self._yaml_config:
            return default
        keys = key_path.split('.')
        val = self._yaml_config
        for k in keys:
            if isinstance(val, dict) and k in val:
                val = val[k]
            else:
                return default
        return val
    
    def _load_config(self):
        """åŠ è½½é…ç½®"""
        # 1. åŠ è½½.envæ–‡ä»¶
        self._load_env_file()
        
        # 2. åŠ è½½YAMLé…ç½®
        self._yaml_config = self._load_yaml_config()
        
        # 3. åˆ›å»ºé…ç½®å¯¹è±¡ï¼ˆæŒ‰ä¼˜å…ˆçº§åˆå¹¶ï¼‰
        self._config = AppConfig(
            ollama=OllamaConfig(
                base_url=os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434'),
                default_model=os.getenv('OLLAMA_MODEL', 
                    self._get_yaml_value('classification.model', 'qwen3:8b')),
                timeout=int(os.getenv('OLLAMA_TIMEOUT', '60')),
            ),
            openai=OpenAIConfig(
                api_key=os.getenv('OPENAI_API_KEY'),
                default_model=os.getenv('OPENAI_MODEL', 'gpt-4o-mini'),
            ),
            azure_openai=AzureOpenAIConfig(
                api_key=os.getenv('AZURE_OPENAI_API_KEY'),
                endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),
                api_version=os.getenv('AZURE_OPENAI_API_VERSION', '2024-02-15-preview'),
                deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT', 'gpt-4o-mini'),
            ),
            classifier=ClassifierConfig(
                default_mode=os.getenv('CLASSIFIER_MODE', 
                    self._get_yaml_value('classification.mode', 'rule')),
                llm_provider=os.getenv('LLM_PROVIDER', 
                    self._get_yaml_value('classification.provider', 'ollama')),
                llm_model=os.getenv('LLM_MODEL', 
                    self._get_yaml_value('classification.model', 'qwen3:8b')),
                enable_cache=os.getenv('ENABLE_CACHE', 'true').lower() == 'true',
                max_workers=int(os.getenv('MAX_WORKERS', 
                    str(self._get_yaml_value('classification.max_workers', 3)))),
            ),
            collector=CollectorConfig(
                product_count=self._get_yaml_value('collector.product_count', 10),
                community_count=self._get_yaml_value('collector.community_count', 10),
                leader_count=self._get_yaml_value('collector.leader_count', 15),
                research_count=self._get_yaml_value('collector.research_count', 15),
                developer_count=self._get_yaml_value('collector.developer_count', 20),
                news_count=self._get_yaml_value('collector.news_count', 25),
                max_total=self._get_yaml_value('collector.max_total', 100),
                data_retention_days=self._get_yaml_value('collector.data_retention_days', 7),
            ),
            output_dir=self._get_yaml_value('output.report_dir', '.'),
            web_output_dir=self._get_yaml_value('output.web_dir', 'web_output'),
        )
    
    def _load_env_file(self):
        """åŠ è½½.envæ–‡ä»¶"""
        env_file = Path('.env')
        if env_file.exists():
            try:
                with open(env_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            key = key.strip()
                            value = value.strip().strip('"').strip("'")
                            if key and value and key not in os.environ:
                                os.environ[key] = value
            except Exception as e:
                log.warning(f"åŠ è½½.envæ–‡ä»¶å¤±è´¥: {e}")
    
    @property
    def config(self) -> AppConfig:
        """è·å–é…ç½®"""
        return self._config
    
    def get(self, key: str, default: Any = None) -> Any:
        """è·å–é…ç½®é¡¹"""
        keys = key.split('.')
        value = self._config
        for k in keys:
            if hasattr(value, k):
                value = getattr(value, k)
            else:
                return default
        return value
    
    def set(self, key: str, value: Any):
        """è®¾ç½®é…ç½®é¡¹"""
        keys = key.split('.')
        obj = self._config
        for k in keys[:-1]:
            if hasattr(obj, k):
                obj = getattr(obj, k)
            else:
                return
        if hasattr(obj, keys[-1]):
            setattr(obj, keys[-1], value)
    
    def get_llm_config(self) -> Dict[str, Any]:
        """è·å–å½“å‰LLMé…ç½®"""
        provider = self._config.classifier.llm_provider
        model = self._config.classifier.llm_model
        
        if provider == 'ollama':
            return {
                'provider': 'ollama',
                'model': model,
                'base_url': self._config.ollama.base_url,
                'timeout': self._config.ollama.timeout,
            }
        elif provider == 'openai':
            return {
                'provider': 'openai',
                'model': model,
                'api_key': self._config.openai.api_key,
            }
        elif provider == 'azure_openai':
            return {
                'provider': 'azure_openai',
                'model': self._config.azure_openai.deployment_name,
                'api_key': self._config.azure_openai.api_key,
                'azure_endpoint': self._config.azure_openai.endpoint,
                'azure_api_version': self._config.azure_openai.api_version,
            }
        
        return {'provider': 'ollama', 'model': 'qwen3:8b'}
    
    def print_config(self):
        """æ‰“å°å½“å‰é…ç½®"""
        log.section("ğŸ“‹ å½“å‰é…ç½®")
        
        log.config("ã€åˆ†ç±»å™¨ã€‘")
        log.menu(f"  é»˜è®¤æ¨¡å¼: {self._config.classifier.default_mode}")
        log.menu(f"  LLMæä¾›å•†: {self._config.classifier.llm_provider}")
        log.menu(f"  LLMæ¨¡å‹: {self._config.classifier.llm_model}")
        log.menu(f"  ç¼“å­˜: {'å¯ç”¨' if self._config.classifier.enable_cache else 'ç¦ç”¨'}")
        log.menu(f"  å¹¶å‘æ•°: {self._config.classifier.max_workers}")
        
        log.config("ã€æ•°æ®é‡‡é›†ã€‘")
        log.menu(f"  äº§å“æ•°: {self._config.collector.product_count}")
        log.menu(f"  ç¤¾åŒºæ•°: {self._config.collector.community_count}")
        log.menu(f"  é¢†è¢–æ•°: {self._config.collector.leader_count}")
        log.menu(f"  ç ”ç©¶æ•°: {self._config.collector.research_count}")
        log.menu(f"  å¼€å‘è€…æ•°: {self._config.collector.developer_count}")
        log.menu(f"  æ–°é—»æ•°: {self._config.collector.news_count}")
        
        log.config("ã€Ollamaã€‘")
        log.menu(f"  åœ°å€: {self._config.ollama.base_url}")
        log.menu(f"  é»˜è®¤æ¨¡å‹: {self._config.ollama.default_model}")
        
        log.config("ã€OpenAIã€‘")
        log.menu(f"  APIå¯†é’¥: {'å·²è®¾ç½® âœ…' if self._config.openai.api_key else 'æœªè®¾ç½® âŒ'}")
        log.menu(f"  é»˜è®¤æ¨¡å‹: {self._config.openai.default_model}")
        
        log.config("ã€Azure OpenAIã€‘")
        log.menu(f"  APIå¯†é’¥: {'å·²è®¾ç½® âœ…' if self._config.azure_openai.api_key else 'æœªè®¾ç½® âŒ'}")
        log.menu(f"  ç«¯ç‚¹: {'å·²è®¾ç½® âœ…' if self._config.azure_openai.endpoint else 'æœªè®¾ç½® âŒ'}")
        log.menu(f"  éƒ¨ç½²åç§°: {self._config.azure_openai.deployment_name}")
        log.menu(f"  APIç‰ˆæœ¬: {self._config.azure_openai.api_version}")
        
        log.separator()
    
    def reload(self):
        """é‡æ–°åŠ è½½é…ç½®"""
        self._load_config()


# å…¨å±€é…ç½®å®ä¾‹ï¼ˆå…¼å®¹æ—§çš„config_manageræ¨¡å—ï¼‰
config = ConfigManager()


def get_config() -> ConfigManager:
    """è·å–é…ç½®ç®¡ç†å™¨å®ä¾‹"""
    return ConfigManager()


def create_env_template():
    """åˆ›å»º.envæ¨¡æ¿æ–‡ä»¶"""
    template = """# AI World Tracker é…ç½®æ–‡ä»¶
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å…¥ä½ çš„é…ç½®

# ============ åˆ†ç±»å™¨é…ç½® ============
# é»˜è®¤åˆ†ç±»æ¨¡å¼: rule (è§„åˆ™) æˆ– llm (å¤§æ¨¡å‹)
CLASSIFIER_MODE=rule

# LLMæä¾›å•†: ollama / openai / azure_openai
LLM_PROVIDER=ollama

# LLMæ¨¡å‹åç§°
LLM_MODEL=qwen3:8b

# æ˜¯å¦å¯ç”¨ç¼“å­˜
ENABLE_CACHE=true

# å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
MAX_WORKERS=3

# ============ Ollamaé…ç½® (æœ¬åœ°å…è´¹) ============
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen3:8b
OLLAMA_TIMEOUT=60

# ============ OpenAIé…ç½® ============
# OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_MODEL=gpt-4o-mini

# ============ Azure OpenAIé…ç½® ============
# ä»Azureé—¨æˆ·è·å–è¿™äº›å€¼: Azure OpenAIèµ„æº -> å¯†é’¥å’Œç»ˆç»“ç‚¹
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key
# AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
# AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini
# AZURE_OPENAI_API_VERSION=2024-02-15-preview
"""
    
    env_example = Path('.env.example')
    with open(env_example, 'w', encoding='utf-8') as f:
        f.write(template)
    
    log.success(f"å·²åˆ›å»ºé…ç½®æ¨¡æ¿: {env_example}")
    log.info("è¯·å¤åˆ¶ä¸º .env å¹¶å¡«å…¥ä½ çš„é…ç½®")


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    config = get_config()
    config.print_config()
    
    # åˆ›å»ºæ¨¡æ¿
    create_env_template()

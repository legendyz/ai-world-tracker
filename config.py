"""
é…ç½®ç®¡ç†æ¨¡å— - Config Manager
ç»Ÿä¸€ç®¡ç†LLMå’Œåº”ç”¨é…ç½®

ä¼˜å…ˆçº§: ç¯å¢ƒå˜é‡ > .envæ–‡ä»¶ > é»˜è®¤å€¼
"""

import os
from typing import Optional, Dict, Any
from dataclasses import dataclass, field
from pathlib import Path


@dataclass
class OllamaConfig:
    """Ollamaé…ç½®"""
    base_url: str = "http://localhost:11434"
    default_model: str = "qwen3:8b"
    timeout: int = 60
    num_predict: int = 300
    num_ctx: int = 2048
    temperature: float = 0.1


@dataclass
class OpenAIConfig:
    """OpenAIé…ç½®"""
    api_key: Optional[str] = None
    default_model: str = "gpt-4o-mini"
    timeout: int = 30
    max_tokens: int = 300
    temperature: float = 0.1


@dataclass
class AnthropicConfig:
    """Anthropicé…ç½®"""
    api_key: Optional[str] = None
    default_model: str = "claude-3-haiku-20240307"
    timeout: int = 30
    max_tokens: int = 300


@dataclass
class ClassifierConfig:
    """åˆ†ç±»å™¨é…ç½®"""
    # é»˜è®¤æ¨¡å¼: 'llm' æˆ– 'rule'
    default_mode: str = "rule"
    
    # LLMé…ç½®
    llm_provider: str = "ollama"
    llm_model: str = "qwen3:8b"
    
    # ç¼“å­˜é…ç½®
    enable_cache: bool = True
    cache_file: str = "llm_classification_cache.json"
    
    # å¹¶å‘é…ç½®
    max_workers: int = 3
    
    # è‡ªåŠ¨é™çº§
    auto_fallback: bool = True


@dataclass 
class AppConfig:
    """åº”ç”¨æ€»é…ç½®"""
    ollama: OllamaConfig = field(default_factory=OllamaConfig)
    openai: OpenAIConfig = field(default_factory=OpenAIConfig)
    anthropic: AnthropicConfig = field(default_factory=AnthropicConfig)
    classifier: ClassifierConfig = field(default_factory=ClassifierConfig)
    
    # æ•°æ®é‡‡é›†é…ç½®
    collect_max_items: int = 15
    collect_timeout: int = 30
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "."
    web_output_dir: str = "web_output"
    visualization_dir: str = "visualizations"


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    _instance = None
    _config: AppConfig = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._load_config()
        return cls._instance
    
    def _load_config(self):
        """åŠ è½½é…ç½®"""
        # å°è¯•åŠ è½½.envæ–‡ä»¶
        self._load_env_file()
        
        # åˆ›å»ºé…ç½®å¯¹è±¡
        self._config = AppConfig(
            ollama=OllamaConfig(
                base_url=os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434'),
                default_model=os.getenv('OLLAMA_MODEL', 'qwen3:8b'),
                timeout=int(os.getenv('OLLAMA_TIMEOUT', '60')),
            ),
            openai=OpenAIConfig(
                api_key=os.getenv('OPENAI_API_KEY'),
                default_model=os.getenv('OPENAI_MODEL', 'gpt-4o-mini'),
            ),
            anthropic=AnthropicConfig(
                api_key=os.getenv('ANTHROPIC_API_KEY'),
                default_model=os.getenv('ANTHROPIC_MODEL', 'claude-3-haiku-20240307'),
            ),
            classifier=ClassifierConfig(
                default_mode=os.getenv('CLASSIFIER_MODE', 'rule'),
                llm_provider=os.getenv('LLM_PROVIDER', 'ollama'),
                llm_model=os.getenv('LLM_MODEL', 'qwen3:8b'),
                enable_cache=os.getenv('ENABLE_CACHE', 'true').lower() == 'true',
                max_workers=int(os.getenv('MAX_WORKERS', '3')),
            ),
        )
    
    def _load_env_file(self):
        """åŠ è½½.envæ–‡ä»¶"""
        env_file = Path('.env')
        if env_file.exists():
            try:
                with open(env_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            key = key.strip()
                            value = value.strip().strip('"').strip("'")
                            if key and value and key not in os.environ:
                                os.environ[key] = value
            except Exception as e:
                print(f"âš ï¸ åŠ è½½.envæ–‡ä»¶å¤±è´¥: {e}")
    
    @property
    def config(self) -> AppConfig:
        """è·å–é…ç½®"""
        return self._config
    
    def get(self, key: str, default: Any = None) -> Any:
        """è·å–é…ç½®é¡¹"""
        keys = key.split('.')
        value = self._config
        for k in keys:
            if hasattr(value, k):
                value = getattr(value, k)
            else:
                return default
        return value
    
    def set(self, key: str, value: Any):
        """è®¾ç½®é…ç½®é¡¹"""
        keys = key.split('.')
        obj = self._config
        for k in keys[:-1]:
            if hasattr(obj, k):
                obj = getattr(obj, k)
            else:
                return
        if hasattr(obj, keys[-1]):
            setattr(obj, keys[-1], value)
    
    def get_llm_config(self) -> Dict[str, Any]:
        """è·å–å½“å‰LLMé…ç½®"""
        provider = self._config.classifier.llm_provider
        model = self._config.classifier.llm_model
        
        if provider == 'ollama':
            return {
                'provider': 'ollama',
                'model': model,
                'base_url': self._config.ollama.base_url,
                'timeout': self._config.ollama.timeout,
            }
        elif provider == 'openai':
            return {
                'provider': 'openai',
                'model': model,
                'api_key': self._config.openai.api_key,
            }
        elif provider == 'anthropic':
            return {
                'provider': 'anthropic',
                'model': model,
                'api_key': self._config.anthropic.api_key,
            }
        
        return {'provider': 'ollama', 'model': 'qwen3:8b'}
    
    def print_config(self):
        """æ‰“å°å½“å‰é…ç½®"""
        print("\n" + "="*60)
        print("ğŸ“‹ å½“å‰é…ç½®")
        print("="*60)
        
        print(f"\nã€åˆ†ç±»å™¨ã€‘")
        print(f"  é»˜è®¤æ¨¡å¼: {self._config.classifier.default_mode}")
        print(f"  LLMæä¾›å•†: {self._config.classifier.llm_provider}")
        print(f"  LLMæ¨¡å‹: {self._config.classifier.llm_model}")
        print(f"  ç¼“å­˜: {'å¯ç”¨' if self._config.classifier.enable_cache else 'ç¦ç”¨'}")
        print(f"  å¹¶å‘æ•°: {self._config.classifier.max_workers}")
        
        print(f"\nã€Ollamaã€‘")
        print(f"  åœ°å€: {self._config.ollama.base_url}")
        print(f"  é»˜è®¤æ¨¡å‹: {self._config.ollama.default_model}")
        
        print(f"\nã€OpenAIã€‘")
        print(f"  APIå¯†é’¥: {'å·²è®¾ç½® âœ…' if self._config.openai.api_key else 'æœªè®¾ç½® âŒ'}")
        print(f"  é»˜è®¤æ¨¡å‹: {self._config.openai.default_model}")
        
        print(f"\nã€Anthropicã€‘")
        print(f"  APIå¯†é’¥: {'å·²è®¾ç½® âœ…' if self._config.anthropic.api_key else 'æœªè®¾ç½® âŒ'}")
        print(f"  é»˜è®¤æ¨¡å‹: {self._config.anthropic.default_model}")
        
        print("="*60)


# å…¨å±€é…ç½®å®ä¾‹
def get_config() -> ConfigManager:
    """è·å–é…ç½®ç®¡ç†å™¨å®ä¾‹"""
    return ConfigManager()


def create_env_template():
    """åˆ›å»º.envæ¨¡æ¿æ–‡ä»¶"""
    template = """# AI World Tracker é…ç½®æ–‡ä»¶
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å…¥ä½ çš„é…ç½®

# ============ åˆ†ç±»å™¨é…ç½® ============
# é»˜è®¤åˆ†ç±»æ¨¡å¼: rule (è§„åˆ™) æˆ– llm (å¤§æ¨¡å‹)
CLASSIFIER_MODE=rule

# LLMæä¾›å•†: ollama / openai / anthropic
LLM_PROVIDER=ollama

# LLMæ¨¡å‹åç§°
LLM_MODEL=qwen3:8b

# æ˜¯å¦å¯ç”¨ç¼“å­˜
ENABLE_CACHE=true

# å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
MAX_WORKERS=3

# ============ Ollamaé…ç½® (æœ¬åœ°å…è´¹) ============
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen3:8b
OLLAMA_TIMEOUT=60

# ============ OpenAIé…ç½® ============
# OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_MODEL=gpt-4o-mini

# ============ Anthropicé…ç½® ============
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key
ANTHROPIC_MODEL=claude-3-haiku-20240307
"""
    
    env_example = Path('.env.example')
    with open(env_example, 'w', encoding='utf-8') as f:
        f.write(template)
    
    print(f"âœ… å·²åˆ›å»ºé…ç½®æ¨¡æ¿: {env_example}")
    print("   è¯·å¤åˆ¶ä¸º .env å¹¶å¡«å…¥ä½ çš„é…ç½®")


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    config = get_config()
    config.print_config()
    
    # åˆ›å»ºæ¨¡æ¿
    create_env_template()

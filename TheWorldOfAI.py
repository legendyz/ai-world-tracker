"""
AI World Tracker - MVPç‰ˆæœ¬
å…¨çƒAIç ”ç©¶ã€äº§å“ã€å¸‚åœºåŠ¨æ€è¿½è¸ªåº”ç”¨

ä¸»è¦åŠŸèƒ½:
1. æ•°æ®é‡‡é›†æ¨¡å— - ä»arXivã€GitHubã€RSSç­‰æºé‡‡é›†AIèµ„è®¯
2. å†…å®¹åˆ†ç±»ç³»ç»Ÿ - è‡ªåŠ¨åˆ†ç±»ä¸ºç ”ç©¶/äº§å“/å¸‚åœºç»´åº¦ï¼ˆæ”¯æŒLLMå’Œè§„åˆ™ä¸¤ç§æ¨¡å¼ï¼‰
3. æ™ºèƒ½åˆ†æåŠŸèƒ½ - ç”Ÿæˆè¶‹åŠ¿åˆ†æå’Œæ´å¯ŸæŠ¥å‘Š
4. æ•°æ®å¯è§†åŒ– - ç”Ÿæˆå„ç±»å›¾è¡¨å±•ç¤ºæ•°æ®

ä½œè€…: AI World Tracker Team
æ—¥æœŸ: 2025-12-01
æ›´æ–°: 2025-12-06 - æ·»åŠ LLMåˆ†ç±»æ”¯æŒ
"""

import sys
import json
import os
from datetime import datetime
from typing import Optional

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_collector import DataCollector
from content_classifier import ContentClassifier
from ai_analyzer import AIAnalyzer
from visualizer import DataVisualizer
from web_publisher import WebPublisher
from manual_reviewer import ManualReviewer
from learning_feedback import LearningFeedback, create_feedback_loop

# ç”¨æˆ·é…ç½®æ–‡ä»¶
CONFIG_FILE = 'ai_tracker_config.json'

# LLMåˆ†ç±»å™¨ï¼ˆå¯é€‰å¯¼å…¥ï¼‰
try:
    from llm_classifier import LLMClassifier, check_ollama_status, AVAILABLE_MODELS, LLMProvider
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    print("âš ï¸ LLMåˆ†ç±»å™¨æœªå®‰è£…ï¼Œå°†ä½¿ç”¨è§„åˆ™åˆ†ç±»æ¨¡å¼")


class AIWorldTracker:
    """AIä¸–ç•Œè¿½è¸ªå™¨ä¸»åº”ç”¨"""
    
    def __init__(self):
        print("\n" + "="*60)
        print("     ğŸŒ AI World Tracker - MVP ç‰ˆæœ¬")
        print("     å…¨çƒäººå·¥æ™ºèƒ½åŠ¨æ€è¿½è¸ªç³»ç»Ÿ")
        print("="*60 + "\n")
        
        self.collector = DataCollector()
        self.classifier = ContentClassifier()  # è§„åˆ™åˆ†ç±»å™¨
        self.llm_classifier = None  # LLMåˆ†ç±»å™¨ï¼ˆæŒ‰éœ€åˆå§‹åŒ–ï¼‰
        self.analyzer = AIAnalyzer()
        self.visualizer = DataVisualizer()
        self.web_publisher = WebPublisher()
        self.reviewer = ManualReviewer()
        self.learner = LearningFeedback()
        
        self.data = []
        self.trends = {}
        self.chart_files = {}
        
        # åˆ†ç±»æ¨¡å¼: 'rule' æˆ– 'llm'
        self.classification_mode = 'rule'
        self.llm_provider = 'ollama'
        self.llm_model = 'qwen3:8b'
        
        # åŠ è½½ç”¨æˆ·é…ç½®ï¼ˆåŒ…æ‹¬ä¸Šæ¬¡çš„åˆ†ç±»æ¨¡å¼ï¼‰
        self._load_user_config()
        
        # å°è¯•åŠ è½½æœ€æ–°æ•°æ®
        self._load_latest_data()
        
        # æ£€æŸ¥LLMå¯ç”¨æ€§
        if LLM_AVAILABLE:
            self._check_llm_availability()
        
        # å°è¯•æ¢å¤ä¸Šæ¬¡çš„LLMåˆ†ç±»å™¨
        self._try_restore_llm_classifier()
    
    def _load_user_config(self):
        """åŠ è½½ç”¨æˆ·é…ç½®ï¼ˆåŒ…æ‹¬ä¸Šæ¬¡çš„åˆ†ç±»æ¨¡å¼é€‰æ‹©ï¼‰"""
        try:
            if os.path.exists(CONFIG_FILE):
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                # æ¢å¤åˆ†ç±»æ¨¡å¼è®¾ç½®
                saved_mode = config.get('classification_mode', 'rule')
                saved_provider = config.get('llm_provider', 'ollama')
                saved_model = config.get('llm_model', 'qwen3:8b')
                
                # éªŒè¯æ¨¡å¼æœ‰æ•ˆæ€§
                if saved_mode in ['rule', 'llm']:
                    self.classification_mode = saved_mode
                    self.llm_provider = saved_provider
                    self.llm_model = saved_model
                    
                    if saved_mode == 'llm':
                        print(f"ğŸ“‹ å·²åŠ è½½ä¸Šæ¬¡é…ç½®: LLMæ¨¡å¼ ({saved_provider}/{saved_model})")
                    else:
                        print(f"ğŸ“‹ å·²åŠ è½½ä¸Šæ¬¡é…ç½®: è§„åˆ™æ¨¡å¼")
        except Exception as e:
            # é…ç½®æ–‡ä»¶æŸåæˆ–ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
            pass
    
    def _save_user_config(self):
        """ä¿å­˜ç”¨æˆ·é…ç½®"""
        try:
            config = {
                'classification_mode': self.classification_mode,
                'llm_provider': self.llm_provider,
                'llm_model': self.llm_model,
                'last_updated': datetime.now().isoformat()
            }
            with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜é…ç½®å¤±è´¥: {e}")
    
    def _try_restore_llm_classifier(self):
        """å°è¯•æ¢å¤ä¸Šæ¬¡çš„LLMåˆ†ç±»å™¨"""
        if self.classification_mode == 'llm' and LLM_AVAILABLE:
            try:
                # æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯ç”¨
                if self.llm_provider == 'ollama':
                    status = check_ollama_status()
                    if status['running'] and self.llm_model in status.get('models', []):
                        self.llm_classifier = LLMClassifier(
                            provider=LLMProvider.OLLAMA,
                            model=self.llm_model
                        )
                        print(f"âœ… å·²æ¢å¤LLMåˆ†ç±»å™¨: {self.llm_model}")
                    else:
                        print(f"âš ï¸ æ— æ³•æ¢å¤LLMæ¨¡å¼ (OllamaæœåŠ¡ä¸å¯ç”¨æˆ–æ¨¡å‹æœªå®‰è£…)ï¼Œåˆ‡æ¢åˆ°è§„åˆ™æ¨¡å¼")
                        self.classification_mode = 'rule'
                        self._save_user_config()
                else:
                    # OpenAI/Anthropic ç­‰äº‘æœåŠ¡ï¼Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨é…ç½®
                    print(f"âš ï¸ ä¸Šæ¬¡ä½¿ç”¨çš„æ˜¯äº‘ç«¯LLM ({self.llm_provider})ï¼Œéœ€è¦é‡æ–°é…ç½®")
                    self.classification_mode = 'rule'
            except Exception as e:
                print(f"âš ï¸ æ¢å¤LLMåˆ†ç±»å™¨å¤±è´¥: {e}ï¼Œåˆ‡æ¢åˆ°è§„åˆ™æ¨¡å¼")
                self.classification_mode = 'rule'
                self._save_user_config()
    
    def _check_llm_availability(self):
        """æ£€æŸ¥LLMæœåŠ¡å¯ç”¨æ€§ï¼Œæä¾›å¯åŠ¨å¸®åŠ©"""
        status = check_ollama_status()
        
        if status['running']:
            if status['models']:
                print(f"âœ… OllamaæœåŠ¡è¿è¡Œä¸­ï¼Œå¯ç”¨æ¨¡å‹: {', '.join(status['models'][:3])}")
                if status['recommended']:
                    self.llm_model = status['recommended']
            else:
                print("âš ï¸  OllamaæœåŠ¡è¿è¡Œä¸­ï¼Œä½†æœªå®‰è£…ä»»ä½•æ¨¡å‹")
                print("   è¯·å®‰è£…æ¨¡å‹: ollama pull qwen3:8b")
                print("   åˆ‡æ¢åˆ†ç±»æ¨¡å¼æ—¶å°†æ— æ³•ä½¿ç”¨æœ¬åœ°LLMåˆ†ç±»")
        else:
            print("â„¹ï¸  OllamaæœåŠ¡æœªè¿è¡Œ")
            self._offer_ollama_startup_help()
    
    def _offer_ollama_startup_help(self):
        """æä¾›Ollamaå¯åŠ¨å¸®åŠ©"""
        print("\n   å¦‚éœ€ä½¿ç”¨æœ¬åœ°LLMåˆ†ç±»ï¼Œè¯·å…ˆå¯åŠ¨OllamaæœåŠ¡ã€‚")
        choice = input("   æ˜¯å¦å°è¯•å¯åŠ¨OllamaæœåŠ¡? (y/n) [n]: ").strip().lower()
        
        if choice == 'y':
            import subprocess
            import platform
            
            try:
                print("\n   ğŸš€ æ­£åœ¨å¯åŠ¨OllamaæœåŠ¡...")
                
                # æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©å¯åŠ¨æ–¹å¼
                system = platform.system()
                if system == 'Windows':
                    # Windows: åœ¨åå°å¯åŠ¨ ollama serve
                    subprocess.Popen(
                        ['ollama', 'serve'],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        creationflags=subprocess.CREATE_NO_WINDOW
                    )
                else:
                    # Linux/Mac: åœ¨åå°å¯åŠ¨
                    subprocess.Popen(
                        ['ollama', 'serve'],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        start_new_session=True
                    )
                
                # ç­‰å¾…æœåŠ¡å¯åŠ¨
                import time
                print("   ç­‰å¾…æœåŠ¡å¯åŠ¨...", end='', flush=True)
                for i in range(10):
                    time.sleep(1)
                    print('.', end='', flush=True)
                    status = check_ollama_status()
                    if status['running']:
                        print("\n   âœ… OllamaæœåŠ¡å·²å¯åŠ¨ï¼")
                        if status['models']:
                            print(f"   å¯ç”¨æ¨¡å‹: {', '.join(status['models'][:3])}")
                            if status['recommended']:
                                self.llm_model = status['recommended']
                        else:
                            print("   âš ï¸  æœªå®‰è£…ä»»ä½•æ¨¡å‹ï¼Œè¯·è¿è¡Œ: ollama pull qwen3:8b")
                            print("   åˆ‡æ¢åˆ†ç±»æ¨¡å¼æ—¶å°†æ— æ³•ä½¿ç”¨æœ¬åœ°LLMåˆ†ç±»")
                        return
                
                print("\n   âš ï¸  OllamaæœåŠ¡å¯åŠ¨è¶…æ—¶ï¼Œè¯·æ‰‹åŠ¨å¯åŠ¨: ollama serve")
                
            except FileNotFoundError:
                print("\n   âŒ æœªæ‰¾åˆ°Ollamaå‘½ä»¤ï¼Œè¯·ç¡®è®¤å·²å®‰è£…Ollama")
                print("   ä¸‹è½½åœ°å€: https://ollama.com/download")
                print("   åˆ‡æ¢åˆ†ç±»æ¨¡å¼æ—¶å°†æ— æ³•ä½¿ç”¨æœ¬åœ°LLMåˆ†ç±»")
            except Exception as e:
                print(f"\n   âŒ å¯åŠ¨Ollamaå¤±è´¥: {e}")
                print("   è¯·æ‰‹åŠ¨å¯åŠ¨: ollama serve")
        else:
            print("   æç¤º: åˆ‡æ¢åˆ†ç±»æ¨¡å¼æ—¶å°†æ— æ³•ä½¿ç”¨æœ¬åœ°LLMåˆ†ç±»")
            print("   æ‚¨å¯ä»¥ç¨åæ‰‹åŠ¨å¯åŠ¨: ollama serve")
    
    def _offer_ollama_startup_help_in_menu(self):
        """åœ¨èœå•ä¸­æä¾›Ollamaå¯åŠ¨å¸®åŠ©ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        choice = input("æ˜¯å¦å°è¯•å¯åŠ¨OllamaæœåŠ¡? (y/n) [n]: ").strip().lower()
        
        if choice == 'y':
            import subprocess
            import platform
            
            try:
                print("\nğŸš€ æ­£åœ¨å¯åŠ¨OllamaæœåŠ¡...")
                
                system = platform.system()
                if system == 'Windows':
                    subprocess.Popen(
                        ['ollama', 'serve'],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        creationflags=subprocess.CREATE_NO_WINDOW
                    )
                else:
                    subprocess.Popen(
                        ['ollama', 'serve'],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        start_new_session=True
                    )
                
                import time
                print("ç­‰å¾…æœåŠ¡å¯åŠ¨...", end='', flush=True)
                for i in range(10):
                    time.sleep(1)
                    print('.', end='', flush=True)
                    status = check_ollama_status()
                    if status['running']:
                        print("\nâœ… OllamaæœåŠ¡å·²å¯åŠ¨ï¼")
                        return
                
                print("\nâš ï¸  æœåŠ¡å¯åŠ¨è¶…æ—¶ï¼Œè¯·æ‰‹åŠ¨å¯åŠ¨: ollama serve")
                
            except FileNotFoundError:
                print("\nâŒ æœªæ‰¾åˆ°Ollamaå‘½ä»¤ï¼Œè¯·ç¡®è®¤å·²å®‰è£…Ollama")
                print("ä¸‹è½½åœ°å€: https://ollama.com/download")
            except Exception as e:
                print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
    
    def _install_ollama_model(self, model_name: str):
        """å®‰è£…Ollamaæ¨¡å‹"""
        import subprocess
        
        print(f"\nğŸ“¥ æ­£åœ¨å®‰è£…æ¨¡å‹ {model_name}...")
        print("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œå–å†³äºæ‚¨çš„ç½‘ç»œé€Ÿåº¦...\n")
        
        try:
            # å®æ—¶æ˜¾ç¤ºä¸‹è½½è¿›åº¦
            process = subprocess.Popen(
                ['ollama', 'pull', model_name],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )
            
            for line in process.stdout:
                print(f"  {line.strip()}")
            
            process.wait()
            
            if process.returncode == 0:
                print(f"\nâœ… æ¨¡å‹ {model_name} å®‰è£…æˆåŠŸï¼")
                self.llm_model = model_name
            else:
                print(f"\nâŒ æ¨¡å‹å®‰è£…å¤±è´¥ (è¿”å›ç : {process.returncode})")
                
        except FileNotFoundError:
            print("\nâŒ æœªæ‰¾åˆ°Ollamaå‘½ä»¤ï¼Œè¯·ç¡®è®¤å·²å®‰è£…Ollama")
        except Exception as e:
            print(f"\nâŒ å®‰è£…å¤±è´¥: {e}")
    
    def _load_latest_data(self):
        """å°è¯•åŠ è½½æœ€æ–°çš„æ•°æ®æ–‡ä»¶"""
        try:
            files = [f for f in os.listdir('.') if f.startswith('ai_tracker_data_') and f.endswith('.json')]
            if not files:
                return
            
            latest_file = max(files)
            print(f"ğŸ“¥ å‘ç°å†å²æ•°æ®ï¼Œæ­£åœ¨åŠ è½½: {latest_file}...")
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
                
            self.data = saved_data.get('data', [])
            self.trends = saved_data.get('trends', {})
            
            # å°è¯•åŠ è½½å›¾è¡¨æ–‡ä»¶
            if os.path.exists('visualizations'):
                self.chart_files = {
                    'tech_hotspots': os.path.join('visualizations', 'tech_hotspots.png'),
                    'content_distribution': os.path.join('visualizations', 'content_distribution.png'),
                    'region_distribution': os.path.join('visualizations', 'region_distribution.png'),
                    'daily_trends': os.path.join('visualizations', 'daily_trends.png'),
                    'dashboard': os.path.join('visualizations', 'dashboard.png')
                }
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                self.chart_files = {k: v for k, v in self.chart_files.items() if os.path.exists(v)}
            
            print(f"âœ… å·²åŠ è½½ {len(self.data)} æ¡å†å²æ•°æ®")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å†å²æ•°æ®å¤±è´¥: {e}")
    
    def run_full_pipeline(self):
        """è¿è¡Œå®Œæ•´æ•°æ®å¤„ç†æµç¨‹"""
        print("ğŸš€ å¯åŠ¨å®Œæ•´æ•°æ®å¤„ç†æµç¨‹...\n")
        
        # æ­¥éª¤1: æ•°æ®é‡‡é›†
        print("ã€æ­¥éª¤ 1/4ã€‘æ•°æ®é‡‡é›†")
        raw_data = self.collector.collect_all()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        all_items = []
        for category, items in raw_data.items():
            all_items.extend(items)
        
        print(f"\nğŸ“¦ å…±é‡‡é›† {len(all_items)} æ¡åŸå§‹æ•°æ®\n")
        
        # æ­¥éª¤2: å†…å®¹åˆ†ç±»ï¼ˆæ ¹æ®å½“å‰æ¨¡å¼é€‰æ‹©åˆ†ç±»å™¨ï¼‰
        print("ã€æ­¥éª¤ 2/5ã€‘å†…å®¹åˆ†ç±»")
        self.data = self._classify_data(all_items)
        
        # æ­¥éª¤3: æ™ºèƒ½åˆ†æ
        print("\nã€æ­¥éª¤ 3/5ã€‘æ™ºèƒ½åˆ†æ")
        self.trends = self.analyzer.analyze_trends(self.data)
        
        # æ­¥éª¤4: æ•°æ®å¯è§†åŒ–
        print("\nã€æ­¥éª¤ 4/5ã€‘æ•°æ®å¯è§†åŒ–")
        self.chart_files = self.visualizer.visualize_all(self.trends)
        
        # æ­¥éª¤5: ç”ŸæˆWebé¡µé¢
        print("\nã€æ­¥éª¤ 5/5ã€‘ç”ŸæˆWebé¡µé¢")
        web_file = self.web_publisher.generate_html_page(self.data, self.trends, self.chart_files)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.analyzer.generate_report(self.data, self.trends)
        
        # ä¿å­˜æ•°æ®å’ŒæŠ¥å‘Š
        self._save_results(report, web_file)
        
        print("\n" + "="*60)
        print("âœ¨ å¤„ç†å®Œæˆï¼")
        print("="*60)
        print(f"\nğŸ“Š å·²ç”Ÿæˆ {len([f for f in self.chart_files.values() if f])} ä¸ªå¯è§†åŒ–å›¾è¡¨")
        print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜")
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° JSON æ–‡ä»¶")
        print(f"ğŸŒ Webé¡µé¢å·²ç”Ÿæˆ\n")
        
        return report
    
    def show_menu(self):
        """æ˜¾ç¤ºäº¤äº’èœå•"""
        while True:
            # æ˜¾ç¤ºå½“å‰åˆ†ç±»æ¨¡å¼
            mode_str = self._get_mode_display()
            
            print("\n" + "="*60)
            print("ğŸ“‹ ä¸»èœå•")
            print(f"   å½“å‰åˆ†ç±»æ¨¡å¼: {mode_str}")
            print("="*60)
            print("1. ğŸš€ è‡ªåŠ¨æ›´æ–°æ•°æ®ä¸æŠ¥å‘Š (Auto Update & Generate)")
            print("2. ğŸŒ ç”Ÿæˆå¹¶æ‰“å¼€ Web é¡µé¢ (Generate & Open Web Page)")
            print("3. ğŸ“ äººå·¥å®¡æ ¸åˆ†ç±» (Manual Review)")
            print("4. ğŸ“ å­¦ä¹ åé¦ˆåˆ†æ (Learning Feedback)")
            print("5. âš™ï¸  åˆ‡æ¢åˆ†ç±»æ¨¡å¼ (Switch Classification Mode)")
            print("0. é€€å‡ºç¨‹åº")
            print("="*60)
            
            choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (0-5): ").strip()
            
            if choice == '1':
                self.run_full_pipeline()
            elif choice == '2':
                self._generate_web_page()
            elif choice == '3':
                self._manual_review()
            elif choice == '4':
                self._learning_feedback()
            elif choice == '5':
                self._switch_classification_mode()
            elif choice == '0':
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ AI World Trackerï¼å†è§ï¼\n")
                break
            else:
                print("\nâŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
    
    def _get_mode_display(self) -> str:
        """è·å–å½“å‰æ¨¡å¼çš„æ˜¾ç¤ºå­—ç¬¦ä¸²"""
        if self.classification_mode == 'llm':
            return f"ğŸ¤– LLMæ¨¡å¼ ({self.llm_provider}/{self.llm_model})"
        else:
            return "ğŸ“ è§„åˆ™æ¨¡å¼ (Rule-based)"
    
    def _switch_classification_mode(self):
        """åˆ‡æ¢åˆ†ç±»æ¨¡å¼"""
        print("\n" + "="*60)
        print("âš™ï¸  åˆ‡æ¢åˆ†ç±»æ¨¡å¼")
        print("="*60)
        
        print(f"\nå½“å‰æ¨¡å¼: {self._get_mode_display()}")
        print("\nå¯ç”¨æ¨¡å¼:")
        print("  1. ğŸ“ è§„åˆ™æ¨¡å¼ (Rule-based) - å¿«é€Ÿã€å…è´¹ã€æ— éœ€ç½‘ç»œ")
        
        if LLM_AVAILABLE:
            print("  2. ğŸ¤– LLMæ¨¡å¼ (Ollamaæœ¬åœ°) - é«˜ç²¾åº¦ã€è¯­ä¹‰ç†è§£")
            print("  3. ğŸ¤– LLMæ¨¡å¼ (OpenAI) - æœ€é«˜ç²¾åº¦ã€éœ€è¦APIå¯†é’¥")
            print("  4. ğŸ¤– LLMæ¨¡å¼ (Anthropic) - é«˜ç²¾åº¦ã€éœ€è¦APIå¯†é’¥")
        else:
            print("  âš ï¸  LLMæ¨¡å¼ä¸å¯ç”¨ (æœªå®‰è£…llm_classifieræ¨¡å—)")
        
        choice = input("\nè¯·é€‰æ‹©æ¨¡å¼ (1-4): ").strip()
        
        if choice == '1':
            self.classification_mode = 'rule'
            self.llm_classifier = None
            self._save_user_config()
            print("\nâœ… å·²åˆ‡æ¢åˆ°è§„åˆ™æ¨¡å¼")
        
        elif choice == '2' and LLM_AVAILABLE:
            self._setup_ollama_mode()
        
        elif choice == '3' and LLM_AVAILABLE:
            self._setup_openai_mode()
        
        elif choice == '4' and LLM_AVAILABLE:
            self._setup_anthropic_mode()
        
        else:
            print("\nâŒ æ— æ•ˆé€‰æ‹©")
    
    def _setup_ollama_mode(self):
        """è®¾ç½®Ollamaæ¨¡å¼"""
        status = check_ollama_status()
        
        if not status['running']:
            print("\nâš ï¸ OllamaæœåŠ¡æœªè¿è¡Œï¼")
            self._offer_ollama_startup_help_in_menu()
            
            # é‡æ–°æ£€æŸ¥çŠ¶æ€
            status = check_ollama_status()
            if not status['running']:
                print("\nâŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·æ‰‹åŠ¨å¯åŠ¨åé‡è¯•")
                return
        
        print(f"\nâœ… OllamaæœåŠ¡è¿è¡Œä¸­")
        print(f"\nå¯ç”¨çš„æœ¬åœ°æ¨¡å‹:")
        
        models = status['models']
        if not models:
            print("  âš ï¸ æœªæ‰¾åˆ°å·²å®‰è£…çš„æ¨¡å‹")
            print("  è¯·å…ˆå®‰è£…æ¨¡å‹: ollama pull qwen3:8b")
            
            choice = input("\næ˜¯å¦ç°åœ¨å®‰è£…æ¨èæ¨¡å‹ qwen3:8b? (y/n) [n]: ").strip().lower()
            if choice == 'y':
                self._install_ollama_model('qwen3:8b')
                # é‡æ–°è·å–æ¨¡å‹åˆ—è¡¨
                status = check_ollama_status()
                models = status['models']
            
            if not models:
                print("\nâŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œæ— æ³•åˆ‡æ¢åˆ°LLMæ¨¡å¼")
                return
        
        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        for i, model in enumerate(models, 1):
            recommended = " â­ æ¨è" if model == status['recommended'] else ""
            print(f"  {i}. {model}{recommended}")
        
        model_choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(models)}) [é»˜è®¤: 1]: ").strip() or '1'
        
        try:
            idx = int(model_choice) - 1
            selected_model = models[idx] if 0 <= idx < len(models) else models[0]
        except:
            selected_model = models[0]
        
        # åˆå§‹åŒ–LLMåˆ†ç±»å™¨
        self.classification_mode = 'llm'
        self.llm_provider = 'ollama'
        self.llm_model = selected_model
        
        try:
            self.llm_classifier = LLMClassifier(
                provider='ollama',
                model=selected_model,
                enable_cache=True,
                max_workers=3,  # é»˜è®¤å¹¶å‘æ•°ï¼ŒGPUæ¨¡å¼è‡ªåŠ¨æå‡è‡³6
                batch_size=5    # å¯ç”¨æ‰¹é‡åˆ†ç±»
            )
            self._save_user_config()
            print(f"\nâœ… å·²åˆ‡æ¢åˆ°LLMæ¨¡å¼: Ollama/{selected_model}")
            
            # é¢„çƒ­æ¨¡å‹
            warmup = input("\næ˜¯å¦ç°åœ¨é¢„çƒ­æ¨¡å‹? (Y/n): ").strip().lower()
            if warmup != 'n':
                self.llm_classifier.warmup_model()
                
        except Exception as e:
            print(f"\nâŒ åˆå§‹åŒ–LLMåˆ†ç±»å™¨å¤±è´¥: {e}")
            self.classification_mode = 'rule'
            self._save_user_config()
    
    def _setup_openai_mode(self):
        """è®¾ç½®OpenAIæ¨¡å¼"""
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            print("\nâš ï¸ æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            api_key = input("è¯·è¾“å…¥OpenAI APIå¯†é’¥ (æˆ–æŒ‰Enterå–æ¶ˆ): ").strip()
            if not api_key:
                return
        
        print("\nå¯ç”¨çš„OpenAIæ¨¡å‹:")
        models = list(AVAILABLE_MODELS[LLMProvider.OPENAI].keys())
        for i, model in enumerate(models, 1):
            info = AVAILABLE_MODELS[LLMProvider.OPENAI][model]
            print(f"  {i}. {info['name']} - {info['description']}")
        
        model_choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(models)}) [é»˜è®¤: 1]: ").strip() or '1'
        
        try:
            idx = int(model_choice) - 1
            selected_model = models[idx] if 0 <= idx < len(models) else models[0]
        except:
            selected_model = models[0]
        
        self.classification_mode = 'llm'
        self.llm_provider = 'openai'
        self.llm_model = selected_model
        
        try:
            self.llm_classifier = LLMClassifier(
                provider='openai',
                model=selected_model,
                api_key=api_key,
                enable_cache=True,
                max_workers=3
            )
            self._save_user_config()
            print(f"\nâœ… å·²åˆ‡æ¢åˆ°LLMæ¨¡å¼: OpenAI/{selected_model}")
        except Exception as e:
            print(f"\nâŒ åˆå§‹åŒ–LLMåˆ†ç±»å™¨å¤±è´¥: {e}")
            self.classification_mode = 'rule'
            self._save_user_config()
    
    def _setup_anthropic_mode(self):
        """è®¾ç½®Anthropicæ¨¡å¼"""
        api_key = os.getenv('ANTHROPIC_API_KEY')
        
        if not api_key:
            print("\nâš ï¸ æœªè®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
            api_key = input("è¯·è¾“å…¥Anthropic APIå¯†é’¥ (æˆ–æŒ‰Enterå–æ¶ˆ): ").strip()
            if not api_key:
                return
        
        print("\nå¯ç”¨çš„Anthropicæ¨¡å‹:")
        models = list(AVAILABLE_MODELS[LLMProvider.ANTHROPIC].keys())
        for i, model in enumerate(models, 1):
            info = AVAILABLE_MODELS[LLMProvider.ANTHROPIC][model]
            print(f"  {i}. {info['name']} - {info['description']}")
        
        model_choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(models)}) [é»˜è®¤: 1]: ").strip() or '1'
        
        try:
            idx = int(model_choice) - 1
            selected_model = models[idx] if 0 <= idx < len(models) else models[0]
        except:
            selected_model = models[0]
        
        self.classification_mode = 'llm'
        self.llm_provider = 'anthropic'
        self.llm_model = selected_model
        
        try:
            self.llm_classifier = LLMClassifier(
                provider='anthropic',
                model=selected_model,
                api_key=api_key,
                enable_cache=True,
                max_workers=3
            )
            self._save_user_config()
            print(f"\nâœ… å·²åˆ‡æ¢åˆ°LLMæ¨¡å¼: Anthropic/{selected_model}")
        except Exception as e:
            print(f"\nâŒ åˆå§‹åŒ–LLMåˆ†ç±»å™¨å¤±è´¥: {e}")
            self.classification_mode = 'rule'
            self._save_user_config()
    
    def _classify_data(self, items: list) -> list:
        """æ ¹æ®å½“å‰æ¨¡å¼åˆ†ç±»æ•°æ®"""
        if self.classification_mode == 'llm' and self.llm_classifier:
            print(f"\nğŸ¤– ä½¿ç”¨LLMåˆ†ç±» ({self.llm_provider}/{self.llm_model})")
            return self.llm_classifier.classify_batch(items)
        else:
            print("\nğŸ“ ä½¿ç”¨è§„åˆ™åˆ†ç±»")
            return self.classifier.classify_batch(items)
    
    def _collect_only(self):
        """ä»…é‡‡é›†æ•°æ®"""
        print("\nğŸ”„ å¼€å§‹æ•°æ®é‡‡é›†...\n")
        raw_data = self.collector.collect_all()
        
        all_items = []
        for items in raw_data.values():
            all_items.extend(items)
        
        self.data = self.classifier.classify_batch(all_items)
        print(f"\nâœ… é‡‡é›†å¹¶åˆ†ç±»å®Œæˆï¼å…± {len(self.data)} æ¡æ•°æ®")
    
    def _show_statistics(self):
        """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        print("\nğŸ“Š æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ:")
        print(f"   æ€»æ•°æ®é‡: {len(self.data)} æ¡")
        
        # å†…å®¹ç±»å‹ç»Ÿè®¡
        type_count = {}
        for item in self.data:
            ct = item.get('content_type', 'unknown')
            type_count[ct] = type_count.get(ct, 0) + 1
        
        print("\n   å†…å®¹ç±»å‹:")
        for ctype, count in type_count.items():
            print(f"   - {ctype}: {count} æ¡")
        
        # åœ°åŒºç»Ÿè®¡
        region_count = {}
        for item in self.data:
            region = item.get('region', 'unknown')
            region_count[region] = region_count.get(region, 0) + 1
        
        print("\n   åœ°åŒºåˆ†å¸ƒ:")
        for region, count in region_count.items():
            print(f"   - {region}: {count} æ¡")
    
    def _generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        if not self.trends:
            print("\nğŸ”„ æ­£åœ¨åˆ†ææ•°æ®...")
            self.trends = self.analyzer.analyze_trends(self.data)
        
        print("\nğŸ¨ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        self.chart_files = self.visualizer.visualize_all(self.trends)
    
    def _show_report(self):
        """æ˜¾ç¤ºåˆ†ææŠ¥å‘Š"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        if not self.trends:
            print("\nğŸ”„ æ­£åœ¨ç”Ÿæˆåˆ†æ...")
            self.trends = self.analyzer.analyze_trends(self.data)
        
        report = self.analyzer.generate_report(self.data, self.trends)
        print("\n" + report)
    
    def _filter_data(self):
        """æŒ‰æ¡ä»¶ç­›é€‰æ•°æ®"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        print("\nğŸ” æ•°æ®ç­›é€‰:")
        print("1. æŒ‰å†…å®¹ç±»å‹ (research/product/market)")
        print("2. æŒ‰åœ°åŒº (China/USA/Europe/Global)")
        print("3. æŒ‰æŠ€æœ¯é¢†åŸŸ")
        
        filter_choice = input("\né€‰æ‹©ç­›é€‰æ–¹å¼ (1-3): ").strip()
        
        if filter_choice == '1':
            ctype = input("è¾“å…¥å†…å®¹ç±»å‹ (research/product/market): ").strip()
            filtered = self.classifier.get_filtered_items(self.data, content_type=ctype)
        elif filter_choice == '2':
            region = input("è¾“å…¥åœ°åŒº (China/USA/Europe/Global): ").strip()
            filtered = self.classifier.get_filtered_items(self.data, region=region)
        elif filter_choice == '3':
            tech = input("è¾“å…¥æŠ€æœ¯é¢†åŸŸ (å¦‚: NLP, Computer Vision): ").strip()
            filtered = self.classifier.get_filtered_items(self.data, tech_category=tech)
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return
        
        print(f"\nâœ… ç­›é€‰ç»“æœ: {len(filtered)} æ¡æ•°æ®\n")
        
        # æ˜¾ç¤ºå‰5æ¡
        for i, item in enumerate(filtered[:5], 1):
            print(f"{i}. {item.get('title', 'No title')}")
            print(f"   ç±»å‹: {item.get('content_type')} | åœ°åŒº: {item.get('region')}")
            print(f"   æ¥æº: {item.get('source')} | æ—¥æœŸ: {item.get('published', 'N/A')}\n")
        
        if len(filtered) > 5:
            print(f"   ... è¿˜æœ‰ {len(filtered) - 5} æ¡ç»“æœ")
    
    def _generate_web_page(self):
        """ç”ŸæˆWebé¡µé¢"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        if not self.trends:
            print("\nğŸ”„ æ­£åœ¨ç”Ÿæˆåˆ†æ...")
            self.trends = self.analyzer.analyze_trends(self.data)
        
        if not self.chart_files:
            print("\nğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾è¡¨...")
            self.chart_files = self.visualizer.visualize_all(self.trends)
        
        print("\nğŸŒ æ­£åœ¨ç”ŸæˆWebé¡µé¢...")
        web_file = self.web_publisher.generate_html_page(self.data, self.trends, self.chart_files)
        
        # è¯¢é—®æ˜¯å¦åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
        try:
            import webbrowser
            choice = input("\næ˜¯å¦åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€Webé¡µé¢? (Y/N): ").strip().lower()
            if choice in ['y', 'yes', 'æ˜¯']:
                webbrowser.open(f'file://{os.path.abspath(web_file)}')
                print("ğŸš€ å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€Webé¡µé¢")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨: {e}")
            print(f"è¯·æ‰‹åŠ¨æ‰“å¼€æ–‡ä»¶: {os.path.abspath(web_file)}")
    
    def _manual_review(self):
        """äººå·¥å®¡æ ¸åˆ†ç±»"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        print("\n" + "="*60)
        print("ğŸ“ äººå·¥å®¡æ ¸æ¨¡å¼")
        print("="*60)
        
        # æ£€æŸ¥éœ€è¦å®¡æ ¸çš„å†…å®¹
        review_items = self.reviewer.get_items_for_review(self.data, min_confidence=0.6)
        
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»å†…å®¹æ•°: {len(self.data)} æ¡")
        print(f"   éœ€è¦å®¡æ ¸: {len(review_items)} æ¡ ({len(review_items)/len(self.data):.1%})")
        
        if not review_items:
            print("\nâœ… æ‰€æœ‰å†…å®¹åˆ†ç±»ç½®ä¿¡åº¦éƒ½å¾ˆé«˜ï¼Œæ— éœ€å®¡æ ¸ï¼")
            return
        
        # æ˜¾ç¤ºéœ€è¦å®¡æ ¸çš„å†…å®¹æ¦‚è§ˆ
        print("\néœ€è¦å®¡æ ¸çš„å†…å®¹:")
        for i, item in enumerate(review_items[:5], 1):
            print(f"   {i}. {item.get('title', 'N/A')[:50]}... (ç½®ä¿¡åº¦: {item.get('confidence', 0):.1%})")
        
        if len(review_items) > 5:
            print(f"   ... è¿˜æœ‰ {len(review_items)-5} æ¡")
        
        print("\nå®¡æ ¸é€‰é¡¹:")
        print("   1. æ‰¹é‡å®¡æ ¸æ‰€æœ‰ä½ç½®ä¿¡åº¦å†…å®¹")
        print("   2. è®¾ç½®è‡ªå®šä¹‰ç½®ä¿¡åº¦é˜ˆå€¼")
        print("   3. ä»…æŸ¥çœ‹éœ€è¦å®¡æ ¸çš„å†…å®¹åˆ—è¡¨")
        print("   0. è¿”å›ä¸»èœå•")
        
        choice = input("\nè¯·é€‰æ‹© (0-3): ").strip()
        
        if choice == '1':
            # æ‰¹é‡å®¡æ ¸
            self.data = self.reviewer.batch_review(self.data, min_confidence=0.6)
            
            # ä¿å­˜å®¡æ ¸åçš„æ•°æ®
            save = input("\næ˜¯å¦ä¿å­˜å®¡æ ¸åçš„æ•°æ®? (Y/N): ").strip().lower()
            if save == 'y':
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f'ai_tracker_data_reviewed_{timestamp}.json'
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump({
                        'metadata': {
                            'timestamp': timestamp,
                            'total_items': len(self.data),
                            'reviewed': True
                        },
                        'data': self.data,
                        'trends': self.trends
                    }, f, ensure_ascii=False, indent=2)
                print(f"âœ… å·²ä¿å­˜åˆ°: {filename}")
            
            # ä¿å­˜å®¡æ ¸å†å²
            self.reviewer.save_review_history()
            
            # æ˜¾ç¤ºå®¡æ ¸æ‘˜è¦
            summary = self.reviewer.get_review_summary()
            print(f"\nğŸ“Š å®¡æ ¸æ‘˜è¦:")
            print(f"   æ€»å®¡æ ¸æ•°: {summary['total']} æ¡")
            for action, count in summary['actions'].items():
                print(f"   - {action}: {count} æ¬¡")
            
            # è¯¢é—®æ˜¯å¦é‡æ–°ç”Ÿæˆåˆ†æå’ŒWebé¡µé¢
            print("\n" + "="*60)
            regenerate = input("\næ˜¯å¦åŸºäºå®¡æ ¸åçš„æ•°æ®é‡æ–°ç”ŸæˆæŠ¥å‘Šå’ŒWebé¡µé¢? (Y/N): ").strip().lower()
            if regenerate == 'y':
                self._regenerate_after_review()
        
        elif choice == '2':
            # è‡ªå®šä¹‰é˜ˆå€¼
            try:
                threshold = float(input("\nè¯·è¾“å…¥ç½®ä¿¡åº¦é˜ˆå€¼ (0.0-1.0, å¦‚ 0.7): ").strip())
                if 0 <= threshold <= 1:
                    self.data = self.reviewer.batch_review(self.data, min_confidence=threshold)
                else:
                    print("âŒ é˜ˆå€¼å¿…é¡»åœ¨ 0.0-1.0 ä¹‹é—´")
            except ValueError:
                print("âŒ æ— æ•ˆè¾“å…¥")
        
        elif choice == '3':
            # ä»…æŸ¥çœ‹åˆ—è¡¨
            print("\n" + "="*70)
            print("éœ€è¦å®¡æ ¸çš„å†…å®¹åˆ—è¡¨:")
            print("="*70)
            for i, item in enumerate(review_items, 1):
                print(f"\n[{i}] {item.get('title', 'N/A')}")
                print(f"    åˆ†ç±»: {item.get('content_type')} | ç½®ä¿¡åº¦: {item.get('confidence', 0):.1%}")
                print(f"    æ¥æº: {item.get('source', 'N/A')}")
        
        elif choice == '0':
            return
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    
    def _regenerate_after_review(self):
        """å®¡æ ¸åé‡æ–°ç”Ÿæˆåˆ†æå’ŒWebé¡µé¢"""
        print("\n" + "="*60)
        print("ğŸ”„ é‡æ–°ç”ŸæˆæŠ¥å‘Šå’Œå¯è§†åŒ–")
        print("="*60)
        
        try:
            # æ­¥éª¤1: é‡æ–°åˆ†æ
            print("\nã€1/3ã€‘é‡æ–°åˆ†æè¶‹åŠ¿...")
            self.trends = self.analyzer.analyze_trends(self.data)
            
            # æ­¥éª¤2: é‡æ–°ç”Ÿæˆå›¾è¡¨
            print("ã€2/3ã€‘é‡æ–°ç”Ÿæˆå›¾è¡¨...")
            self.chart_files = self.visualizer.visualize_all(self.trends)
            
            # æ­¥éª¤3: é‡æ–°ç”ŸæˆWebé¡µé¢
            print("ã€3/3ã€‘é‡æ–°ç”ŸæˆWebé¡µé¢...")
            web_file = self.web_publisher.generate_html_page(self.data, self.trends, self.chart_files)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.analyzer.generate_report(self.data, self.trends)
            
            # ä¿å­˜ï¼ˆä½¿ç”¨reviewedæ ‡è®°ï¼‰
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            data_file = f'ai_tracker_data_reviewed_{timestamp}.json'
            with open(data_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'metadata': {
                        'timestamp': timestamp,
                        'total_items': len(self.data),
                        'reviewed': True
                    },
                    'data': self.data,
                    'trends': self.trends
                }, f, ensure_ascii=False, indent=2)
            
            report_file = f'ai_tracker_report_reviewed_{timestamp}.txt'
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print("\nâœ… é‡æ–°ç”Ÿæˆå®Œæˆï¼")
            print(f"   æ•°æ®æ–‡ä»¶: {data_file}")
            print(f"   æŠ¥å‘Šæ–‡ä»¶: {report_file}")
            print(f"   Webé¡µé¢: {web_file}")
            
            # è¯¢é—®æ˜¯å¦æ‰“å¼€
            import webbrowser
            choice = input("\næ˜¯å¦åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ›´æ–°åçš„Webé¡µé¢? (Y/N): ").strip().lower()
            if choice == 'y':
                webbrowser.open(f'file://{os.path.abspath(web_file)}')
                print("ğŸš€ å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€")
        
        except Exception as e:
            print(f"\nâŒ é‡æ–°ç”Ÿæˆå¤±è´¥: {e}")
    
    def _learning_feedback(self):
        """å­¦ä¹ åé¦ˆåˆ†æ"""
        print("\n" + "="*60)
        print("ğŸ“ å­¦ä¹ åé¦ˆç³»ç»Ÿ")
        print("="*60)
        
        # æŸ¥æ‰¾å®¡æ ¸å†å²æ–‡ä»¶å’Œå®¡æ ¸åæ•°æ®æ–‡ä»¶
        import glob
        
        review_files = sorted(glob.glob('review_history_*.json'), reverse=True)
        data_files = sorted(glob.glob('ai_tracker_data_reviewed_*.json'), reverse=True)
        
        if not review_files:
            print("\nâš ï¸ æœªæ‰¾åˆ°å®¡æ ¸å†å²æ–‡ä»¶")
            print("è¯·å…ˆå®Œæˆäººå·¥å®¡æ ¸ï¼ˆèœå•é€‰é¡¹5ï¼‰")
            return
        
        if not data_files:
            print("\nâš ï¸ æœªæ‰¾åˆ°å®¡æ ¸åçš„æ•°æ®æ–‡ä»¶")
            print("è¯·å…ˆå®Œæˆäººå·¥å®¡æ ¸å¹¶ä¿å­˜æ•°æ®")
            return
        
        print(f"\nğŸ“ æ‰¾åˆ°å®¡æ ¸è®°å½•:")
        print(f"   å®¡æ ¸å†å²: {len(review_files)} ä¸ªæ–‡ä»¶")
        print(f"   å®¡æ ¸æ•°æ®: {len(data_files)} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºæœ€è¿‘çš„æ–‡ä»¶
        print(f"\næœ€è¿‘çš„å®¡æ ¸:")
        for i, (review_file, data_file) in enumerate(zip(review_files[:3], data_files[:3]), 1):
            print(f"   {i}. {review_file}")
        
        print("\né€‰é¡¹:")
        print("   1. åˆ†ææœ€è¿‘ä¸€æ¬¡å®¡æ ¸")
        print("   2. é€‰æ‹©ç‰¹å®šå®¡æ ¸æ–‡ä»¶")
        print("   0. è¿”å›")
        
        choice = input("\nè¯·é€‰æ‹© (0-2): ").strip()
        
        if choice == '1':
            # åˆ†ææœ€è¿‘ä¸€æ¬¡
            review_file = review_files[0]
            data_file = data_files[0]
            
            print(f"\nğŸ“Š æ­£åœ¨åˆ†æ: {review_file}")
            
            try:
                report_file = create_feedback_loop(
                    review_file,
                    data_file,
                    self.classifier
                )
                
                print(f"\nâœ… å­¦ä¹ åˆ†æå®Œæˆï¼")
                print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
                
                # è¯¢é—®æ˜¯å¦æŸ¥çœ‹å»ºè®®
                view = input("\næ˜¯å¦æŸ¥çœ‹æ”¹è¿›å»ºè®®? (Y/N): ").strip().lower()
                if view == 'y':
                    self._show_improvement_suggestions(report_file)
                
            except Exception as e:
                print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        
        elif choice == '2':
            # é€‰æ‹©ç‰¹å®šæ–‡ä»¶
            print("\nå¯ç”¨çš„å®¡æ ¸å†å²æ–‡ä»¶:")
            for i, file in enumerate(review_files, 1):
                print(f"   {i}. {file}")
            
            try:
                idx = int(input("\né€‰æ‹©æ–‡ä»¶ç¼–å·: ").strip()) - 1
                if 0 <= idx < len(review_files):
                    review_file = review_files[idx]
                    data_file = data_files[idx] if idx < len(data_files) else data_files[0]
                    
                    report_file = create_feedback_loop(
                        review_file,
                        data_file,
                        self.classifier
                    )
                    
                    print(f"\nâœ… å­¦ä¹ åˆ†æå®Œæˆï¼æŠ¥å‘Š: {report_file}")
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
            except (ValueError, IndexError) as e:
                print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
        
        elif choice == '0':
            return
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    
    def _show_improvement_suggestions(self, report_file: str):
        """æ˜¾ç¤ºæ”¹è¿›å»ºè®®"""
        try:
            with open(report_file, 'r', encoding='utf-8') as f:
                report = json.load(f)
            
            suggestions = report.get('improvement_suggestions', [])
            
            if not suggestions:
                print("\nâœ… å½“å‰åˆ†ç±»å™¨è¡¨ç°è‰¯å¥½ï¼Œæš‚æ— æ”¹è¿›å»ºè®®")
                return
            
            print("\n" + "="*70)
            print("ğŸ’¡ æ”¹è¿›å»ºè®®è¯¦æƒ…")
            print("="*70)
            
            for i, sug in enumerate(suggestions, 1):
                print(f"\nå»ºè®® {i}:")
                print(f"   ç±»å‹: {sug.get('type')}")
                
                if sug.get('category'):
                    print(f"   åˆ†ç±»: {sug.get('category')}")
                
                if sug.get('issue'):
                    print(f"   é—®é¢˜: {sug.get('issue')}")
                
                if sug.get('suggestion'):
                    print(f"   å»ºè®®: {sug.get('suggestion')}")
                
                if sug.get('keywords'):
                    keywords_str = ', '.join(sug['keywords'])
                    print(f"   å»ºè®®æ·»åŠ å…³é”®è¯: {keywords_str}")
                
                if sug.get('severity'):
                    print(f"   ä¸¥é‡ç¨‹åº¦: {sug.get('severity')}")
            
            print("\n" + "="*70)
            print("ğŸ“ è¯´æ˜:")
            print("   è¿™äº›å»ºè®®åŸºäºäººå·¥å®¡æ ¸ç»“æœè‡ªåŠ¨ç”Ÿæˆ")
            print("   å¯ä»¥æ‰‹åŠ¨ç¼–è¾‘ content_classifier.py åº”ç”¨è¿™äº›æ”¹è¿›")
            print("="*70)
            
        except Exception as e:
            print(f"âŒ è¯»å–æŠ¥å‘Šå¤±è´¥: {e}")
    
    def _save_results(self, report: str, web_file: Optional[str] = None):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜JSONæ•°æ®
        data_file = f'ai_tracker_data_{timestamp}.json'
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'timestamp': timestamp,
                    'total_items': len(self.data)
                },
                'data': self.data,
                'trends': self.trends
            }, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {data_file}")
        
        # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
        report_file = f'ai_tracker_report_{timestamp}.txt'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        if web_file:
            print(f"ğŸŒ Webé¡µé¢å·²ç”Ÿæˆ: {web_file}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        tracker = AIWorldTracker()
        
        # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
        if len(sys.argv) > 1:
            if sys.argv[1] == '--auto':
                # è‡ªåŠ¨è¿è¡Œå®Œæ•´æµç¨‹
                tracker.run_full_pipeline()
            elif sys.argv[1] == '--help':
                print("\nAI World Tracker - ä½¿ç”¨è¯´æ˜")
                print("\nå‚æ•°:")
                print("  --auto    è‡ªåŠ¨è¿è¡Œå®Œæ•´æµç¨‹")
                print("  --help    æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
                print("\næ— å‚æ•°:     è¿›å…¥äº¤äº’å¼èœå•\n")
        else:
            # äº¤äº’å¼èœå•
            tracker.show_menu()
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

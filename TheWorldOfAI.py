"""
AI World Tracker - MVPç‰ˆæœ¬
å…¨çƒAIç ”ç©¶ã€äº§å“ã€å¸‚åœºåŠ¨æ€è¿½è¸ªåº”ç”¨

ä¸»è¦åŠŸèƒ½:
1. æ•°æ®é‡‡é›†æ¨¡å— - ä»arXivã€GitHubã€RSSç­‰æºé‡‡é›†AIèµ„è®¯
2. å†…å®¹åˆ†ç±»ç³»ç»Ÿ - è‡ªåŠ¨åˆ†ç±»ä¸ºç ”ç©¶/äº§å“/å¸‚åœºç»´åº¦
3. æ™ºèƒ½åˆ†æåŠŸèƒ½ - ç”Ÿæˆè¶‹åŠ¿åˆ†æå’Œæ´å¯ŸæŠ¥å‘Š
4. æ•°æ®å¯è§†åŒ– - ç”Ÿæˆå„ç±»å›¾è¡¨å±•ç¤ºæ•°æ®

ä½œè€…: AI World Tracker Team
æ—¥æœŸ: 2025-12-01
"""

import sys
import json
import os
from datetime import datetime
from typing import Optional

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_collector import DataCollector
from content_classifier import ContentClassifier
from ai_analyzer import AIAnalyzer
from visualizer import DataVisualizer
from web_publisher import WebPublisher
from manual_reviewer import ManualReviewer
from learning_feedback import LearningFeedback, create_feedback_loop


class AIWorldTracker:
    """AIä¸–ç•Œè¿½è¸ªå™¨ä¸»åº”ç”¨"""
    
    def __init__(self):
        print("\n" + "="*60)
        print("     ğŸŒ AI World Tracker - MVP ç‰ˆæœ¬")
        print("     å…¨çƒäººå·¥æ™ºèƒ½åŠ¨æ€è¿½è¸ªç³»ç»Ÿ")
        print("="*60 + "\n")
        
        self.collector = DataCollector()
        self.classifier = ContentClassifier()
        self.analyzer = AIAnalyzer()
        self.visualizer = DataVisualizer()
        self.web_publisher = WebPublisher()
        self.reviewer = ManualReviewer()
        self.learner = LearningFeedback()
        
        self.data = []
        self.trends = {}
        self.chart_files = {}
        
        # å°è¯•åŠ è½½æœ€æ–°æ•°æ®
        self._load_latest_data()
    
    def _load_latest_data(self):
        """å°è¯•åŠ è½½æœ€æ–°çš„æ•°æ®æ–‡ä»¶"""
        try:
            files = [f for f in os.listdir('.') if f.startswith('ai_tracker_data_') and f.endswith('.json')]
            if not files:
                return
            
            latest_file = max(files)
            print(f"ğŸ“¥ å‘ç°å†å²æ•°æ®ï¼Œæ­£åœ¨åŠ è½½: {latest_file}...")
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
                
            self.data = saved_data.get('data', [])
            self.trends = saved_data.get('trends', {})
            
            # å°è¯•åŠ è½½å›¾è¡¨æ–‡ä»¶
            if os.path.exists('visualizations'):
                self.chart_files = {
                    'tech_hotspots': os.path.join('visualizations', 'tech_hotspots.png'),
                    'content_distribution': os.path.join('visualizations', 'content_distribution.png'),
                    'region_distribution': os.path.join('visualizations', 'region_distribution.png'),
                    'daily_trends': os.path.join('visualizations', 'daily_trends.png'),
                    'dashboard': os.path.join('visualizations', 'dashboard.png')
                }
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                self.chart_files = {k: v for k, v in self.chart_files.items() if os.path.exists(v)}
            
            print(f"âœ… å·²åŠ è½½ {len(self.data)} æ¡å†å²æ•°æ®")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å†å²æ•°æ®å¤±è´¥: {e}")
    
    def run_full_pipeline(self):
        """è¿è¡Œå®Œæ•´æ•°æ®å¤„ç†æµç¨‹"""
        print("ğŸš€ å¯åŠ¨å®Œæ•´æ•°æ®å¤„ç†æµç¨‹...\n")
        
        # æ­¥éª¤1: æ•°æ®é‡‡é›†
        print("ã€æ­¥éª¤ 1/4ã€‘æ•°æ®é‡‡é›†")
        raw_data = self.collector.collect_all()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        all_items = []
        for category, items in raw_data.items():
            all_items.extend(items)
        
        print(f"\nğŸ“¦ å…±é‡‡é›† {len(all_items)} æ¡åŸå§‹æ•°æ®\n")
        
        # æ­¥éª¤2: å†…å®¹åˆ†ç±»
        print("ã€æ­¥éª¤ 2/4ã€‘å†…å®¹åˆ†ç±»")
        self.data = self.classifier.classify_batch(all_items)
        
        # æ­¥éª¤3: æ™ºèƒ½åˆ†æ
        print("\nã€æ­¥éª¤ 3/4ã€‘æ™ºèƒ½åˆ†æ")
        self.trends = self.analyzer.analyze_trends(self.data)
        
        # æ­¥éª¤4: æ•°æ®å¯è§†åŒ–
        print("\nã€æ­¥éª¤ 4/4ã€‘æ•°æ®å¯è§†åŒ–")
        self.chart_files = self.visualizer.visualize_all(self.trends)
        
        # æ­¥éª¤5: ç”ŸæˆWebé¡µé¢
        print("\nã€æ­¥éª¤ 5/5ã€‘ç”ŸæˆWebé¡µé¢")
        web_file = self.web_publisher.generate_html_page(self.data, self.trends, self.chart_files)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.analyzer.generate_report(self.data, self.trends)
        
        # ä¿å­˜æ•°æ®å’ŒæŠ¥å‘Š
        self._save_results(report, web_file)
        
        print("\n" + "="*60)
        print("âœ¨ å¤„ç†å®Œæˆï¼")
        print("="*60)
        print(f"\nğŸ“Š å·²ç”Ÿæˆ {len([f for f in self.chart_files.values() if f])} ä¸ªå¯è§†åŒ–å›¾è¡¨")
        print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜")
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° JSON æ–‡ä»¶")
        print(f"ğŸŒ Webé¡µé¢å·²ç”Ÿæˆ\n")
        
        return report
    
    def show_menu(self):
        """æ˜¾ç¤ºäº¤äº’èœå•"""
        while True:
            print("\n" + "="*60)
            print("ğŸ“‹ ä¸»èœå•")
            print("="*60)
            print("1. ğŸš€ ä¸€é”®æ›´æ–°æ•°æ®ä¸æŠ¥å‘Š (Update & Generate All)")
            print("2. ğŸ“„ æŸ¥çœ‹åˆ†ææŠ¥å‘Š (View Report)")
            print("3. ğŸ” æœç´¢ä¸ç­›é€‰ (Search & Filter)")
            print("4. ğŸŒ ç”Ÿæˆå¹¶æ‰“å¼€ Web é¡µé¢ (Generate & Open Web Page)")
            print("5. ğŸ“ äººå·¥å®¡æ ¸åˆ†ç±» (Manual Review) â­ æ–°åŠŸèƒ½")
            print("6. ğŸ“ å­¦ä¹ åé¦ˆåˆ†æ (Learning Feedback) â­ æ–°åŠŸèƒ½")
            print("0. é€€å‡ºç¨‹åº")
            print("="*60)
            
            choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (0-6): ").strip()
            
            if choice == '1':
                self.run_full_pipeline()
            elif choice == '2':
                self._show_report()
            elif choice == '3':
                self._filter_data()
            elif choice == '4':
                self._generate_web_page()
            elif choice == '5':
                self._manual_review()
            elif choice == '6':
                self._learning_feedback()
            elif choice == '0':
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ AI World Trackerï¼å†è§ï¼\n")
                break
            else:
                print("\nâŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
    
    def _collect_only(self):
        """ä»…é‡‡é›†æ•°æ®"""
        print("\nğŸ”„ å¼€å§‹æ•°æ®é‡‡é›†...\n")
        raw_data = self.collector.collect_all()
        
        all_items = []
        for items in raw_data.values():
            all_items.extend(items)
        
        self.data = self.classifier.classify_batch(all_items)
        print(f"\nâœ… é‡‡é›†å¹¶åˆ†ç±»å®Œæˆï¼å…± {len(self.data)} æ¡æ•°æ®")
    
    def _show_statistics(self):
        """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        print("\nğŸ“Š æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ:")
        print(f"   æ€»æ•°æ®é‡: {len(self.data)} æ¡")
        
        # å†…å®¹ç±»å‹ç»Ÿè®¡
        type_count = {}
        for item in self.data:
            ct = item.get('content_type', 'unknown')
            type_count[ct] = type_count.get(ct, 0) + 1
        
        print("\n   å†…å®¹ç±»å‹:")
        for ctype, count in type_count.items():
            print(f"   - {ctype}: {count} æ¡")
        
        # åœ°åŒºç»Ÿè®¡
        region_count = {}
        for item in self.data:
            region = item.get('region', 'unknown')
            region_count[region] = region_count.get(region, 0) + 1
        
        print("\n   åœ°åŒºåˆ†å¸ƒ:")
        for region, count in region_count.items():
            print(f"   - {region}: {count} æ¡")
    
    def _generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        if not self.trends:
            print("\nğŸ”„ æ­£åœ¨åˆ†ææ•°æ®...")
            self.trends = self.analyzer.analyze_trends(self.data)
        
        print("\nğŸ¨ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        self.chart_files = self.visualizer.visualize_all(self.trends)
    
    def _show_report(self):
        """æ˜¾ç¤ºåˆ†ææŠ¥å‘Š"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        if not self.trends:
            print("\nğŸ”„ æ­£åœ¨ç”Ÿæˆåˆ†æ...")
            self.trends = self.analyzer.analyze_trends(self.data)
        
        report = self.analyzer.generate_report(self.data, self.trends)
        print("\n" + report)
    
    def _filter_data(self):
        """æŒ‰æ¡ä»¶ç­›é€‰æ•°æ®"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        print("\nğŸ” æ•°æ®ç­›é€‰:")
        print("1. æŒ‰å†…å®¹ç±»å‹ (research/product/market)")
        print("2. æŒ‰åœ°åŒº (China/USA/Europe/Global)")
        print("3. æŒ‰æŠ€æœ¯é¢†åŸŸ")
        
        filter_choice = input("\né€‰æ‹©ç­›é€‰æ–¹å¼ (1-3): ").strip()
        
        if filter_choice == '1':
            ctype = input("è¾“å…¥å†…å®¹ç±»å‹ (research/product/market): ").strip()
            filtered = self.classifier.get_filtered_items(self.data, content_type=ctype)
        elif filter_choice == '2':
            region = input("è¾“å…¥åœ°åŒº (China/USA/Europe/Global): ").strip()
            filtered = self.classifier.get_filtered_items(self.data, region=region)
        elif filter_choice == '3':
            tech = input("è¾“å…¥æŠ€æœ¯é¢†åŸŸ (å¦‚: NLP, Computer Vision): ").strip()
            filtered = self.classifier.get_filtered_items(self.data, tech_category=tech)
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return
        
        print(f"\nâœ… ç­›é€‰ç»“æœ: {len(filtered)} æ¡æ•°æ®\n")
        
        # æ˜¾ç¤ºå‰5æ¡
        for i, item in enumerate(filtered[:5], 1):
            print(f"{i}. {item.get('title', 'No title')}")
            print(f"   ç±»å‹: {item.get('content_type')} | åœ°åŒº: {item.get('region')}")
            print(f"   æ¥æº: {item.get('source')} | æ—¥æœŸ: {item.get('published', 'N/A')}\n")
        
        if len(filtered) > 5:
            print(f"   ... è¿˜æœ‰ {len(filtered) - 5} æ¡ç»“æœ")
    
    def _generate_web_page(self):
        """ç”ŸæˆWebé¡µé¢"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        if not self.trends:
            print("\nğŸ”„ æ­£åœ¨ç”Ÿæˆåˆ†æ...")
            self.trends = self.analyzer.analyze_trends(self.data)
        
        if not self.chart_files:
            print("\nğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾è¡¨...")
            self.chart_files = self.visualizer.visualize_all(self.trends)
        
        print("\nğŸŒ æ­£åœ¨ç”ŸæˆWebé¡µé¢...")
        web_file = self.web_publisher.generate_html_page(self.data, self.trends, self.chart_files)
        
        # è¯¢é—®æ˜¯å¦åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
        try:
            import webbrowser
            choice = input("\næ˜¯å¦åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€Webé¡µé¢? (Y/N): ").strip().lower()
            if choice in ['y', 'yes', 'æ˜¯']:
                webbrowser.open(f'file://{os.path.abspath(web_file)}')
                print("ğŸš€ å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€Webé¡µé¢")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨: {e}")
            print(f"è¯·æ‰‹åŠ¨æ‰“å¼€æ–‡ä»¶: {os.path.abspath(web_file)}")
    
    def _manual_review(self):
        """äººå·¥å®¡æ ¸åˆ†ç±»"""
        if not self.data:
            print("\nâš ï¸ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
            return
        
        print("\n" + "="*60)
        print("ğŸ“ äººå·¥å®¡æ ¸æ¨¡å¼")
        print("="*60)
        
        # æ£€æŸ¥éœ€è¦å®¡æ ¸çš„å†…å®¹
        review_items = self.reviewer.get_items_for_review(self.data, min_confidence=0.6)
        
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»å†…å®¹æ•°: {len(self.data)} æ¡")
        print(f"   éœ€è¦å®¡æ ¸: {len(review_items)} æ¡ ({len(review_items)/len(self.data):.1%})")
        
        if not review_items:
            print("\nâœ… æ‰€æœ‰å†…å®¹åˆ†ç±»ç½®ä¿¡åº¦éƒ½å¾ˆé«˜ï¼Œæ— éœ€å®¡æ ¸ï¼")
            return
        
        # æ˜¾ç¤ºéœ€è¦å®¡æ ¸çš„å†…å®¹æ¦‚è§ˆ
        print("\néœ€è¦å®¡æ ¸çš„å†…å®¹:")
        for i, item in enumerate(review_items[:5], 1):
            print(f"   {i}. {item.get('title', 'N/A')[:50]}... (ç½®ä¿¡åº¦: {item.get('confidence', 0):.1%})")
        
        if len(review_items) > 5:
            print(f"   ... è¿˜æœ‰ {len(review_items)-5} æ¡")
        
        print("\nå®¡æ ¸é€‰é¡¹:")
        print("   1. æ‰¹é‡å®¡æ ¸æ‰€æœ‰ä½ç½®ä¿¡åº¦å†…å®¹")
        print("   2. è®¾ç½®è‡ªå®šä¹‰ç½®ä¿¡åº¦é˜ˆå€¼")
        print("   3. ä»…æŸ¥çœ‹éœ€è¦å®¡æ ¸çš„å†…å®¹åˆ—è¡¨")
        print("   0. è¿”å›ä¸»èœå•")
        
        choice = input("\nè¯·é€‰æ‹© (0-3): ").strip()
        
        if choice == '1':
            # æ‰¹é‡å®¡æ ¸
            self.data = self.reviewer.batch_review(self.data, min_confidence=0.6)
            
            # ä¿å­˜å®¡æ ¸åçš„æ•°æ®
            save = input("\næ˜¯å¦ä¿å­˜å®¡æ ¸åçš„æ•°æ®? (Y/N): ").strip().lower()
            if save == 'y':
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f'ai_tracker_data_reviewed_{timestamp}.json'
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump({
                        'metadata': {
                            'timestamp': timestamp,
                            'total_items': len(self.data),
                            'reviewed': True
                        },
                        'data': self.data,
                        'trends': self.trends
                    }, f, ensure_ascii=False, indent=2)
                print(f"âœ… å·²ä¿å­˜åˆ°: {filename}")
            
            # ä¿å­˜å®¡æ ¸å†å²
            self.reviewer.save_review_history()
            
            # æ˜¾ç¤ºå®¡æ ¸æ‘˜è¦
            summary = self.reviewer.get_review_summary()
            print(f"\nğŸ“Š å®¡æ ¸æ‘˜è¦:")
            print(f"   æ€»å®¡æ ¸æ•°: {summary['total']} æ¡")
            for action, count in summary['actions'].items():
                print(f"   - {action}: {count} æ¬¡")
            
            # è¯¢é—®æ˜¯å¦é‡æ–°ç”Ÿæˆåˆ†æå’ŒWebé¡µé¢
            print("\n" + "="*60)
            regenerate = input("\næ˜¯å¦åŸºäºå®¡æ ¸åçš„æ•°æ®é‡æ–°ç”ŸæˆæŠ¥å‘Šå’ŒWebé¡µé¢? (Y/N): ").strip().lower()
            if regenerate == 'y':
                self._regenerate_after_review()
        
        elif choice == '2':
            # è‡ªå®šä¹‰é˜ˆå€¼
            try:
                threshold = float(input("\nè¯·è¾“å…¥ç½®ä¿¡åº¦é˜ˆå€¼ (0.0-1.0, å¦‚ 0.7): ").strip())
                if 0 <= threshold <= 1:
                    self.data = self.reviewer.batch_review(self.data, min_confidence=threshold)
                else:
                    print("âŒ é˜ˆå€¼å¿…é¡»åœ¨ 0.0-1.0 ä¹‹é—´")
            except ValueError:
                print("âŒ æ— æ•ˆè¾“å…¥")
        
        elif choice == '3':
            # ä»…æŸ¥çœ‹åˆ—è¡¨
            print("\n" + "="*70)
            print("éœ€è¦å®¡æ ¸çš„å†…å®¹åˆ—è¡¨:")
            print("="*70)
            for i, item in enumerate(review_items, 1):
                print(f"\n[{i}] {item.get('title', 'N/A')}")
                print(f"    åˆ†ç±»: {item.get('content_type')} | ç½®ä¿¡åº¦: {item.get('confidence', 0):.1%}")
                print(f"    æ¥æº: {item.get('source', 'N/A')}")
        
        elif choice == '0':
            return
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    
    def _regenerate_after_review(self):
        """å®¡æ ¸åé‡æ–°ç”Ÿæˆåˆ†æå’ŒWebé¡µé¢"""
        print("\n" + "="*60)
        print("ğŸ”„ é‡æ–°ç”ŸæˆæŠ¥å‘Šå’Œå¯è§†åŒ–")
        print("="*60)
        
        try:
            # æ­¥éª¤1: é‡æ–°åˆ†æ
            print("\nã€1/3ã€‘é‡æ–°åˆ†æè¶‹åŠ¿...")
            self.trends = self.analyzer.analyze_trends(self.data)
            
            # æ­¥éª¤2: é‡æ–°ç”Ÿæˆå›¾è¡¨
            print("ã€2/3ã€‘é‡æ–°ç”Ÿæˆå›¾è¡¨...")
            self.chart_files = self.visualizer.visualize_all(self.trends)
            
            # æ­¥éª¤3: é‡æ–°ç”ŸæˆWebé¡µé¢
            print("ã€3/3ã€‘é‡æ–°ç”ŸæˆWebé¡µé¢...")
            web_file = self.web_publisher.generate_html_page(self.data, self.trends, self.chart_files)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.analyzer.generate_report(self.data, self.trends)
            
            # ä¿å­˜ï¼ˆä½¿ç”¨reviewedæ ‡è®°ï¼‰
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            data_file = f'ai_tracker_data_reviewed_{timestamp}.json'
            with open(data_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'metadata': {
                        'timestamp': timestamp,
                        'total_items': len(self.data),
                        'reviewed': True
                    },
                    'data': self.data,
                    'trends': self.trends
                }, f, ensure_ascii=False, indent=2)
            
            report_file = f'ai_tracker_report_reviewed_{timestamp}.txt'
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print("\nâœ… é‡æ–°ç”Ÿæˆå®Œæˆï¼")
            print(f"   æ•°æ®æ–‡ä»¶: {data_file}")
            print(f"   æŠ¥å‘Šæ–‡ä»¶: {report_file}")
            print(f"   Webé¡µé¢: {web_file}")
            
            # è¯¢é—®æ˜¯å¦æ‰“å¼€
            import webbrowser
            choice = input("\næ˜¯å¦åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ›´æ–°åçš„Webé¡µé¢? (Y/N): ").strip().lower()
            if choice == 'y':
                webbrowser.open(f'file://{os.path.abspath(web_file)}')
                print("ğŸš€ å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€")
        
        except Exception as e:
            print(f"\nâŒ é‡æ–°ç”Ÿæˆå¤±è´¥: {e}")
    
    def _learning_feedback(self):
        """å­¦ä¹ åé¦ˆåˆ†æ"""
        print("\n" + "="*60)
        print("ğŸ“ å­¦ä¹ åé¦ˆç³»ç»Ÿ")
        print("="*60)
        
        # æŸ¥æ‰¾å®¡æ ¸å†å²æ–‡ä»¶å’Œå®¡æ ¸åæ•°æ®æ–‡ä»¶
        import glob
        
        review_files = sorted(glob.glob('review_history_*.json'), reverse=True)
        data_files = sorted(glob.glob('ai_tracker_data_reviewed_*.json'), reverse=True)
        
        if not review_files:
            print("\nâš ï¸ æœªæ‰¾åˆ°å®¡æ ¸å†å²æ–‡ä»¶")
            print("è¯·å…ˆå®Œæˆäººå·¥å®¡æ ¸ï¼ˆèœå•é€‰é¡¹5ï¼‰")
            return
        
        if not data_files:
            print("\nâš ï¸ æœªæ‰¾åˆ°å®¡æ ¸åçš„æ•°æ®æ–‡ä»¶")
            print("è¯·å…ˆå®Œæˆäººå·¥å®¡æ ¸å¹¶ä¿å­˜æ•°æ®")
            return
        
        print(f"\nğŸ“ æ‰¾åˆ°å®¡æ ¸è®°å½•:")
        print(f"   å®¡æ ¸å†å²: {len(review_files)} ä¸ªæ–‡ä»¶")
        print(f"   å®¡æ ¸æ•°æ®: {len(data_files)} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºæœ€è¿‘çš„æ–‡ä»¶
        print(f"\næœ€è¿‘çš„å®¡æ ¸:")
        for i, (review_file, data_file) in enumerate(zip(review_files[:3], data_files[:3]), 1):
            print(f"   {i}. {review_file}")
        
        print("\né€‰é¡¹:")
        print("   1. åˆ†ææœ€è¿‘ä¸€æ¬¡å®¡æ ¸")
        print("   2. é€‰æ‹©ç‰¹å®šå®¡æ ¸æ–‡ä»¶")
        print("   0. è¿”å›")
        
        choice = input("\nè¯·é€‰æ‹© (0-2): ").strip()
        
        if choice == '1':
            # åˆ†ææœ€è¿‘ä¸€æ¬¡
            review_file = review_files[0]
            data_file = data_files[0]
            
            print(f"\nğŸ“Š æ­£åœ¨åˆ†æ: {review_file}")
            
            try:
                report_file = create_feedback_loop(
                    review_file,
                    data_file,
                    self.classifier
                )
                
                print(f"\nâœ… å­¦ä¹ åˆ†æå®Œæˆï¼")
                print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
                
                # è¯¢é—®æ˜¯å¦æŸ¥çœ‹å»ºè®®
                view = input("\næ˜¯å¦æŸ¥çœ‹æ”¹è¿›å»ºè®®? (Y/N): ").strip().lower()
                if view == 'y':
                    self._show_improvement_suggestions(report_file)
                
            except Exception as e:
                print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        
        elif choice == '2':
            # é€‰æ‹©ç‰¹å®šæ–‡ä»¶
            print("\nå¯ç”¨çš„å®¡æ ¸å†å²æ–‡ä»¶:")
            for i, file in enumerate(review_files, 1):
                print(f"   {i}. {file}")
            
            try:
                idx = int(input("\né€‰æ‹©æ–‡ä»¶ç¼–å·: ").strip()) - 1
                if 0 <= idx < len(review_files):
                    review_file = review_files[idx]
                    data_file = data_files[idx] if idx < len(data_files) else data_files[0]
                    
                    report_file = create_feedback_loop(
                        review_file,
                        data_file,
                        self.classifier
                    )
                    
                    print(f"\nâœ… å­¦ä¹ åˆ†æå®Œæˆï¼æŠ¥å‘Š: {report_file}")
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
            except (ValueError, IndexError) as e:
                print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
        
        elif choice == '0':
            return
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    
    def _show_improvement_suggestions(self, report_file: str):
        """æ˜¾ç¤ºæ”¹è¿›å»ºè®®"""
        try:
            with open(report_file, 'r', encoding='utf-8') as f:
                report = json.load(f)
            
            suggestions = report.get('improvement_suggestions', [])
            
            if not suggestions:
                print("\nâœ… å½“å‰åˆ†ç±»å™¨è¡¨ç°è‰¯å¥½ï¼Œæš‚æ— æ”¹è¿›å»ºè®®")
                return
            
            print("\n" + "="*70)
            print("ğŸ’¡ æ”¹è¿›å»ºè®®è¯¦æƒ…")
            print("="*70)
            
            for i, sug in enumerate(suggestions, 1):
                print(f"\nå»ºè®® {i}:")
                print(f"   ç±»å‹: {sug.get('type')}")
                
                if sug.get('category'):
                    print(f"   åˆ†ç±»: {sug.get('category')}")
                
                if sug.get('issue'):
                    print(f"   é—®é¢˜: {sug.get('issue')}")
                
                if sug.get('suggestion'):
                    print(f"   å»ºè®®: {sug.get('suggestion')}")
                
                if sug.get('keywords'):
                    print(f"   å»ºè®®æ·»åŠ å…³é”®è¯: {', '.join(sug['keywords'])}")
                
                if sug.get('severity'):
                    print(f"   ä¸¥é‡ç¨‹åº¦: {sug.get('severity')}")
            
            print("\n" + "="*70)
            print("ğŸ“ è¯´æ˜:")
            print("   è¿™äº›å»ºè®®åŸºäºäººå·¥å®¡æ ¸ç»“æœè‡ªåŠ¨ç”Ÿæˆ")
            print("   å¯ä»¥æ‰‹åŠ¨ç¼–è¾‘ content_classifier.py åº”ç”¨è¿™äº›æ”¹è¿›")
            print("="*70)
            
        except Exception as e:
            print(f"âŒ è¯»å–æŠ¥å‘Šå¤±è´¥: {e}")
    
    def _save_results(self, report: str, web_file: Optional[str] = None):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜JSONæ•°æ®
        data_file = f'ai_tracker_data_{timestamp}.json'
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'timestamp': timestamp,
                    'total_items': len(self.data)
                },
                'data': self.data,
                'trends': self.trends
            }, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {data_file}")
        
        # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
        report_file = f'ai_tracker_report_{timestamp}.txt'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        if web_file:
            print(f"ğŸŒ Webé¡µé¢å·²ç”Ÿæˆ: {web_file}")


def main():
    """ä¸»å‡½æ•°"""
    tracker = AIWorldTracker()
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == '--auto':
            # è‡ªåŠ¨è¿è¡Œå®Œæ•´æµç¨‹
            tracker.run_full_pipeline()
        elif sys.argv[1] == '--help':
            print("\nAI World Tracker - ä½¿ç”¨è¯´æ˜")
            print("\nå‚æ•°:")
            print("  --auto    è‡ªåŠ¨è¿è¡Œå®Œæ•´æµç¨‹")
            print("  --help    æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
            print("\næ— å‚æ•°:     è¿›å…¥äº¤äº’å¼èœå•\n")
    else:
        # äº¤äº’å¼èœå•
        tracker.show_menu()


if __name__ == "__main__":
    main()

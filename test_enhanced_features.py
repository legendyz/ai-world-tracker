"""æµ‹è¯•å¢å¼ºåŠŸèƒ½ï¼šå¦å®šè¯æ£€æµ‹ã€å¤šæ ‡ç­¾æ”¯æŒã€æ¥æºå¯ä¿¡åº¦"""
from content_classifier import ContentClassifier

classifier = ContentClassifier()

# æµ‹è¯•å¦å®šè¯æ£€æµ‹å’Œå¤šæ ‡ç­¾
test_cases = [
    {
        'title': 'OpenAI denies rumors about GPT-5 release',
        'summary': 'Company says fake news about launch is false and unconfirmed',
        'source': 'TechCrunch'
    },
    {
        'title': 'Research paper released on GitHub with implementation',
        'summary': 'Academic study on neural networks published with open-source code repository',
        'source': 'arXiv/GitHub'
    },
    {
        'title': 'Google announces Gemini 2.0 official release',
        'summary': 'Official press release from Google about new AI model launch available now',
        'source': 'Google Official Blog'
    },
    {
        'title': 'Startup might launch AI product next month',
        'summary': 'Unconfirmed speculation about possible release from new company',
        'source': 'Tech Blog'
    },
    {
        'title': 'Meta publishes research on reinforcement learning with developer toolkit',
        'summary': 'Research paper with open source framework for ML researchers and developers',
        'source': 'Meta AI Blog'
    },
    {
        'title': 'æœªè¯å®ï¼šå­—èŠ‚è·³åŠ¨å¯èƒ½æ¨å‡ºæ–°AIåŠ©æ‰‹',
        'summary': 'æ®ç§°å…¬å¸æ­£åœ¨å¼€å‘æ–°äº§å“ï¼Œä½†å®˜æ–¹å°šæœªç¡®è®¤å‘å¸ƒæ—¶é—´',
        'source': 'ç§‘æŠ€åª’ä½“'
    }
]

results = classifier.classify_batch(test_cases)

print("\n" + "="*70)
print("ğŸ¯ å¢å¼ºåŠŸèƒ½æµ‹è¯•ç»“æœ")
print("="*70)

for i, item in enumerate(results, 1):
    print(f"\næ¡ˆä¾‹ {i}: {item['title'][:50]}...")
    print(f"  â”œâ”€ ä¸»åˆ†ç±»: {item['content_type']} (ç½®ä¿¡åº¦: {item['confidence']:.1%})")
    
    # æ˜¾ç¤ºæ¬¡è¦æ ‡ç­¾
    if item.get('secondary_labels'):
        print(f"  â”œâ”€ æ¬¡è¦åˆ†ç±»: {', '.join(item['secondary_labels'])} â­")
    else:
        print(f"  â”œâ”€ æ¬¡è¦åˆ†ç±»: æ— ")
    
    print(f"  â”œâ”€ æŠ€æœ¯é¢†åŸŸ: {', '.join(item['tech_categories'])}")
    print(f"  â”œâ”€ åœ°åŒº: {item['region']}")
    
    if item.get('needs_review'):
        print(f"  â””â”€ âš ï¸  éœ€è¦äººå·¥å®¡æ ¸ (ç½®ä¿¡åº¦è¿‡ä½)")
    else:
        print(f"  â””â”€ âœ… åˆ†ç±»å¯ä¿¡")

print("\n" + "="*70)
print("ğŸ“Š åŠŸèƒ½éªŒè¯æ€»ç»“")
print("="*70)

# ç»Ÿè®¡
has_secondary = sum(1 for item in results if item.get('secondary_labels'))
avg_confidence = sum(item['confidence'] for item in results) / len(results)
needs_review = sum(1 for item in results if item.get('needs_review'))

print(f"âœ“ å¤šæ ‡ç­¾æ”¯æŒ: {has_secondary}/{len(results)} æ¡å†…å®¹æœ‰æ¬¡è¦åˆ†ç±»")
print(f"âœ“ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.1%}")
print(f"âœ“ éœ€è¦å®¡æ ¸: {needs_review} æ¡")
print(f"âœ“ å¦å®šè¯æ£€æµ‹: å·²å¯ç”¨å¹¶å½±å“åˆ†ç±»åˆ†æ•°")
print(f"âœ“ æ¥æºå¯ä¿¡åº¦: å·²å¯ç”¨å¹¶å½±å“ç½®ä¿¡åº¦")

# ðŸŒ AI World Tracker

[ðŸ‡¨ðŸ‡³ ä¸­æ–‡ç‰ˆ (Chinese Version)](README_CN.md)

**AI World Tracker** is a comprehensive platform for tracking and analyzing global Artificial Intelligence trends. It automatically collects data from multiple authoritative sources, classifies content using intelligent algorithms (LLM or rule-based), and generates visual trend analysis reports and web dashboards.

## ðŸŒŸ Branch Overview

| Branch | Version | Description | Target Users |
|--------|---------|-------------|--------------|
| `main` | v2.0 | **Latest stable version** with full LLM integration | Production use |
| `ai-world-tracker-v1` | v1.0 | First complete release with rule-based classification | Hobbyists & custom development |
| `feature/data-collection-v2` | Beta | Enhanced data collection (in development) | Contributors & testers |

### Choosing the Right Branch

- **Production Use**: Use `main` branch - fully tested with LLM-enhanced classification
- **Learning/Customization**: Use `ai-world-tracker-v1` - simpler architecture, rule-based, easy to modify
- **Contributing**: Use `feature/data-collection-v2` - help us improve data collection

## âœ¨ Key Features

### Core Capabilities
- **ðŸ¤– Multi-Source Data Collection**: Automatically scrapes data from arXiv (latest papers), GitHub (trending projects), tech media (TechCrunch, The Verge, Wired), and AI blogs (OpenAI, Google AI, Hugging Face)
- **ðŸ§  Intelligent Classification**: Dual-mode classification system
  - **LLM Mode**: Semantic understanding via Ollama/OpenAI (95%+ accuracy)
  - **Rule Mode**: Keyword-based pattern recognition (fast, no dependencies)
- **ðŸ“Š Data Visualization**: Generates charts for technology hotspots, content distribution, regional distribution, and daily trends
- **ðŸŒ Web Dashboard**: Creates responsive HTML dashboard with categorized news
- **ðŸ”„ Smart Caching**: MD5-based caching to avoid redundant API calls
- **ðŸŒ Bilingual Support**: Full Chinese/English interface (i18n)

### LLM Integration (Main Branch)
- **Multi-Provider Support**: Ollama (free, local), OpenAI
- **Local Models**: Qwen3:8b via Ollama - completely free
- **GPU Acceleration**: Auto-detects NVIDIA, AMD, Apple Silicon
- **Concurrent Processing**: 3-6 thread parallel processing for speed
- **Auto-Fallback**: Gracefully degrades to rule-based when LLM unavailable
- **Resource Management**: Automatic model unloading on exit to free VRAM/memory

## ðŸ› ï¸ Installation

### Requirements

- Python 3.8+
- Windows / macOS / Linux
- (Optional) Ollama for local LLM

### Quick Start

1. **Clone the Repository**
   ```bash
   git clone https://github.com/legendyz/ai-world-tracker.git
   cd ai-world-tracker
   ```

2. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **(Optional) Set up Ollama for LLM Classification**
   ```bash
   # Install Ollama from https://ollama.com/download
   ollama pull qwen3:8b
   ollama serve
   ```

4. **Run the Application**
   ```bash
   python TheWorldOfAI.py
   ```

## ðŸš€ Usage

### Main Menu

```
ðŸ“‹ Main Menu
============================================================
Current Mode: ðŸ¤– LLM Mode (ollama/qwen3:8b)
============================================================
1. ðŸš€ Auto Update & Generate (Full pipeline)
2. ðŸŒ Generate & Open Web Page
3. ðŸ“ Manual Review (Review low-confidence items)
4. ðŸ“š Learning Feedback (Analyze review history)
5. âš™ï¸  Settings & Management
0. Exit
============================================================
```

### Settings & Management Menu

```
âš™ï¸  Settings & Management

Current Mode: ðŸ¤– LLM Mode (ollama/qwen3:8b)

ðŸ“‹ Classification Mode:
  1. ðŸ“ Rule Mode (Rule-based) - Fast, free, no network required
  2. ðŸ¤– LLM Mode (Ollama Local) - High accuracy, semantic understanding
  3. ðŸ¤– LLM Mode (Azure OpenAI) - Highest accuracy, API key required

ðŸ§¹ Data Maintenance:
  4. ðŸ—‘ï¸ Clear LLM classification cache
  5. ðŸ—‘ï¸ Clear collection history cache
  6. ðŸ—‘ï¸ Clear export data history
  7. ðŸ—‘ï¸ Clear manual review records
  8. âš ï¸ Clear ALL data (requires confirmation)

  0. â†©ï¸ Back to main menu
```

### Feature Description

| Option | Function | Description |
|--------|----------|-------------|
| 1 | Auto Update | Execute full pipeline: Collection â†’ Classification â†’ Analysis â†’ Visualization â†’ Web Generation, then prompt to open browser |
| 2 | Web Page | Regenerate HTML dashboard and open in browser |
| 3 | Manual Review | Review items with low classification confidence |
| 4 | Learning Feedback | Generate optimization suggestions based on review history |
| 5 | Settings & Management | Switch classification mode and manage data/cache |

### Data Maintenance Options

| Option | Function | Description |
|--------|----------|-------------|
| Clear LLM Cache | ðŸ—‘ï¸ | Delete `llm_classification_cache.json`, force re-classification with LLM |
| Clear Collection Cache | ðŸ—‘ï¸ | Delete `collection_history_cache.json`, allow re-collection of all URLs |
| Clear Export History | ðŸ—‘ï¸ | Delete all `data/exports/ai_tracker_*.json` and `*.txt` files (requires confirmation) |
| Clear Review Records | ðŸ—‘ï¸ | Delete all `data/exports/review_history_*.json` and `learning_report_*.json` files |
| Clear ALL Data | âš ï¸ | Delete all cache and export files - **requires typing "YES" to confirm** |

## ðŸ“‚ Project Structure

```
ai-world-tracker/
â”œâ”€â”€ TheWorldOfAI.py          # Main application entry point
â”œâ”€â”€ data_collector.py        # Multi-source data collection
â”œâ”€â”€ content_classifier.py    # Rule-based content classifier
â”œâ”€â”€ llm_classifier.py        # LLM-enhanced classifier
â”œâ”€â”€ config.py                # Unified configuration management
â”œâ”€â”€ logger.py                # Unified logging system
â”œâ”€â”€ ai_analyzer.py           # Trend analysis engine
â”œâ”€â”€ visualizer.py            # Data visualization (Matplotlib)
â”œâ”€â”€ web_publisher.py         # Web page generator
â”œâ”€â”€ manual_reviewer.py       # Manual review interface
â”œâ”€â”€ learning_feedback.py     # Learning feedback system
â”œâ”€â”€ i18n.py                  # Internationalization (EN/CN)
â”œâ”€â”€ link_validator.py        # URL validation utility
â”œâ”€â”€ regenerate_web.py        # Quick web regeneration utility
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ config.yaml              # Application configuration
â”œâ”€â”€ ai_tracker_config.json   # User preferences (auto-generated)
â”œâ”€â”€ pytest.ini               # Test configuration
â”œâ”€â”€ data/                    # Generated data directory
â”‚   â”œâ”€â”€ exports/             # Exported data and reports
â”‚   â”‚   â”œâ”€â”€ ai_tracker_data_*.json    # Collected data with timestamps
â”‚   â”‚   â”œâ”€â”€ ai_tracker_report_*.txt   # Text reports
â”‚   â”‚   â”œâ”€â”€ review_history_*.json     # Manual review records
â”‚   â”‚   â””â”€â”€ learning_report_*.json    # Learning feedback reports
â”‚   â””â”€â”€ cache/               # Cache files
â”‚       â”œâ”€â”€ collection_history_cache.json  # URL/title deduplication
â”‚       â””â”€â”€ llm_classification_cache.json  # LLM classification results
â”œâ”€â”€ tests/                   # Test files directory
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_classifier_*.py
â”‚   â”œâ”€â”€ test_llm_*.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/                    # Log files directory
â”œâ”€â”€ visualizations/          # Generated charts
â”œâ”€â”€ web_output/              # Generated web pages (backup)
â”‚   â””â”€â”€ index.html
â””â”€â”€ index.html               # Main dashboard (GitHub Pages)
```

## ðŸ“° Data Sources

### Research Papers
- arXiv (cs.AI, cs.LG, cs.CV, cs.CL)

### Tech News Media
- TechCrunch AI
- The Verge AI
- Wired AI
- MIT Technology Review
- IEEE Spectrum AI
- AI News
- Synced Review

### Chinese Tech Media
- 36æ°ª (36Kr)
- ITä¹‹å®¶
- æœºå™¨ä¹‹å¿ƒ
- é‡å­ä½ (QbitAI)
- InfoQ China

### Developer Resources
- GitHub Blog
- Hugging Face Blog
- OpenAI Blog
- Google AI Blog

### Community & Leaders
- Product Hunt AI
- Hacker News AI
- Sam Altman's Blog
- Andrej Karpathy's Blog
- Lex Fridman Podcast

## âš™ï¸ Configuration

### Configuration Files

The application supports multiple configuration sources with the following priority:

1. **Environment Variables** - Highest priority
2. **.env File** - For local development
3. **config.yaml** - Project defaults
4. **ai_tracker_config.json** - User preferences (auto-saved)
5. **Code Defaults** - Fallback values

### config.yaml Example

```yaml
collector:
  product_count: 15
  community_count: 10
  leader_count: 15
  research_count: 15
  developer_count: 20
  news_count: 25
  max_total: 100

classification:
  mode: llm        # Options: llm, rule
  provider: ollama
  model: Qwen3:8B
  batch_size: 10
  max_workers: 4

visualization:
  theme: default

output:
  report_dir: ./
  web_dir: ./web_output/

# Data directory configuration
data:
  exports_dir: data/exports    # Exported data and reports
  cache_dir: data/cache        # Cache files

# Logging configuration
logging:
  level: INFO                  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  dir: logs                    # Log files directory
  console: true                # Output to console
  file: true                   # Output to file
  max_size_mb: 10              # Max size per log file (MB)
  backup_count: 2              # Number of backup files
  retention_days: 3            # Log retention days
  format: standard             # standard or json
```

### LLM Providers

| Provider | Model | Cost | Setup |
|----------|-------|------|-------|
| Ollama | qwen3:8b | Free | `ollama pull qwen3:8b` |
| OpenAI | gpt-4o-mini | Paid | Set `OPENAI_API_KEY` |

### Environment Variables

```bash
# Optional: Cloud LLM providers
export OPENAI_API_KEY="your-key"

# Optional: Custom Ollama URL
export OLLAMA_BASE_URL="http://localhost:11434"
```

## ðŸ“Š Content Classification

The classifier categorizes content into six dimensions:

| Category | Description | Examples |
|----------|-------------|----------|
| `research` | Academic papers and studies | arXiv papers, benchmark results |
| `product` | Product launches and updates | GPT-4o release, new features |
| `market` | Business and market news | Funding rounds, acquisitions |
| `developer` | Developer tools and resources | SDKs, APIs, tutorials |
| `leader` | Industry leader opinions | CEO interviews, keynotes |
| `community` | Community discussions | Hot topics, debates |

## ðŸ—ï¸ Classification System Architecture

### Overview

The system uses a **dual-mode classification architecture** with automatic fallback:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Classification Pipeline                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input Data                                                   â”‚
â”‚      â†“                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  LLM Classifier â”‚ OR â”‚ Rule Classifier â”‚                  â”‚
â”‚  â”‚  (Primary)      â”‚    â”‚ (Fallback)      â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚           â†“                      â†“                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚      Importance Evaluator               â”‚                 â”‚
â”‚  â”‚   (Multi-dimensional Weighted Scoring)  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚           â†“                                                   â”‚
â”‚  Output: category, importance, confidence, breakdown          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LLM Classifier (`llm_classifier.py`)

The LLM-enhanced classifier provides semantic understanding:

- **Multi-Provider Support**: Ollama (local), OpenAI, Anthropic
- **MD5-based Caching**: Avoid redundant API calls
- **Concurrent Processing**: 3-6 threads for parallel classification
- **Auto-Fallback**: Gracefully degrades to rule-based when LLM unavailable
- **GPU Auto-Detection**: NVIDIA (CUDA), AMD (ROCm), Apple Silicon (Metal)

### Rule Classifier (`content_classifier.py`)

The rule-based classifier uses keyword patterns:

- **Keyword Matching**: Category-specific keyword dictionaries
- **Confidence Scoring**: Based on keyword match strength
- **Fast Processing**: No network dependency, instant results

## âš–ï¸ Multi-Dimensional Importance Evaluation

The `ImportanceEvaluator` calculates content importance using **5 weighted dimensions**:

### Dimension Weights

| Dimension | Weight | Description |
|-----------|--------|-------------|
| **Source Authority** | 25% | Credibility of the content source |
| **Recency** | 25% | How recent the content is |
| **Confidence** | 20% | Classification confidence score (capped for old content) |
| **Relevance** | 20% | Relevance to AI topics |
| **Engagement** | 10% | Social signals (stars, downloads, etc.) |

### Confidence Cap Mechanism

To prevent old, low-value content from ranking too high, the system applies confidence caps:

| Content Age | Source Authority | Confidence Cap |
|-------------|-----------------|----------------|
| > 14 days | < 0.80 (non-official) | 60% |
| > 14 days | â‰¥ 0.80 (official) | 75% |
| 7-14 days | < 0.70 (low authority) | 75% |
| â‰¤ 7 days | Any | No cap |

### Calculation Formula

```
Importance = Î£ (dimension_score Ã— weight)

Where:
- source_authority Ã— 0.25
- recency Ã— 0.25
- confidence Ã— 0.20  (with cap for old content)
- relevance Ã— 0.20
- engagement Ã— 0.10
```

### Source Authority Scores

| Source Type | Score Range | Examples |
|-------------|-------------|----------|
| Official AI Companies | 0.90 - 1.00 | OpenAI, Google AI, Anthropic, Meta AI |
| Academic/Research | 0.90 - 0.95 | arXiv, GitHub, Hugging Face |
| Professional Media | 0.70 - 0.85 | TechCrunch, The Verge, Wired |
| Community | 0.50 - 0.65 | Hacker News, Reddit |
| Unknown | 0.40 | Default for unrecognized sources |

### Recency Decay Curve

| Age | Score | Description |
|-----|-------|-------------|
| Today | 1.00 | Most recent |
| 1 day | 0.95 | Very fresh |
| 3 days | 0.85 | Recent |
| 7 days | 0.70 | Within a week |
| 14 days | 0.50 | Two weeks old |
| 30+ days | 0.20 | Older content |

### Importance Levels

| Score Range | Level | Emoji |
|-------------|-------|-------|
| â‰¥ 0.85 | Critical | ðŸ”´ |
| â‰¥ 0.70 | High | ðŸŸ  |
| â‰¥ 0.55 | Medium | ðŸŸ¡ |
| â‰¥ 0.40 | Low | ðŸŸ¢ |
| < 0.40 | Minimal | âšª |

### Output Example

```json
{
  "title": "OpenAI releases GPT-5",
  "category": "product",
  "importance": 0.892,
  "confidence": 0.95,
  "importance_breakdown": {
    "source_authority": 1.0,
    "recency": 0.95,
    "confidence": 0.95,
    "relevance": 0.85,
    "engagement": 0.5
  }
}
```

## ðŸ”§ Version Comparison

| Feature | v1.0 (ai-world-tracker-v1) | v2.0 (main) |
|---------|----------------------------|-------------|
| Classification | Rule-based | LLM + Rule fallback |
| LLM Support | âŒ | âœ… Ollama/OpenAI |
| Local Models | âŒ | âœ… Qwen3:8b |
| Concurrent Processing | âŒ | âœ… Multi-threaded (3-6) |
| Smart Caching | âŒ | âœ… MD5-based |
| GPU Acceleration | âŒ | âœ… Auto-detection |
| Unified Logging | âŒ | âœ… logger.py (with emoji dedup) |
| Structured Data Dir | âŒ | âœ… data/exports, data/cache |
| Log Auto-Cleanup | âŒ | âœ… Configurable retention |
| JSON Log Format | âŒ | âœ… Optional |
| Test Organization | Scattered | âœ… tests/ directory |
| Bilingual UI | âŒ | âœ… Chinese/English |
| Resource Cleanup | âŒ | âœ… Auto unload LLM on exit |
| Cache Management | âŒ | âœ… Clear cache via menu |
| Review Data Management | âŒ | âœ… Clear review records |
| Bulk Data Cleanup | âŒ | âœ… Clear ALL data option |
| Confidence Cap | âŒ | âœ… Cap for old content |
| Accuracy | ~70% | ~95% |
| Use Case | Learning, customization | Production |

## ðŸ§ª Testing

Tests are organized in the `tests/` directory:

```bash
# Run all tests
pytest tests/ -v

# Run specific test
pytest tests/test_classifier_advanced.py -v

# Run with coverage
pytest tests/ --cov=. --cov-report=html
```

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ¤ Contributing

Contributions are welcome! Here's how to get involved:

1. **Report Issues**: Found a bug? [Open an issue](https://github.com/legendyz/ai-world-tracker/issues)
2. **Feature Requests**: Have an idea? Let us know!
3. **Submit Code**:
   - Fork the repository
   - Create a feature branch from `feature/data-collection-v2`
   - Submit a PR

### Development Workflow

```bash
# Clone and setup
git clone https://github.com/legendyz/ai-world-tracker.git
cd ai-world-tracker
git checkout feature/data-collection-v2

# Create feature branch
git checkout -b feature/your-feature

# Make changes and test
pytest tests/ -v

# Commit and push
git commit -m "feat: add your feature"
git push origin feature/your-feature
```

## ðŸ“§ Contact

- GitHub: [@legendyz](https://github.com/legendyz)
- Project: [ai-world-tracker](https://github.com/legendyz/ai-world-tracker)

---

**â­ Star this repository if you find it helpful!**

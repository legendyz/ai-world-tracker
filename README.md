# ğŸŒ AI World Tracker

[ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç‰ˆ (Chinese Version)](README_CN.md) | [ğŸ“Š Project Status](PROJECT_STATUS.md)

**AI World Tracker** is a comprehensive platform for tracking and analyzing global Artificial Intelligence trends. It automatically collects data from multiple sources such as arXiv, GitHub, tech media, and blogs. Utilizing intelligent classification algorithms (Rule-based + LLM-enhanced), it categorizes content into various dimensions (Research, Product, Market, etc.) and generates visual trend analysis reports and web pages.

**ğŸ†• v2.0-beta**: Now featuring **LLM-Enhanced Classification** with local Ollama support (Qwen3:8b), OpenAI, and Anthropic integration for semantic understanding and 95%+ accuracy!

---

## ğŸŒŸ What's New in v2.0

### Main Branch (v1.2 - Stable)
- Rule-based classification with keyword matching
- Manual review and learning feedback system
- Streamlined 4-item menu
- Production-ready and stable

### Feature Branch (v2.0-beta - LLM Enhanced)
- ğŸ¤– **LLM Classification**: Ollama (Qwen3:8b), OpenAI (GPT-4o-mini), Anthropic (Claude-3-Haiku)
- âš¡ **Performance**: 6-9x faster with concurrent processing (3 threads)
- ğŸ§  **Smart Caching**: MD5-based content caching to avoid redundant API calls
- ğŸ“± **Enhanced UI**: Hierarchical menu with manual workflow sub-menu
- ğŸ¯ **95%+ Accuracy**: Semantic understanding vs. keyword matching
- ğŸ’° **Cost-Free Option**: Local Ollama model with zero API costs
- ğŸ”„ **Auto-fallback**: Graceful degradation to rule-based classification

---

## âœ¨ Key Features

### Core Features (All Versions)
*   **ğŸ¤– Multi-source Data Collection**: Automatically scrapes data from arXiv (latest papers), GitHub (trending projects), and RSS Feeds (tech news, official blogs).
*   **ğŸ“Š Data Visualization**: Generates charts for technology hotspots, content distribution, regional distribution, and daily trends.
*   **ğŸŒ Web Report Generation**: Automatically generates a static HTML page (`index.html`) containing a dashboard and categorized news, with mobile support.

### Classification System
**Main Branch**: Rule-based with keyword matching (~70-80% accuracy)
- Pattern recognition and keyword weights
- Manual review system for corrections
- Learning feedback for rule optimization

**Feature Branch**: LLM-Enhanced with multi-provider support (95%+ accuracy)
- Semantic understanding and context analysis
- Multiple confidence levels and reasoning
- Technology field identification
- Rumor detection and fact verification

## ğŸ› ï¸ Installation Guide

### Requirements
*   Python 3.8+
*   Windows/macOS/Linux
*   (Optional) Ollama for local LLM support

### Quick Start - Main Branch (Stable)

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/legendyz/ai-world-tracker.git
    cd ai-world-tracker
    ```

2.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Run the Application**
    ```bash
    python TheWorldOfAI.py
    ```

### Advanced Setup - Feature Branch (LLM Enhanced)

1.  **Switch to Feature Branch**
    ```bash
    git checkout feature/ai-enhancements
    ```

2.  **Option A: Using Ollama (Recommended - Free & Local)**
    ```bash
    # Install Ollama
    # Windows: Download from https://ollama.com/download
    # Mac: brew install ollama
    # Linux: curl -fsSL https://ollama.com/install.sh | sh
    
    # Pull the model
    ollama pull qwen3:8b
    
    # Start Ollama service
    ollama serve
    
    # Install Python dependencies
    pip install -r requirements.txt
    
    # Run the application
    python TheWorldOfAI.py
    ```

3.  **Option B: Using OpenAI or Anthropic**
    ```bash
    # Install dependencies
    pip install -r requirements.txt
    
    # Set API keys (Windows PowerShell)
    $env:OPENAI_API_KEY='sk-your-openai-key'
    $env:ANTHROPIC_API_KEY='sk-ant-your-anthropic-key'
    
    # Or create .env file
    cp .env.example .env
    # Edit .env and add your API keys
    
    # Run the application
    python TheWorldOfAI.py
    ```

## ğŸš€ Quick Start

Run the main program to launch the interactive menu:

```bash
python TheWorldOfAI.py
```

### Main Branch Menu (v1.2)

1.  **ğŸš€ Auto Update & Generate**
    *   Executes the full pipeline: Collection â†’ Classification â†’ Analysis â†’ Visualization â†’ Web Generation.
    *   Automatically opens the generated web page in your browser.

2.  **ğŸŒ Generate & Open Web Page**
    *   Regenerate the HTML page based on current data and open it in your browser.

3.  **ğŸ“ Manual Review**
    *   Enter review mode where the system filters out low-confidence content for manual confirmation or correction.
    *   Review results are automatically saved for future learning optimization.

4.  **ğŸ“ Learning Feedback**
    *   Analyze review history and generate a report with suggestions for improving the classifier.

### Feature Branch Menu (v2.0-beta)

#### When Using LLM Mode:
```
Current Classification Mode: ğŸ¤– LLM Enhanced - Ollama (Qwen3:8b)

1. ğŸš€ Auto Update & Generate Web
2. ğŸ› ï¸  Manual Workflow
   â”œâ”€ 1. ğŸ“¥ Update Data Only
   â”œâ”€ 2. ğŸ·ï¸  Classify Existing Data
   â””â”€ 3. ğŸŒ Generate Web Page
5. âš™ï¸  Switch Classification Mode
0. Exit
```

#### When Using Rule-based Mode:
```
Current Classification Mode: ğŸ“ Rule-based

1. ğŸš€ Auto Update & Generate Web
2. ğŸ› ï¸  Manual Workflow
3. ğŸ“ Manual Review (Rule-mode only)
4. ğŸ“ Learning Feedback (Rule-mode only)
5. âš™ï¸  Switch Classification Mode
0. Exit
```

## ğŸ“‚ Project Structure

### Main Branch (v1.2)
```text
ai-world-tracker/
â”œâ”€â”€ TheWorldOfAI.py          # Main application entry point
â”œâ”€â”€ data_collector.py        # Data collection (arXiv, RSS, GitHub)
â”œâ”€â”€ content_classifier.py    # Rule-based classifier
â”œâ”€â”€ ai_analyzer.py           # Trend analysis
â”œâ”€â”€ visualizer.py            # Data visualization (Matplotlib)
â”œâ”€â”€ web_publisher.py         # Web page generator
â”œâ”€â”€ manual_reviewer.py       # Manual review interface
â”œâ”€â”€ learning_feedback.py     # Learning feedback system
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ visualizations/          # Generated charts
â””â”€â”€ web_output/              # Generated web pages
```

### Feature Branch (v2.0-beta) - Additional Files
```text
ai-world-tracker/
â”œâ”€â”€ llm_classifier.py        # ğŸ†• LLM classification engine
â”œâ”€â”€ config.py                # ğŸ†• Configuration management
â”œâ”€â”€ .env.example             # ğŸ†• Environment template
â”œâ”€â”€ cache/                   # ğŸ†• LLM response cache
â”œâ”€â”€ test_ollama.py           # ğŸ†• Ollama integration test
â”œâ”€â”€ test_llm_classifier.py   # ğŸ†• LLM classifier tests
â”œâ”€â”€ demo_llm_classifier.py   # ğŸ†• Interactive demo
â”œâ”€â”€ LLM_CLASSIFICATION_GUIDE.md     # ğŸ†• LLM usage guide
â”œâ”€â”€ LLM_IMPLEMENTATION_SUMMARY.md   # ğŸ†• Implementation details
â”œâ”€â”€ OLLAMA_SETUP_COMPLETE.md        # ğŸ†• Ollama setup guide
â””â”€â”€ PROJECT_STATUS.md               # ğŸ†• Comprehensive status report
```

## ğŸ”„ Workflow

### Main Branch Workflow
```
1. Collection â†’ Rule Classification â†’ Analysis
2. Visualization â†’ Web Generation
3. [Optional] Manual Review â†’ Learning Feedback
```

### Feature Branch Workflow (LLM Mode)
```
1. Collection â†’ Smart Classification
   â”œâ”€ Cache Check (MD5)
   â”œâ”€ Smart Skip (pre-classified)
   â”œâ”€ Concurrent LLM Calls (3 threads)
   â””â”€ Auto-fallback (if LLM fails)
2. Analysis â†’ Visualization
3. Web Generation + Auto-open
```

## âš¡ Performance Comparison

| Metric | Main Branch | Feature Branch (LLM) |
|--------|-------------|----------------------|
| **Accuracy** | 70-80% | 95%+ |
| **Speed** | Baseline | 6-9x faster* |
| **Cost** | Free | Free (Ollama) / Paid (APIs) |
| **Offline** | âœ… | âœ… (Ollama only) |
| **Setup** | Simple | Moderate |

*With concurrent processing and optimizations

## ğŸ“Š Classification Categories

Both versions support 6 main categories:

1. **Research** - Academic papers, scientific studies
2. **Product** - Product launches, new releases
3. **Market** - Funding, acquisitions, business news
4. **Developer** - Tools, libraries, tutorials
5. **Leader** - Expert opinions, interviews
6. **Community** - Trending discussions, viral content

### LLM Advantages (Feature Branch)
- Semantic understanding vs. keyword matching
- Context-aware categorization
- Multi-dimensional analysis
- Confidence scoring with reasoning
- Technology field identification
- Rumor detection

## ğŸ§ª Testing

### Main Branch
```bash
python test_workflow.py
python test_classifier_advanced.py
```

### Feature Branch
```bash
# Test Ollama integration
python test_ollama.py

# Test LLM classifier
python test_llm_classifier.py

# Interactive demo
python demo_llm_classifier.py
```

## ğŸ¤ Contributing

We welcome contributions! Please see our development branches:

- `main` - Stable production version (v1.2)
- `feature/ai-enhancements` - LLM features (v2.0-beta)

### Development Workflow
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

### Commit Convention
```
feat: New feature
fix: Bug fix
docs: Documentation
refactor: Code refactoring
perf: Performance improvement
test: Testing
chore: Build/config
```

## ğŸ“ Documentation

- [Project Status Report](PROJECT_STATUS.md) - Comprehensive project overview
- [LLM Classification Guide](LLM_CLASSIFICATION_GUIDE.md) - Feature branch only
- [LLM Implementation Summary](LLM_IMPLEMENTATION_SUMMARY.md) - Feature branch only
- [Ollama Setup Guide](OLLAMA_SETUP_COMPLETE.md) - Feature branch only
- [Changelog](CHANGELOG.md) - Version history

## ğŸ› Known Issues

### Main Branch
- Rule-based accuracy limited to 70-80%
- Requires manual review for edge cases

### Feature Branch
- First Ollama inference slow (~28s, subsequent faster with cache)
- Memory usage higher with concurrent processing
- Learning feedback not available in LLM mode

## ğŸ—ºï¸ Roadmap

### v2.0.0 (Feature Branch - In Progress)
- [x] LLM classification core
- [x] Multi-provider support
- [x] Local Ollama integration
- [x] Concurrent processing
- [x] Smart caching
- [x] Menu restructuring
- [ ] Comprehensive testing
- [ ] Merge to main

### v2.1.0 (Planned)
- [ ] Batch API support
- [ ] Custom prompt templates
- [ ] Classification export
- [ ] RESTful API

### v2.2.0 (Planned)
- [ ] Web UI
- [ ] Real-time data streaming
- [ ] User authentication
- [ ] Database integration

## ğŸ’¬ Community & Support

- **GitHub Issues**: Report bugs or request features
- **GitHub Discussions**: Community discussions and Q&A
- **Documentation**: Check our comprehensive docs

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Note**: The feature branch (v2.0-beta) is currently in beta testing. For production use, please use the main branch. The LLM-enhanced version will be merged after thorough testing and stability verification.

**Last Updated**: December 5, 2025

MIT License

"""å¿«é€Ÿæµ‹è¯• Qwen3:8b (no_think æ¨¡å¼)"""
from llm_classifier import LLMClassifier
import time

classifier = LLMClassifier(
    provider='ollama',
    model='qwen3:8b',
    enable_cache=False
)

test_item = {
    'title': 'OpenAI officially launches GPT-4o with new features',
    'summary': 'OpenAI announces the general availability of GPT-4o model with multimodal capabilities',
    'source': 'TechCrunch'
}

print("=" * 60)
print("æµ‹è¯• Qwen3:8b (no_think æ¨¡å¼)")
print("=" * 60)

start = time.time()
result = classifier.classify_item(test_item)
elapsed = time.time() - start

print(f"\nğŸ“ æ ‡é¢˜: {test_item['title']}")
print(f"\nğŸ“Š ç»“æœ:")
print(f"   ç±»åˆ«: {result.get('content_type')}")
print(f"   ç½®ä¿¡åº¦: {result.get('confidence', 0):.0%}")
print(f"   åˆ†ç±»å™¨: {result.get('classified_by')}")
print(f"   ç†ç”±: {result.get('llm_reasoning', 'N/A')}")
print(f"\nâ±ï¸ è€—æ—¶: {elapsed:.1f}s")

"""
å†…å®¹åˆ†ç±»ç³»ç»Ÿ - Content Classifier
åŸºäºå…³é”®è¯å’Œè§„åˆ™å¯¹AIå†…å®¹è¿›è¡Œå¤šç»´åº¦åˆ†ç±»
"""

from typing import Dict, List, Set
import re
from datetime import datetime


class ContentClassifier:
    """AIå†…å®¹æ™ºèƒ½åˆ†ç±»å™¨"""
    
    def __init__(self):
        # ç ”ç©¶ç±»å…³é”®è¯
        self.research_keywords = {
            'paper', 'research', 'study', 'arxiv', 'conference', 'journal',
            'algorithm', 'model', 'neural network', 'deep learning', 'machine learning',
            'è®ºæ–‡', 'ç ”ç©¶', 'ç®—æ³•', 'æ¨¡å‹', 'ç¥ç»ç½‘ç»œ', 'å­¦ä¹ '
        }
        
        # å¼€å‘è€…ç±»å…³é”®è¯
        self.developer_keywords = {
            'github', 'code', 'library', 'framework', 'sdk', 'api', 'open source',
            'repository', 'commit', 'pull request', 'developer', 'programming',
            'implementation', 'tutorial', 'documentation', 'guide',
            'å¼€å‘', 'ä»£ç ', 'åº“', 'æ¡†æ¶', 'å¼€æº', 'ä»“åº“', 'æ•™ç¨‹', 'æ–‡æ¡£', 'æŒ‡å—'
        }
        
        # äº§å“ç±»å…³é”®è¯ï¼ˆä¸“æ³¨äºå…¬å¸æ­£å¼å‘å¸ƒçš„AIäº§å“ï¼‰
        self.product_keywords = {
            'release', 'launch', 'announce', 'unveil', 'debut', 'introduce',
            'official', 'commercial', 'enterprise', 'product', 'version', 'update',
            'platform', 'service', 'solution', 'system', 'assistant', 'api',
            'available', 'beta', 'preview', 'early access', 'public',
            'å‘å¸ƒ', 'æ¨å‡º', 'å®£å¸ƒ', 'å®˜æ–¹', 'å•†ä¸š', 'ä¼ä¸š', 'äº§å“', 'ç‰ˆæœ¬', 'å¹³å°', 
            'æœåŠ¡', 'è§£å†³æ–¹æ¡ˆ', 'åŠ©æ‰‹', 'ä¸Šçº¿', 'æ­£å¼', 'å…¬æµ‹'
        }
        
        # å¸‚åœºç±»å…³é”®è¯
        self.market_keywords = {
            'funding', 'investment', 'market', 'business', 'startup', 'company',
            'acquisition', 'ipo', 'valuation', 'revenue', 'policy', 'regulation',
            'èèµ„', 'æŠ•èµ„', 'å¸‚åœº', 'ä¼ä¸š', 'å…¬å¸', 'æ”¿ç­–', 'ç›‘ç®¡', 'è¡Œä¸š'
        }
        
        # é¢†è¢–è¨€è®ºå…³é”®è¯
        self.leader_keywords = {
            'said', 'stated', 'believes', 'warns', 'predicts', 'interview', 'speech',
            'tweeted', 'posted', 'commented', 'opinion', 'quote',
            'è¯´', 'è¡¨ç¤º', 'è®¤ä¸º', 'è­¦å‘Š', 'é¢„æµ‹', 'é‡‡è®¿', 'æ¼”è®²', 'å‘æ–‡', 'è¯„è®º', 'è§‚ç‚¹'
        }
        
        # æŠ€æœ¯é¢†åŸŸå…³é”®è¯
        self.tech_categories = {
            'NLP': [
                'nlp', 'natural language', 'text mining', 'embedding', 'bert', 'transformer', 
                'sentiment analysis', 'translation', 'linguistics', 'tokenization',
                'è‡ªç„¶è¯­è¨€', 'æ–‡æœ¬æŒ–æ˜', 'è¯­ä¹‰', 'ç¿»è¯‘', 'è¯å‘é‡'
            ],
            'Computer Vision': [
                'vision', 'image', 'video', 'detection', 'recognition', 'segmentation', 'ocr',
                'yolo', 'resnet', 'vit', 'è§†è§‰', 'å›¾åƒ', 'è§†é¢‘', 'è¯†åˆ«', 'æ£€æµ‹'
            ],
            'Reinforcement Learning': [
                'reinforcement', 'rl', 'agent', 'policy', 'reward', 'q-learning', 'ppo',
                'å¼ºåŒ–å­¦ä¹ ', 'æ™ºèƒ½ä½“', 'å¥–åŠ±'
            ],
            'Generative AI': [
                'generative', 'generation', 'aigc', 'llm', 'large language model', 'foundation model',
                'gpt', 'chatgpt', 'claude', 'llama', 'mistral', 'gemini', 'copilot', 'grok',
                'sora', 'midjourney', 'dalle', 'stable diffusion', 'runway', 'pika', 'flux',
                'text-to-image', 'text-to-video', 'ç”Ÿæˆå¼', 'å¤§æ¨¡å‹', 'è¯­è¨€æ¨¡å‹', 'æ–‡ç”Ÿå›¾', 'æ–‡ç”Ÿè§†é¢‘'
            ],
            'MLOps': ['mlops', 'deployment', 'production', 'monitoring', 'pipeline', 'éƒ¨ç½²', 'è¿ç»´'],
            'AI Ethics': ['ethics', 'bias', 'fairness', 'privacy', 'safety', 'alignment', 'ä¼¦ç†', 'åè§', 'éšç§', 'å®‰å…¨', 'å¯¹é½']
        }
        
        # åŒºåŸŸå…³é”®è¯
        self.region_keywords = {
            'China': ['china', 'chinese', 'beijing', 'shanghai', 'baidu', 'alibaba', 'tencent', 'ä¸­å›½', 'ç™¾åº¦', 'é˜¿é‡Œ', 'è…¾è®¯'],
            'USA': ['usa', 'us', 'silicon valley', 'openai', 'google', 'microsoft', 'meta', 'ç¾å›½'],
            'Europe': ['europe', 'eu', 'european', 'mistral', 'deepmind', 'æ¬§æ´²'],
            'Global': ['global', 'international', 'worldwide', 'å…¨çƒ', 'å›½é™…']
        }
    
    def classify_content_type(self, item: Dict) -> str:
        """
        åˆ†ç±»å†…å®¹ç±»å‹ï¼šç ”ç©¶/å¼€å‘è€…/äº§å“/å¸‚åœº/é¢†è¢–/ç¤¾åŒº
        
        Args:
            item: å†…å®¹é¡¹ï¼ˆåŒ…å«title, summaryç­‰å­—æ®µï¼‰
            
        Returns:
            åˆ†ç±»ç»“æœ
        """
        # å¦‚æœé‡‡é›†æ—¶å·²ç»æŒ‡å®šäº†ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
        if item.get('category') in ['research', 'developer', 'product', 'market', 'leader', 'community']:
            return item.get('category')

        text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('description', '')}".lower()
        source = item.get('source', '').lower()
        
        # ç»å¯¹ä¼˜å…ˆè§„åˆ™ï¼šGitHubæ¥æºå¿…é¡»å½’ç±»ä¸ºå¼€å‘è€…
        if 'github' in source or 'github' in text:
            return 'developer'
        
        # arXivæ¥æºå¿…é¡»å½’ç±»ä¸ºç ”ç©¶
        if 'arxiv' in source:
            return 'research'
        
        # äº§å“ç±»ä¸¥æ ¼è§„åˆ™ï¼šå¿…é¡»åŒæ—¶åŒ…å«å…¬å¸åç§°å’Œäº§å“å‘å¸ƒå…³é”®è¯
        company_indicators = ['google', 'microsoft', 'openai', 'anthropic', 'meta', 'apple', 'amazon', 
                             'baidu', 'alibaba', 'tencent', 'bytedance', 'huawei', 'xiaomi',
                             'ç™¾åº¦', 'é˜¿é‡Œ', 'è…¾è®¯', 'å­—èŠ‚', 'åä¸º', 'å°ç±³',
                             'deepseek', 'mistral', 'cohere', 'stability', 'midjourney', 'runway',
                             'æ™ºè°±', 'æœˆä¹‹æš—é¢', 'é›¶ä¸€ä¸‡ç‰©', 'ç™¾å·', 'ç§‘å¤§è®¯é£']
        
        has_company = any(company in text or company in source for company in company_indicators)
        product_score = self._calculate_keyword_score(text, self.product_keywords)
        
        # ä¼˜åŒ–è§„åˆ™ï¼š
        # 1. å¦‚æœæœ‰æ˜ç¡®çš„å…¬å¸å + å‘å¸ƒè¯ï¼Œæƒé‡æå¤§æå‡
        # 2. å¦‚æœæ²¡æœ‰å…¬å¸åï¼Œä½†æœ‰å¼ºçƒˆçš„å‘å¸ƒè¯ï¼ˆå¦‚ launch, releaseï¼‰ï¼Œä¹Ÿä¿ç•™åˆ†æ•°
        if has_company and product_score > 0:
            product_score *= 3.0
        elif product_score > 0:
            product_score *= 1.5 # å³ä½¿æ²¡æœ‰åŒ¹é…åˆ°å¤§å…¬å¸ï¼Œåªè¦æœ‰å‘å¸ƒåŠ¨ä½œï¼Œä¹Ÿç»™äºˆä¸€å®šæƒé‡
        
        scores = {
            'research': self._calculate_keyword_score(text, self.research_keywords),
            'developer': self._calculate_keyword_score(text, self.developer_keywords),
            'product': product_score,
            'market': self._calculate_keyword_score(text, self.market_keywords),
            'leader': self._calculate_keyword_score(text, self.leader_keywords)
        }
        
        return max(scores.items(), key=lambda x: x[1])[0]
    
    def classify_tech_category(self, item: Dict) -> List[str]:
        """
        åˆ†ç±»æŠ€æœ¯é¢†åŸŸï¼ˆå¯å¤šæ ‡ç­¾ï¼‰
        
        Args:
            item: å†…å®¹é¡¹
            
        Returns:
            æŠ€æœ¯é¢†åŸŸåˆ—è¡¨
        """
        text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('description', '')}".lower()
        categories = []
        
        for category, keywords in self.tech_categories.items():
            score = self._calculate_keyword_score(text, keywords)
            if score > 0:
                categories.append(category)
        
        return categories if categories else ['General AI']
    
    def classify_region(self, item: Dict) -> str:
        """
        åˆ†ç±»åœ°åŒº
        
        Args:
            item: å†…å®¹é¡¹
            
        Returns:
            åœ°åŒºåˆ†ç±»
        """
        # å¦‚æœå·²æœ‰regionå­—æ®µ
        if 'region' in item and item['region']:
            return item['region']
        
        text = f"{item.get('title', '')} {item.get('summary', '')} {item.get('description', '')} {item.get('source', '')}".lower()
        
        scores = {}
        for region, keywords in self.region_keywords.items():
            scores[region] = self._calculate_keyword_score(text, keywords)
        
        max_region = max(scores.items(), key=lambda x: x[1])[0]
        return max_region if scores[max_region] > 0 else 'Global'
    
    def classify_item(self, item: Dict) -> Dict:
        """
        å¯¹å•ä¸ªå†…å®¹é¡¹è¿›è¡Œå®Œæ•´åˆ†ç±»
        
        Args:
            item: åŸå§‹å†…å®¹é¡¹
            
        Returns:
            æ·»åŠ äº†åˆ†ç±»ä¿¡æ¯çš„å†…å®¹é¡¹
        """
        classified = item.copy()
        
        classified['content_type'] = self.classify_content_type(item)
        classified['tech_categories'] = self.classify_tech_category(item)
        classified['region'] = self.classify_region(item)
        classified['classified_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        return classified
    
    def classify_batch(self, items: List[Dict]) -> List[Dict]:
        """
        æ‰¹é‡åˆ†ç±»
        
        Args:
            items: å†…å®¹é¡¹åˆ—è¡¨
            
        Returns:
            åˆ†ç±»åçš„å†…å®¹é¡¹åˆ—è¡¨
        """
        print(f"æ­£åœ¨å¯¹ {len(items)} æ¡å†…å®¹è¿›è¡Œåˆ†ç±»...")
        
        classified_items = []
        for item in items:
            classified_items.append(self.classify_item(item))
        
        # ç»Ÿè®¡
        stats = self._calculate_statistics(classified_items)
        print(f"åˆ†ç±»å®Œæˆï¼")
        print(f"   - ç ”ç©¶: {stats['research']} | å¼€å‘è€…: {stats['developer']} | äº§å“: {stats['product']} | å¸‚åœº: {stats['market']} | é¢†è¢–: {stats['leader']}")
        
        return classified_items
    
    def _calculate_keyword_score(self, text: str, keywords: Set[str]) -> int:
        """è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°"""
        score = 0
        for keyword in keywords:
            if keyword in text:
                score += 1
        return score
    
    def _calculate_statistics(self, items: List[Dict]) -> Dict:
        """è®¡ç®—åˆ†ç±»ç»Ÿè®¡"""
        stats = {'research': 0, 'developer': 0, 'product': 0, 'market': 0, 'leader': 0}
        
        for item in items:
            content_type = item.get('content_type', 'market')
            if content_type in stats:
                stats[content_type] += 1
        
        return stats
    
    def get_filtered_items(self, items: List[Dict], 
                          content_type: str = None,
                          tech_category: str = None,
                          region: str = None) -> List[Dict]:
        """
        æ ¹æ®æ¡ä»¶è¿‡æ»¤å†…å®¹
        
        Args:
            items: åˆ†ç±»åçš„å†…å®¹åˆ—è¡¨
            content_type: å†…å®¹ç±»å‹è¿‡æ»¤
            tech_category: æŠ€æœ¯é¢†åŸŸè¿‡æ»¤
            region: åœ°åŒºè¿‡æ»¤
            
        Returns:
            è¿‡æ»¤åçš„å†…å®¹åˆ—è¡¨
        """
        filtered = items
        
        if content_type:
            filtered = [item for item in filtered if item.get('content_type') == content_type]
        
        if tech_category:
            filtered = [item for item in filtered if tech_category in item.get('tech_categories', [])]
        
        if region:
            filtered = [item for item in filtered if item.get('region') == region]
        
        return filtered


if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    classifier = ContentClassifier()
    
    test_items = [
        {
            'title': 'GPT-5 Released by OpenAI',
            'summary': 'OpenAI announces the release of GPT-5 with improved capabilities',
            'source': 'TechNews'
        },
        {
            'title': 'New Research on Transformer Architecture',
            'summary': 'A breakthrough paper on attention mechanisms in neural networks',
            'source': 'arXiv'
        },
        {
            'title': 'ç™¾åº¦è·å¾—10äº¿ç¾å…ƒAIæŠ•èµ„',
            'summary': 'ä¸­å›½ç§‘æŠ€å·¨å¤´ç™¾åº¦å®£å¸ƒå®Œæˆæ–°ä¸€è½®èèµ„ï¼Œç”¨äºAIç ”å‘',
            'source': 'ä¸­å›½ç§‘æŠ€'
        }
    ]
    
    results = classifier.classify_batch(test_items)
    
    print("\nğŸ“‹ åˆ†ç±»ç»“æœ:")
    for item in results:
        print(f"\n  æ ‡é¢˜: {item['title']}")
        print(f"  ç±»å‹: {item['content_type']}")
        print(f"  é¢†åŸŸ: {', '.join(item['tech_categories'])}")
        print(f"  åœ°åŒº: {item['region']}")

"""
æµ‹è¯•URLé¢„è¿‡æ»¤ä¼˜åŒ–æ•ˆæœ

å¯¹æ¯”ä¼˜åŒ–å‰åçš„é‡‡é›†æ€§èƒ½ï¼š
- è¯·æ±‚æ•°é‡
- é‡‡é›†è€—æ—¶
- èµ„æºæ¶ˆè€—
"""

import asyncio
import time
from data_collector import AIDataCollector
from logger import get_log_helper, configure_logging

configure_logging(log_level='INFO')
log = get_log_helper('test')


async def test_with_url_filter():
    """æµ‹è¯•å¯ç”¨URLé¢„è¿‡æ»¤çš„æ€§èƒ½"""
    collector = AIDataCollector()
    
    print("\n" + "="*70)
    print("æµ‹è¯•åœºæ™¯ï¼šURLé¢„è¿‡æ»¤ä¼˜åŒ– (URL Pre-filtering Optimization)")
    print("="*70)
    
    start_time = time.time()
    
    # æ‰§è¡Œå¼‚æ­¥é‡‡é›†ï¼ˆé»˜è®¤å¯ç”¨URLé¢„è¿‡æ»¤ï¼‰
    data = await collector._collect_all_async()
    
    elapsed = time.time() - start_time
    
    # ç»Ÿè®¡ç»“æœ
    total_items = sum(len(items) for items in data.values())
    
    print("\n" + "="*70)
    print("ä¼˜åŒ–åæ€§èƒ½æŒ‡æ ‡ (With URL Pre-filtering)")
    print("="*70)
    print(f"âœ… æ€»è€—æ—¶: {elapsed:.1f}s")
    print(f"âœ… é‡‡é›†é¡¹ç›®: {total_items} items")
    print(f"âœ… HTTPè¯·æ±‚æ•°: {collector.stats['requests_made']}")
    print(f"âœ… å¤±è´¥è¯·æ±‚: {collector.stats['requests_failed']}")
    print(f"âœ… å¹³å‡é€Ÿåº¦: {total_items/elapsed:.1f} items/s")
    print(f"âœ… è¯·æ±‚æ•ˆç‡: {total_items/collector.stats['requests_made']:.2f} items/request")
    
    # åˆ†ç±»ç»Ÿè®¡
    print("\nåˆ†ç±»ç»Ÿè®¡:")
    for category, items in data.items():
        if items:
            print(f"  {category}: {len(items)} items")
    
    return {
        'elapsed': elapsed,
        'total_items': total_items,
        'requests': collector.stats['requests_made'],
        'failed': collector.stats['requests_failed'],
        'speed': total_items/elapsed if elapsed > 0 else 0,
        'efficiency': total_items/collector.stats['requests_made'] if collector.stats['requests_made'] > 0 else 0
    }


def compare_results(with_filter):
    """å¯¹æ¯”åˆ†æç»“æœ"""
    print("\n" + "="*70)
    print("ä¼˜åŒ–æ•ˆæœåˆ†æ (Optimization Analysis)")
    print("="*70)
    
    print("\nğŸ“Š æ€§èƒ½æŒ‡æ ‡æ±‡æ€»:")
    print(f"  é‡‡é›†è€—æ—¶: {with_filter['elapsed']:.1f}s")
    print(f"  é‡‡é›†é¡¹ç›®: {with_filter['total_items']} items")
    print(f"  HTTPè¯·æ±‚: {with_filter['requests']} requests")
    print(f"  é‡‡é›†é€Ÿåº¦: {with_filter['speed']:.1f} items/s")
    print(f"  è¯·æ±‚æ•ˆç‡: {with_filter['efficiency']:.2f} items/request")
    
    print("\nğŸ’¡ URLé¢„è¿‡æ»¤ä¼˜åŒ–è¯´æ˜:")
    print("  âœ… åœ¨è¯·æ±‚è¯¦ç»†å†…å®¹å‰ï¼Œå…ˆæ£€æŸ¥URLæ˜¯å¦å·²åœ¨å†å²ç¼“å­˜ä¸­")
    print("  âœ… è·³è¿‡å·²ç¼“å­˜çš„URLï¼Œå‡å°‘ä¸å¿…è¦çš„HTTPè¯·æ±‚")
    print("  âœ… é€‚ç”¨äºRSSæºã€GitHubã€Hugging Faceã€Hacker Newsç­‰")
    print("  âœ… é¢„æœŸå‡å°‘50-70%çš„é‡å¤è¯·æ±‚ï¼ˆé¦–æ¬¡è¿è¡Œåï¼‰")
    
    print("\nğŸ“ˆ æ•ˆæœå±•ç¤º:")
    print("  é¦–æ¬¡è¿è¡Œ: å»ºç«‹ç¼“å­˜åŸºçº¿ï¼Œæ€§èƒ½ä¸åŸå§‹ç‰ˆæœ¬ç›¸ä¼¼")
    print("  ç¬¬äºŒæ¬¡è¿è¡Œ: URLé¢„è¿‡æ»¤å¼€å§‹ç”Ÿæ•ˆï¼Œè¯·æ±‚æ•°é‡æ˜¾è‘—é™ä½")
    print("  åç»­è¿è¡Œ: éšç€ç¼“å­˜å¢é•¿ï¼Œè¿‡æ»¤æ•ˆæœæŒç»­æå‡")
    
    print("\nğŸ”§ ä½¿ç”¨å»ºè®®:")
    print("  â€¢ ä¿æŒ7å¤©å†å²ç¼“å­˜ï¼ˆconfig.yamlå¯é…ç½®ï¼‰")
    print("  â€¢ å®šæœŸè¿è¡Œé‡‡é›†ä»»åŠ¡ï¼Œå……åˆ†åˆ©ç”¨ç¼“å­˜")
    print("  â€¢ å¦‚éœ€å¼ºåˆ¶å…¨é‡é‡‡é›†ï¼Œå¯æ¸…é™¤å†å²ç¼“å­˜")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "="*70)
    print("ğŸš€ URLé¢„è¿‡æ»¤ä¼˜åŒ–æµ‹è¯• (URL Pre-filtering Optimization Test)")
    print("="*70)
    
    # æµ‹è¯•å¯ç”¨URLé¢„è¿‡æ»¤
    with_filter = await test_with_url_filter()
    
    # å¯¹æ¯”åˆ†æ
    compare_results(with_filter)
    
    print("\n" + "="*70)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*70)


if __name__ == "__main__":
    asyncio.run(main())

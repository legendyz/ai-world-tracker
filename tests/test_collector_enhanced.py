"""
data_collector.py å¢å¼ºæµ‹è¯•
å®Œå–„å¼‚æ­¥æ•°æ®æ”¶é›†å™¨æµ‹è¯•è¦†ç›–ç‡
"""

import sys
import os
import pytest
import asyncio
import aiohttp
from unittest.mock import Mock, patch, AsyncMock, MagicMock
from datetime import datetime
import json

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data_collector import AIDataCollector


class TestAIDataCollectorAdvanced:
    """é«˜çº§æ•°æ®æ”¶é›†å™¨æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_context_manager_enter_exit(self):
        """æµ‹è¯•å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        collector = AIDataCollector()
        
        async with collector as c:
            assert c._session is not None
            assert isinstance(c._session, aiohttp.ClientSession)
        
        # é€€å‡ºåsessionåº”è¯¥è¢«å…³é—­
        print("âœ… å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ­£å¸¸å·¥ä½œ")
    
    @pytest.mark.asyncio
    async def test_session_creation(self):
        """æµ‹è¯•sessionåˆ›å»º"""
        collector = AIDataCollector()
        
        await collector._ensure_session()
        
        assert collector._session is not None
        assert isinstance(collector._session, aiohttp.ClientSession)
        
        await collector._close_session()
        
        print("âœ… Sessionåˆ›å»ºå’Œå…³é—­æ­£å¸¸")
    
    @pytest.mark.asyncio
    async def test_multiple_session_creation_calls(self):
        """æµ‹è¯•å¤šæ¬¡è°ƒç”¨sessionåˆ›å»º"""
        collector = AIDataCollector()
        
        await collector._ensure_session()
        first_session = collector._session
        
        await collector._ensure_session()
        second_session = collector._session
        
        # åº”è¯¥é‡ç”¨åŒä¸€ä¸ªsession
        assert first_session is second_session
        
        await collector._close_session()
        
        print("âœ… Sessioné‡ç”¨æ­£å¸¸")
    
    def test_history_cache_structure(self):
        """æµ‹è¯•å†å²ç¼“å­˜ç»“æ„"""
        collector = AIDataCollector()
        
        # éªŒè¯å†å²ç¼“å­˜å·²åŠ è½½
        assert hasattr(collector, 'history_cache')
        assert isinstance(collector.history_cache, dict)
        
        print("âœ… å†å²ç¼“å­˜ç»“æ„æ­£å¸¸")
    
    def test_async_config_loaded(self):
        """æµ‹è¯•å¼‚æ­¥é…ç½®å·²åŠ è½½"""
        collector = AIDataCollector()
        
        # éªŒè¯å¼‚æ­¥é…ç½®
        assert hasattr(collector, 'async_config')
        assert collector.async_config is not None
        
        print("âœ… å¼‚æ­¥é…ç½®åŠ è½½æ­£å¸¸")
    
    def test_stats_initialization(self):
        """æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯åˆå§‹åŒ–"""
        collector = AIDataCollector()
        
        assert 'requests_made' in collector.stats
        assert 'requests_failed' in collector.stats
        assert 'items_collected' in collector.stats
        assert 'failed_sources' in collector.stats
        
        assert collector.stats['requests_made'] == 0
        assert collector.stats['items_collected'] == 0
        
        print("âœ… ç»Ÿè®¡ä¿¡æ¯åˆå§‹åŒ–æ­£å¸¸")
    
    def test_stats_update(self):
        """æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯æ›´æ–°"""
        collector = AIDataCollector()
        
        collector.stats['requests_made'] = 10
        collector.stats['items_collected'] = 7
        collector.stats['requests_failed'] = 2
        
        assert collector.stats['requests_made'] == 10
        assert collector.stats['items_collected'] == 7
        
        print("âœ… ç»Ÿè®¡ä¿¡æ¯æ›´æ–°æ­£å¸¸")
    
    def test_record_failure(self):
        """æµ‹è¯•è®°å½•å¤±è´¥"""
        collector = AIDataCollector()
        
        initial_failed = collector.stats['requests_failed']
        # ç›´æ¥æ›´æ–°ç»Ÿè®¡ï¼Œå› ä¸º_record_failureå¯èƒ½ä¸æ˜¯å…¬å…±æ–¹æ³•
        collector.stats['requests_failed'] += 1
        
        assert collector.stats['requests_failed'] == initial_failed + 1
        
        print("âœ… å¤±è´¥è®°å½•æ­£å¸¸")


class TestCacheManagement:
    """æµ‹è¯•ç¼“å­˜ç®¡ç†"""
    
    def test_cache_file_path(self):
        """æµ‹è¯•ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        collector = AIDataCollector()
        
        assert hasattr(collector, 'history_cache_file')
        assert collector.history_cache_file is not None
        
        print(f"âœ… ç¼“å­˜æ–‡ä»¶è·¯å¾„: {collector.history_cache_file}")
    
    def test_load_cache(self):
        """æµ‹è¯•åŠ è½½ç¼“å­˜"""
        collector = AIDataCollector()
        
        # _load_history_cacheåº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        try:
            collector._load_history_cache()
        except Exception as e:
            pytest.fail(f"åŠ è½½ç¼“å­˜ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸: {e}")
        
        print("âœ… ç¼“å­˜åŠ è½½æ­£å¸¸")
    
    def test_save_cache(self):
        """æµ‹è¯•ä¿å­˜ç¼“å­˜"""
        collector = AIDataCollector()
        
        # æ·»åŠ ä¸€äº›æµ‹è¯•æ•°æ®åˆ°å†å²ç¼“å­˜
        collector.history_cache['test_key'] = 'test_value'
        
        # _save_history_cacheåº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        try:
            collector._save_history_cache()
        except Exception as e:
            pytest.fail(f"ä¿å­˜ç¼“å­˜ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸: {e}")
        
        print("âœ… ç¼“å­˜ä¿å­˜æ­£å¸¸")
    
    def test_cache_persistence(self, tmp_path):
        """æµ‹è¯•ç¼“å­˜æŒä¹…åŒ–"""
        cache_file = tmp_path / "test_cache.json"
        
        # ç¬¬ä¸€ä¸ªæ”¶é›†å™¨ï¼šä¿å­˜æ•°æ®
        collector1 = AIDataCollector()
        collector1.history_cache_file = str(cache_file)
        collector1.history_cache['urls'] = ['https://test.com/1']
        collector1.history_cache['titles'] = ['Test Title 1']
        collector1._save_history_cache()
        
        # ç¬¬äºŒä¸ªæ”¶é›†å™¨ï¼šåŠ è½½æ•°æ®
        collector2 = AIDataCollector()
        collector2.history_cache_file = str(cache_file)
        collector2.history_cache = collector2._load_history_cache()
        
        assert 'urls' in collector2.history_cache or 'titles' in collector2.history_cache
        
        print("âœ… ç¼“å­˜æŒä¹…åŒ–æ­£å¸¸")


class TestRSSFeedProcessing:
    """æµ‹è¯•RSSæºå¤„ç†"""
    
    @pytest.mark.asyncio
    async def test_rss_feeds_configuration(self):
        """æµ‹è¯•RSSæºé…ç½®"""
        collector = AIDataCollector()
        
        assert hasattr(collector, 'rss_feeds')
        assert isinstance(collector.rss_feeds, dict)  # RSS_FEEDSæ˜¯å­—å…¸æ ¼å¼
        
        print(f"âœ… RSSæºé…ç½®: {len(collector.rss_feeds)}ä¸ªç±»åˆ«")
    
    @pytest.mark.asyncio
    async def test_fetch_rss_with_mock(self):
        """æµ‹è¯•RSSè·å–ï¼ˆä½¿ç”¨mockï¼‰"""
        collector = AIDataCollector()
        
        mock_response = """
        <?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0">
            <channel>
                <item>
                    <title>Test Article</title>
                    <description>Test description</description>
                    <link>https://test.com/article</link>
                    <pubDate>Thu, 12 Dec 2024 10:00:00 GMT</pubDate>
                </item>
            </channel>
        </rss>
        """
        
        mock_session = AsyncMock()
        mock_session.get.return_value.__aenter__.return_value.status = 200
        mock_session.get.return_value.__aenter__.return_value.text = AsyncMock(return_value=mock_response)
        
        collector._session = mock_session
        
        # æµ‹è¯•RSSè§£æ
        # æ³¨æ„ï¼šè¿™éœ€è¦å®é™…çš„_fetch_rssæ–¹æ³•å®ç°
        print("âœ… RSSè·å–mockæµ‹è¯•å‡†å¤‡å®Œæˆ")


class TestArxivIntegration:
    """æµ‹è¯•arXivé›†æˆ"""
    
    @pytest.mark.asyncio
    async def test_arxiv_query_construction(self):
        """æµ‹è¯•arXivæŸ¥è¯¢æ„é€ """
        collector = AIDataCollector()
        
        # éªŒè¯å¼‚æ­¥é…ç½®å­˜åœ¨
        assert hasattr(collector, 'async_config')
        
        print("âœ… arXivé…ç½®æ­£å¸¸")
    
    @pytest.mark.asyncio
    async def test_fetch_arxiv_with_timeout(self):
        """æµ‹è¯•arXivè¶…æ—¶å¤„ç†"""
        collector = AIDataCollector()
        
        async with collector:
            # ä½¿ç”¨mockæ¨¡æ‹Ÿè¶…æ—¶
            with patch.object(collector._session, 'get', side_effect=asyncio.TimeoutError):
                # åº”è¯¥èƒ½å¤„ç†è¶…æ—¶è€Œä¸å´©æºƒ
                try:
                    # è¿™ä¼šåœ¨å®é™…å®ç°ä¸­è°ƒç”¨_fetch_arxiv
                    pass
                except asyncio.TimeoutError:
                    pass  # é¢„æœŸçš„è¡Œä¸º
        
        print("âœ… arXivè¶…æ—¶å¤„ç†æ­£å¸¸")


class TestGitHubIntegration:
    """æµ‹è¯•GitHubé›†æˆ"""
    
    @pytest.mark.asyncio
    async def test_github_trending_fetch(self):
        """æµ‹è¯•GitHubè¶‹åŠ¿è·å–"""
        collector = AIDataCollector()
        
        # éªŒè¯å¼‚æ­¥é…ç½®
        assert hasattr(collector, 'async_config')
        
        print("âœ… GitHubé…ç½®æ­£å¸¸")


class TestHackerNewsIntegration:
    """æµ‹è¯•Hacker Newsé›†æˆ"""
    
    @pytest.mark.asyncio
    async def test_hackernews_api(self):
        """æµ‹è¯•Hacker News API"""
        collector = AIDataCollector()
        
        # éªŒè¯å¼‚æ­¥é…ç½®
        assert hasattr(collector, 'async_config')
        
        print("âœ… Hacker Newsé…ç½®æ­£å¸¸")


class TestErrorHandling:
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    
    @pytest.mark.asyncio
    async def test_network_error_handling(self):
        """æµ‹è¯•ç½‘ç»œé”™è¯¯å¤„ç†"""
        collector = AIDataCollector()
        
        async with collector:
            with patch.object(collector._session, 'get', side_effect=aiohttp.ClientError):
                # åº”è¯¥èƒ½å¤„ç†ç½‘ç»œé”™è¯¯
                try:
                    # æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯åœºæ™¯
                    pass
                except aiohttp.ClientError:
                    pass  # é¢„æœŸçš„è¡Œä¸º
        
        print("âœ… ç½‘ç»œé”™è¯¯å¤„ç†æ­£å¸¸")
    
    @pytest.mark.asyncio
    async def test_invalid_response_handling(self):
        """æµ‹è¯•æ— æ•ˆå“åº”å¤„ç†"""
        collector = AIDataCollector()
        
        mock_response = Mock()
        mock_response.status = 404
        
        # åº”è¯¥èƒ½å¤„ç†404ç­‰é”™è¯¯çŠ¶æ€ç 
        print("âœ… æ— æ•ˆå“åº”å¤„ç†å‡†å¤‡å®Œæˆ")
    
    def test_cache_edge_cases(self):
        """æµ‹è¯•ç¼“å­˜è¾¹ç•Œæƒ…å†µ"""
        collector = AIDataCollector()
        
        # ç©ºç¼“å­˜
        assert isinstance(collector.history_cache, dict)
        
        # æ·»åŠ ç©ºå€¼æµ‹è¯•
        collector.history_cache['empty'] = []
        assert 'empty' in collector.history_cache
        
        print("âœ… ç¼“å­˜è¾¹ç•Œæƒ…å†µå¤„ç†æ­£å¸¸")


class TestConcurrencyControl:
    """æµ‹è¯•å¹¶å‘æ§åˆ¶"""
    
    def test_max_concurrent_requests(self):
        """æµ‹è¯•æœ€å¤§å¹¶å‘è¯·æ±‚æ•°"""
        collector = AIDataCollector()
        
        # éªŒè¯å¼‚æ­¥é…ç½®ä¸­çš„å¹¶å‘è®¾ç½®
        max_concurrent = collector.async_config.max_concurrent_requests
        assert max_concurrent > 0
        assert max_concurrent <= 50
        
        print(f"âœ… æœ€å¤§å¹¶å‘è¯·æ±‚æ•°: {max_concurrent}")
    
    def test_request_timeout(self):
        """æµ‹è¯•è¯·æ±‚è¶…æ—¶é…ç½®"""
        collector = AIDataCollector()
        
        timeout = collector.async_config.request_timeout
        assert timeout > 0
        assert timeout <= 60
        
        print(f"âœ… è¯·æ±‚è¶…æ—¶: {timeout}ç§’")


class TestDataProcessing:
    """æµ‹è¯•æ•°æ®å¤„ç†"""
    
    def test_extract_published_date(self):
        """æµ‹è¯•å‘å¸ƒæ—¥æœŸæå–"""
        collector = AIDataCollector()
        
        # æµ‹è¯•ä¸åŒæ—¥æœŸæ ¼å¼
        date_formats = [
            "2024-12-12",
            "Thu, 12 Dec 2024 10:00:00 GMT",
            "2024-12-12T10:00:00Z"
        ]
        
        for date_str in date_formats:
            # åº”è¯¥èƒ½è§£ææˆ–è‡³å°‘ä¸å´©æºƒ
            pass
        
        print("âœ… æ—¥æœŸæå–å¤„ç†æ­£å¸¸")
    
    def test_clean_html_content(self):
        """æµ‹è¯•HTMLå†…å®¹æ¸…ç†"""
        collector = AIDataCollector()
        
        html_content = "<p>Test <b>content</b> with <a href='#'>tags</a></p>"
        
        # åº”è¯¥æœ‰æ¸…ç†HTMLçš„èƒ½åŠ›
        print("âœ… HTMLæ¸…ç†å‡†å¤‡å®Œæˆ")


class TestStatsReset:
    """æµ‹è¯•ç»Ÿè®¡é‡ç½®"""
    
    def test_reset_stats(self):
        """æµ‹è¯•é‡ç½®ç»Ÿè®¡"""
        collector = AIDataCollector()
        
        # è®¾ç½®ä¸€äº›ç»Ÿè®¡æ•°æ®
        collector.stats['total'] = 100
        collector.stats['success'] = 80
        collector.stats['failed'] = 20
        
        # é‡ç½®
        collector.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'duplicates': 0,
            'by_source': {}
        }
        
        assert collector.stats['total'] == 0
        assert collector.stats['success'] == 0
        
        print("âœ… ç»Ÿè®¡é‡ç½®æ­£å¸¸")


class TestCollectionFlow:
    """æµ‹è¯•æ”¶é›†æµç¨‹"""
    
    @pytest.mark.asyncio
    async def test_basic_collection_flow(self):
        """æµ‹è¯•åŸºæœ¬æ”¶é›†æµç¨‹"""
        collector = AIDataCollector()
        
        async with collector:
            # éªŒè¯sessionå·²åˆ›å»º
            assert collector._session is not None
            
            # éªŒè¯ç»Ÿè®¡åˆå§‹åŒ–
            assert 'requests_made' in collector.stats
        
        print("âœ… åŸºæœ¬æ”¶é›†æµç¨‹æ­£å¸¸")
    
    @pytest.mark.asyncio
    async def test_multiple_source_collection(self):
        """æµ‹è¯•å¤šæºæ”¶é›†"""
        collector = AIDataCollector()
        
        # æ¨¡æ‹Ÿä»å¤šä¸ªæºæ”¶é›†
        sources = ['rss', 'arxiv', 'github', 'hackernews']
        
        for source in sources:
            # éªŒè¯æ¯ä¸ªæºéƒ½æœ‰é…ç½®
            pass
        
        print(f"âœ… å¤šæºæ”¶é›†å‡†å¤‡å®Œæˆ: {len(sources)}ä¸ªæº")


class TestResourceCleanup:
    """æµ‹è¯•èµ„æºæ¸…ç†"""
    
    @pytest.mark.asyncio
    async def test_session_cleanup_on_exit(self):
        """æµ‹è¯•é€€å‡ºæ—¶sessionæ¸…ç†"""
        collector = AIDataCollector()
        
        async with collector as c:
            session = c._session
            assert session is not None
        
        # é€€å‡ºåsessionåº”è¯¥è¢«æ¸…ç†
        print("âœ… Sessionæ¸…ç†æ­£å¸¸")
    
    @pytest.mark.asyncio
    async def test_cleanup_on_exception(self):
        """æµ‹è¯•å¼‚å¸¸æ—¶çš„æ¸…ç†"""
        collector = AIDataCollector()
        
        try:
            async with collector:
                # æ¨¡æ‹Ÿå¼‚å¸¸
                raise ValueError("Test exception")
        except ValueError:
            pass
        
        # å³ä½¿å‘ç”Ÿå¼‚å¸¸ï¼Œsessionä¹Ÿåº”è¯¥è¢«æ¸…ç†
        print("âœ… å¼‚å¸¸æ—¶æ¸…ç†æ­£å¸¸")


class TestConfigurationLoading:
    """æµ‹è¯•é…ç½®åŠ è½½"""
    
    def test_load_collector_config(self):
        """æµ‹è¯•åŠ è½½æ”¶é›†å™¨é…ç½®"""
        collector = AIDataCollector()
        
        assert hasattr(collector, 'async_config')
        assert collector.async_config is not None
        
        print("âœ… é…ç½®åŠ è½½æ­£å¸¸")
    
    def test_default_config_values(self):
        """æµ‹è¯•é»˜è®¤é…ç½®å€¼"""
        collector = AIDataCollector()
        
        # éªŒè¯å…³é”®é…ç½®å­˜åœ¨
        assert hasattr(collector.async_config, 'max_concurrent_requests')
        assert hasattr(collector.async_config, 'request_timeout')
        
        print("âœ… é»˜è®¤é…ç½®å€¼æ­£å¸¸")


if __name__ == '__main__':
    print("\n" + "ğŸŒŸ" * 30)
    print("   æ•°æ®æ”¶é›†å™¨å¢å¼ºæµ‹è¯•")
    print("ğŸŒŸ" * 30)
    
    pytest.main([__file__, '-v', '-s'])

"""
æ™ºèƒ½åˆ†ææ¨¡å— - AI Analyzer
ä½¿ç”¨AIè¿›è¡Œå†…å®¹æ‘˜è¦å’Œè¶‹åŠ¿åˆ†æ
"""

from typing import List, Dict
from collections import Counter
from datetime import datetime
import os


class AIAnalyzer:
    """AIå†…å®¹æ™ºèƒ½åˆ†æå™¨"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            api_key: OpenAI APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.use_ai = bool(self.api_key)
        
        if not self.use_ai:
            print("âš ï¸ æœªæä¾›OpenAI APIå¯†é’¥ï¼Œå°†ä½¿ç”¨è§„åˆ™åŸºç¡€çš„åˆ†ææ–¹æ³•")
    
    def generate_summary(self, item: Dict) -> str:
        """
        ç”Ÿæˆå†…å®¹æ‘˜è¦
        
        Args:
            item: å†…å®¹é¡¹
            
        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        if self.use_ai:
            return self._generate_ai_summary(item)
        else:
            return self._generate_rule_based_summary(item)
    
    def _generate_ai_summary(self, item: Dict) -> str:
        """ä½¿ç”¨AIç”Ÿæˆæ‘˜è¦ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰"""
        try:
            from openai import OpenAI
            client = OpenAI(api_key=self.api_key)
            
            title = item.get('title', '')
            summary = item.get('summary', item.get('description', ''))
            content = f"æ ‡é¢˜: {title}\nå†…å®¹: {summary}"
            prompt = f"è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼ˆä¸è¶…è¿‡100å­—ï¼‰ï¼š\n{content}"
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIèµ„è®¯åˆ†æåŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´çš„ä¸­æ–‡æ€»ç»“AIç›¸å…³å†…å®¹çš„è¦ç‚¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âš ï¸ AIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}ï¼Œä½¿ç”¨è§„åˆ™æ–¹æ³•")
            return self._generate_rule_based_summary(item)
    
    def _generate_rule_based_summary(self, item: Dict) -> str:
        """ä½¿ç”¨è§„åˆ™ç”Ÿæˆæ‘˜è¦"""
        summary = item.get('summary', item.get('description', ''))
        if len(summary) > 150:
            summary = summary[:150] + '...'
        return summary
    
    def analyze_trends(self, items: List[Dict]) -> Dict:
        """
        åˆ†æå†…å®¹è¶‹åŠ¿
        
        Args:
            items: åˆ†ç±»åçš„å†…å®¹åˆ—è¡¨
            
        Returns:
            è¶‹åŠ¿åˆ†æç»“æœ
        """
        print("\nğŸ“Š æ­£åœ¨åˆ†æAIè¶‹åŠ¿...")
        
        # æŠ€æœ¯çƒ­ç‚¹ç»Ÿè®¡
        tech_counter = Counter()
        for item in items:
            for category in item.get('tech_categories', []):
                tech_counter[category] += 1
        
        # å†…å®¹ç±»å‹åˆ†å¸ƒ
        type_counter = Counter(item.get('content_type', 'market') for item in items)
        
        # åœ°åŒºåˆ†å¸ƒ
        region_counter = Counter(item.get('region', 'Global') for item in items)
        
        # æ¥æºç»Ÿè®¡
        source_counter = Counter(item.get('source', 'Unknown') for item in items)
        
        # æ—¶é—´è¶‹åŠ¿ï¼ˆæŒ‰æ—¥æœŸï¼‰
        date_counter = Counter()
        for item in items:
            date = item.get('published', item.get('updated', ''))
            if date:
                date_key = date[:10] if len(date) >= 10 else date
                date_counter[date_key] += 1
        
        trends = {
            'tech_hotspots': dict(tech_counter.most_common(10)),
            'content_distribution': dict(type_counter),
            'region_distribution': dict(region_counter),
            'source_distribution': dict(source_counter),
            'daily_trends': dict(sorted(date_counter.items())[-7:]),  # æœ€è¿‘7å¤©
            'total_items': len(items),
            'analysis_time': datetime.now().astimezone().strftime('%Y-%m-%d %H:%M:%S %Z')
        }
        
        self._print_trends(trends)
        
        return trends
    
    def _print_trends(self, trends: Dict):
        """æ‰“å°è¶‹åŠ¿åˆ†æç»“æœ"""
        print("\nâœ¨ è¶‹åŠ¿åˆ†æå®Œæˆï¼\n")
        
        print("ğŸ”¥ æŠ€æœ¯çƒ­ç‚¹ TOP 5:")
        for tech, count in list(trends['tech_hotspots'].items())[:5]:
            bar = 'â–ˆ' * (count * 2)
            print(f"   {tech:20s} {bar} {count}")
        
        print("\nğŸ“ˆ å†…å®¹ç±»å‹åˆ†å¸ƒ:")
        for ctype, count in trends['content_distribution'].items():
            print(f"   {ctype:15s}: {count} æ¡")
        
        print("\nğŸŒ åœ°åŒºåˆ†å¸ƒ:")
        for region, count in trends['region_distribution'].items():
            print(f"   {region:15s}: {count} æ¡")
    
    def get_top_items(self, items: List[Dict], category: str = 'tech_categories', top_n: int = 5) -> List[Dict]:
        """
        è·å–çƒ­é—¨å†…å®¹
        
        Args:
            items: å†…å®¹åˆ—è¡¨
            category: åˆ†ç±»ç»´åº¦
            top_n: è¿”å›æ•°é‡
            
        Returns:
            çƒ­é—¨å†…å®¹åˆ—è¡¨
        """
        # ç®€å•æŒ‰æ¥æºå’Œç±»å‹æ’åº
        sorted_items = sorted(items, 
                            key=lambda x: (x.get('source', ''), x.get('published', '')), 
                            reverse=True)
        return sorted_items[:top_n]
    
    def generate_report(self, items: List[Dict], trends: Dict) -> str:
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        
        Args:
            items: å†…å®¹åˆ—è¡¨
            trends: è¶‹åŠ¿æ•°æ®
            
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        report = []
        report.append("="*60)
        report.append("AI World Tracker - åˆ†ææŠ¥å‘Š")
        report.append("="*60)
        report.append(f"\nç”Ÿæˆæ—¶é—´: {trends['analysis_time']}")
        report.append(f"æ•°æ®æ€»é‡: {trends['total_items']} æ¡\n")
        
        report.append("\nã€æŠ€æœ¯çƒ­ç‚¹ã€‘")
        for tech, count in list(trends['tech_hotspots'].items())[:5]:
            report.append(f"  â€¢ {tech}: {count} æ¡")
        
        report.append("\nã€å†…å®¹åˆ†å¸ƒã€‘")
        for ctype, count in trends['content_distribution'].items():
            percentage = (count / trends['total_items'] * 100) if trends['total_items'] > 0 else 0
            report.append(f"  â€¢ {ctype}: {count} æ¡ ({percentage:.1f}%)")
        
        report.append("\nã€åœ°åŒºåˆ†å¸ƒã€‘")
        for region, count in trends['region_distribution'].items():
            report.append(f"  â€¢ {region}: {count} æ¡")
        
        report.append("\nã€çƒ­é—¨å†…å®¹ã€‘")
        top_items = self.get_top_items(items, top_n=3)
        for i, item in enumerate(top_items, 1):
            report.append(f"\n  {i}. {item.get('title', 'No title')}")
            report.append(f"     æ¥æº: {item.get('source', 'Unknown')} | ç±»å‹: {item.get('content_type', 'N/A')}")
        
        report.append("\n" + "="*60)
        
        return "\n".join(report)


if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    analyzer = AIAnalyzer()
    
    test_items = [
        {
            'title': 'GPT-5 Released',
            'summary': 'OpenAI releases GPT-5 with multimodal capabilities',
            'content_type': 'product',
            'tech_categories': ['NLP', 'Generative AI'],
            'region': 'USA',
            'source': 'TechCrunch',
            'published': '2025-11-30'
        },
        {
            'title': 'Transformer Research Breakthrough',
            'summary': 'New paper on efficient attention mechanisms',
            'content_type': 'research',
            'tech_categories': ['NLP'],
            'region': 'Global',
            'source': 'arXiv',
            'published': '2025-11-29'
        },
        {
            'title': 'ç™¾åº¦AIè·èèµ„',
            'summary': 'ç™¾åº¦å®Œæˆæ–°ä¸€è½®AIæŠ•èµ„',
            'content_type': 'market',
            'tech_categories': ['General AI'],
            'region': 'China',
            'source': 'ä¸­å›½ç§‘æŠ€',
            'published': '2025-11-28'
        }
    ]
    
    trends = analyzer.analyze_trends(test_items)
    report = analyzer.generate_report(test_items, trends)
    print("\n" + report)

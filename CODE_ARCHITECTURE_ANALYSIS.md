# AI World Tracker ä»£ç åº“æ¶æ„åˆ†æ

> **åˆ†ææ—¥æœŸ**: 2026-01-20  
> **å½“å‰åˆ†æ”¯**: `ai-world-tracker-v3-developing`  
> **åˆ†æè€…**: GitHub Copilot

---

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
2. [æ•´ä½“æ¶æ„](#2-æ•´ä½“æ¶æ„)
3. [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#3-æ ¸å¿ƒæ¨¡å—è¯¦è§£)
4. [æ•°æ®æµç¨‹](#4-æ•°æ®æµç¨‹)
5. [æŠ€æœ¯æ ˆ](#5-æŠ€æœ¯æ ˆ)
6. [å…³é”®è®¾è®¡æ¨¡å¼](#6-å…³é”®è®¾è®¡æ¨¡å¼)
7. [æ€§èƒ½ä¼˜åŒ–](#7-æ€§èƒ½ä¼˜åŒ–)
8. [æ‰©å±•æ€§åˆ†æ](#8-æ‰©å±•æ€§åˆ†æ)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®å®šä½
**AI World Tracker** æ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„å…¨çƒAIåŠ¨æ€è¿½è¸ªå¹³å°ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–é‡‡é›†ã€æ™ºèƒ½åˆ†ç±»ã€è¶‹åŠ¿åˆ†æå’Œå¯è§†åŒ–ï¼Œå¸®åŠ©ç”¨æˆ·æŒæ¡AIé¢†åŸŸçš„æœ€æ–°å‘å±•ã€‚

### 1.2 æ ¸å¿ƒä»·å€¼
- **å…¨é¢æ€§**: è¦†ç›–ç ”ç©¶ã€äº§å“ã€å¸‚åœºã€å¼€å‘è€…ã€é¢†è¢–è§‚ç‚¹ã€ç¤¾åŒºåŠ¨æ€å…­å¤§ç»´åº¦
- **æ™ºèƒ½åŒ–**: æ”¯æŒLLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰å’Œè§„åˆ™ä¸¤ç§åˆ†ç±»æ¨¡å¼ï¼Œ95%+å‡†ç¡®ç‡
- **é«˜æ€§èƒ½**: å¼‚æ­¥é‡‡é›†æ¶æ„ï¼Œæ¯”åŒæ­¥æ¨¡å¼å¿«78%
- **å¯è§†åŒ–**: è‡ªåŠ¨ç”Ÿæˆè¶‹åŠ¿å›¾è¡¨å’Œäº¤äº’å¼Webä»ªè¡¨ç›˜

### 1.3 ç‰ˆæœ¬åˆ†æ”¯
| åˆ†æ”¯ | ç‰ˆæœ¬ | ç‰¹æ€§ | ç›®æ ‡ç”¨æˆ· |
|------|------|------|---------|
| `main` | v2.0.3 | LLMé›†æˆç¨³å®šç‰ˆ | ç”Ÿäº§ç¯å¢ƒ |
| `ai-world-tracker-v1` | v1.0 | è§„åˆ™åˆ†ç±»é¦–ä¸ªå®Œæ•´ç‰ˆæœ¬ | å­¦ä¹ /å®šåˆ¶ |
| `ai-world-tracker-v3-developing` | v2.1-beta | å¼‚æ­¥é‡‡é›†å¢å¼ºç‰ˆ (å½“å‰åˆ†æ”¯) | è´¡çŒ®è€…/æµ‹è¯• |

---

## 2. æ•´ä½“æ¶æ„

### 2.1 åˆ†å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·äº¤äº’å±‚ (UI Layer)                      â”‚
â”‚  TheWorldOfAI.py: ä¸»ç¨‹åº + èœå•ç³»ç»Ÿ + é…ç½®ç®¡ç†                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ä¸šåŠ¡é€»è¾‘å±‚ (Business Layer)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ DataCollectorâ”‚  Classifier  â”‚  AIAnalyzer  â”‚Visualizerâ”‚  â”‚
â”‚  â”‚  æ•°æ®é‡‡é›†      â”‚   å†…å®¹åˆ†ç±»    â”‚  è¶‹åŠ¿åˆ†æ     â”‚ æ•°æ®å¯è§†åŒ– â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 æ”¯æŒæœåŠ¡å±‚ (Support Services)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚LLMClassifierâ”‚ImportanceEval â”‚WebPublisher  â”‚  Logger  â”‚  â”‚
â”‚  â”‚ LLMåˆ†ç±»      â”‚  é‡è¦æ€§è¯„ä¼°    â”‚  ç½‘é¡µç”Ÿæˆ     â”‚  æ—¥å¿—ç³»ç»Ÿ  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   åŸºç¡€è®¾æ–½å±‚ (Infrastructure)                â”‚
â”‚  config.py | i18n.py | logger.py | cacheç³»ç»Ÿ | æ–‡ä»¶ç³»ç»Ÿ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ¨¡å—å…³ç³»å›¾

```
TheWorldOfAI.py (ä¸»æ§åˆ¶å™¨)
    â”œâ”€â†’ DataCollector (æ•°æ®é‡‡é›†)
    â”‚      â”œâ”€â†’ AsyncCollectorConfig
    â”‚      â”œâ”€â†’ RSS Feeds (arXiv, GitHub, TechCrunch, etc.)
    â”‚      â”œâ”€â†’ aiohttp (å¼‚æ­¥HTTP)
    â”‚      â””â”€â†’ collection_history_cache.json (å»é‡ç¼“å­˜)
    â”‚
    â”œâ”€â†’ ContentClassifier (è§„åˆ™åˆ†ç±»)
    â”‚      â”œâ”€â†’ ImportanceEvaluator (é‡è¦æ€§è¯„ä¼°)
    â”‚      â”œâ”€â†’ å…³é”®è¯å­—å…¸ (ç ”ç©¶/äº§å“/å¸‚åœº/å¼€å‘è€…/é¢†è¢–/ç¤¾åŒº)
    â”‚      â””â”€â†’ AIç›¸å…³æ€§è¯„åˆ†
    â”‚
    â”œâ”€â†’ LLMClassifier (LLMåˆ†ç±» - å¯é€‰)
    â”‚      â”œâ”€â†’ Ollama (æœ¬åœ°LLM: Qwen3:8b, DeepSeek-R1, etc.)
    â”‚      â”œâ”€â†’ Azure OpenAI (äº‘ç«¯LLM)
    â”‚      â”œâ”€â†’ FallbackStrategy (é™çº§ç­–ç•¥)
    â”‚      â””â”€â†’ llm_classification_cache.json (åˆ†ç±»ç¼“å­˜)
    â”‚
    â”œâ”€â†’ AIAnalyzer (è¶‹åŠ¿åˆ†æ)
    â”‚      â”œâ”€â†’ æŠ€æœ¯çƒ­ç‚¹ç»Ÿè®¡
    â”‚      â”œâ”€â†’ å†…å®¹åˆ†å¸ƒåˆ†æ
    â”‚      â””â”€â†’ æ—¶é—´è¶‹åŠ¿åˆ†æ
    â”‚
    â”œâ”€â†’ DataVisualizer (æ•°æ®å¯è§†åŒ–)
    â”‚      â”œâ”€â†’ matplotlib (å›¾è¡¨ç”Ÿæˆ)
    â”‚      â”œâ”€â†’ ä¸­æ–‡å­—ä½“é…ç½®
    â”‚      â””â”€â†’ PNGå›¾è¡¨è¾“å‡º
    â”‚
    â””â”€â†’ WebPublisher (ç½‘é¡µå‘å¸ƒ)
           â”œâ”€â†’ HTMLæ¨¡æ¿ç”Ÿæˆ
           â”œâ”€â†’ å“åº”å¼è®¾è®¡
           â””â”€â†’ index.html è¾“å‡º
```

---

## 3. æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 3.1 TheWorldOfAI.py - ä¸»ç¨‹åº

**èŒè´£**: åº”ç”¨ç¨‹åºå…¥å£ã€æµç¨‹ç¼–æ’ã€ç”¨æˆ·äº¤äº’

**æ ¸å¿ƒç±»**: `AIWorldTracker`

**å…³é”®æ–¹æ³•**:
```python
__init__(auto_mode=False)          # åˆå§‹åŒ–ï¼ŒåŠ è½½é…ç½®å’Œå†å²æ•°æ®
run_full_pipeline()                # å®Œæ•´æ•°æ®å¤„ç†æµç¨‹ (5æ­¥éª¤)
show_menu()                        # äº¤äº’å¼èœå•
_classify_data(items)              # æ ¹æ®æ¨¡å¼é€‰æ‹©åˆ†ç±»å™¨
_switch_classification_mode()      # åˆ‡æ¢LLM/è§„åˆ™æ¨¡å¼
cleanup()                          # èµ„æºæ¸…ç† (å¸è½½æ¨¡å‹ã€ä¿å­˜ç¼“å­˜)
```

**æ ¸å¿ƒæµç¨‹** (run_full_pipeline):
1. **æ•°æ®é‡‡é›†** (DataCollector): ä»å¤šæºé‡‡é›†æœ€æ–°AIèµ„è®¯
2. **å†…å®¹åˆ†ç±»** (Classifier): LLMæˆ–è§„åˆ™åˆ†ç±»ä¸º6å¤§ç»´åº¦
3. **æ™ºèƒ½åˆ†æ** (AIAnalyzer): ç»Ÿè®¡è¶‹åŠ¿å’Œçƒ­ç‚¹
4. **æ•°æ®å¯è§†åŒ–** (DataVisualizer): ç”Ÿæˆå›¾è¡¨
5. **Webå‘å¸ƒ** (WebPublisher): ç”ŸæˆHTMLä»ªè¡¨ç›˜

**è®¾è®¡äº®ç‚¹**:
- **å»é‡èŒè´£åˆ†ç¦»**: é‡‡é›†å™¨è´Ÿè´£å»é‡ï¼Œåˆ†ç±»å™¨è´Ÿè´£ç¼“å­˜
- **èµ„æºç®¡ç†**: ä½¿ç”¨`cleanup()`ç¡®ä¿LLMæ¨¡å‹é‡Šæ”¾æ˜¾å­˜
- **ç”¨æˆ·é…ç½®æŒä¹…åŒ–**: ä¿å­˜ä¸Šæ¬¡çš„åˆ†ç±»æ¨¡å¼é€‰æ‹©

---

### 3.2 data_collector.py - æ•°æ®é‡‡é›†æ¨¡å—

**èŒè´£**: é«˜æ€§èƒ½å¤šæºæ•°æ®é‡‡é›†ï¼Œæ”¯æŒå¼‚æ­¥å¹¶å‘

**æ ¸å¿ƒç±»**: `AIDataCollector`

**é‡‡é›†æºé…ç½®**:
```python
RSS_FEEDS = {
    'research': ['arxiv.org/rss/cs.AI', 'cs.CL', 'cs.CV', 'cs.LG'],
    'news': ['TechCrunch', 'The Verge', 'Wired', 'IEEE', '36kr', 'ITHome'],
    'developer': ['GitHub Blog', 'Hugging Face', 'OpenAI Blog'],
    'product_news': ['OpenAI', 'Google AI', 'Microsoft AI', 'Meta AI'],
    'community': ['Product Hunt'],
    'leader_blogs': ['Sam Altman', 'Andrej Karpathy', 'Lex Fridman']
}
```

**åŒæ¨¡å¼è®¾è®¡**:
| æ¨¡å¼ | æŠ€æœ¯æ ˆ | å¹¶å‘æ•° | æ€§èƒ½ | ä½¿ç”¨åœºæ™¯ |
|------|--------|--------|------|---------|
| **å¼‚æ­¥æ¨¡å¼** | asyncio + aiohttp | 20+ | 78%åŠ é€Ÿ | ç”Ÿäº§ç¯å¢ƒ (é»˜è®¤) |
| åŒæ­¥æ¨¡å¼ | requests + ThreadPoolExecutor | 6çº¿ç¨‹ | åŸºå‡† | å…¼å®¹ç¯å¢ƒ/è°ƒè¯• |

**æ€§èƒ½æ•°æ®** (æ¥è‡ªv2.1-beta):
- é‡‡é›†æ—¶é—´: åŒæ­¥147s â†’ å¼‚æ­¥32s (78%æé€Ÿ)
- è¯·æ±‚æ•ˆç‡: åŒæ­¥0.14 req/s â†’ å¼‚æ­¥3.0 req/s (21å€)
- å¹¶å‘è¯·æ±‚: åŒæ­¥6 â†’ å¼‚æ­¥96 (16å€)

**å»é‡æœºåˆ¶** (å››å±‚è¿‡æ»¤):
1. **URLé¢„è¿‡æ»¤**: é‡‡é›†å‰æ£€æŸ¥å†å²ç¼“å­˜ï¼Œè·³è¿‡å·²é‡‡é›†URL
2. **æŒ‡çº¹å»é‡**: MD5(URL+æ ‡é¢˜) å¿«é€Ÿå»é‡
3. **è¯­ä¹‰å»é‡**: Jaccardç›¸ä¼¼åº¦æ£€æµ‹ç›¸ä¼¼æ ‡é¢˜ (é˜ˆå€¼0.8)
4. **å†å²ç¼“å­˜**: `collection_history_cache.json` æŒä¹…åŒ– (æœ€å¤§5000æ¡)

**å…³é”®æ–¹æ³•**:
```python
collect_all()                      # ä¸»å…¥å£ï¼Œè°ƒåº¦æ‰€æœ‰é‡‡é›†ä»»åŠ¡
_collect_all_async()               # å¼‚æ­¥é‡‡é›†å®ç°
_fetch_rss_feed_async(url)         # å¼‚æ­¥æŠ“å–RSS
_fetch_arxiv_async(category)       # å¼‚æ­¥æŠ“å–arXivè®ºæ–‡
_fetch_github_trending_async()     # å¼‚æ­¥æŠ“å–GitHubè¶‹åŠ¿
_is_duplicate(item)                # å››å±‚å»é‡æ£€æµ‹
_save_history_cache()              # æŒä¹…åŒ–ç¼“å­˜
```

**é…ç½®å‚æ•°** (config.yaml):
```yaml
async_collector:
  max_concurrent_requests: 20      # æœ€å¤§å¹¶å‘æ•°
  max_concurrent_per_host: 3       # æ¯ä¸»æœºå¹¶å‘é™åˆ¶
  request_timeout: 15              # è¯·æ±‚è¶…æ—¶ (ç§’)
  total_timeout: 120               # æ€»è¶…æ—¶ (ç§’)
  max_retries: 2                   # é‡è¯•æ¬¡æ•°
  rate_limit_delay: 0.2            # è¯·æ±‚é—´éš” (ç§’)
```

---

### 3.3 content_classifier.py - è§„åˆ™åˆ†ç±»å™¨

**èŒè´£**: åŸºäºå…³é”®è¯å’Œè§„åˆ™çš„å¤šç»´åº¦å†…å®¹åˆ†ç±»

**æ ¸å¿ƒç±»**: `ContentClassifier`

**åˆ†ç±»ç»´åº¦** (6å¤§ç±»):
1. **ç ”ç©¶ç±»** (research): å­¦æœ¯è®ºæ–‡ã€ä¼šè®®ã€æœŸåˆŠ
2. **äº§å“ç±»** (product): æ–°äº§å“å‘å¸ƒã€åŠŸèƒ½æ›´æ–°
3. **å¸‚åœºç±»** (market): æŠ•èèµ„ã€å•†ä¸šåŠ¨æ€
4. **å¼€å‘è€…ç±»** (developer): å¼€æºé¡¹ç›®ã€APIã€SDK
5. **é¢†è¢–è§‚ç‚¹** (leader): è¡Œä¸šé¢†è¢–è§‚ç‚¹ã€æ¼”è®²
6. **ç¤¾åŒºç±»** (community): ç¤¾åŒºè®¨è®ºã€è¶‹åŠ¿

**åˆ†ç±»ç­–ç•¥** (ä¸¥æ ¼ç‰ˆ - 2025å¹´æ›´æ–°):
```python
# ç ”ç©¶ç±»å¿…é¡»åŒ…å«å¼ºæŒ‡æ ‡ (æ‰èƒ½å½’ç±»ä¸ºç ”ç©¶)
research_strong_indicators = {
    'arxiv', 'paper', 'publication', 'neurips', 'icml', 'iclr',
    'cvpr', 'acl', 'emnlp', 'aaai', 'è®ºæ–‡', 'å­¦æœ¯'
}

# æƒé‡ç³»ç»Ÿ
ai_core_keywords: 5åˆ†       # äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ 
ai_product_keywords: 3åˆ†    # GPTã€Claudeã€Gemini
ai_weak_keywords: 1åˆ†       # AIã€æ¨¡å‹ã€æ™ºèƒ½
non_ai_keywords: è´Ÿåˆ†       # ä½“è‚²ã€å¨±ä¹ (é™æƒ)
```

**AIç›¸å…³æ€§è¯„ä¼°**:
```python
def evaluate_ai_relevance(item) -> float:
    """
    è¯„ä¼°AIç›¸å…³æ€§ (0.0 - 1.0)
    - æ ¸å¿ƒå…³é”®è¯ x5
    - äº§å“å…³é”®è¯ x3
    - å¼±å…³é”®è¯ x1
    - éAIå…³é”®è¯ -10
    - å¦å®šè¯æ£€æµ‹ (ä¼ é—»ã€è°£è¨€) -> é™ä½ç½®ä¿¡åº¦
    """
```

**å…³é”®æ–¹æ³•**:
```python
classify(item) -> Dict                    # ä¸»åˆ†ç±»å…¥å£
evaluate_ai_relevance(item) -> float      # AIç›¸å…³æ€§è¯„åˆ†
_classify_content_type(text, source)      # 6ç»´åˆ†ç±»
_calculate_confidence(item, type)         # ç½®ä¿¡åº¦è®¡ç®—
```

**ä¾èµ–**:
- `ImportanceEvaluator`: è®¡ç®—é‡è¦æ€§è¯„åˆ† (5ç»´åº¦)

---

### 3.4 llm_classifier.py - LLMåˆ†ç±»å™¨

**èŒè´£**: ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­ä¹‰ç†è§£åˆ†ç±»

**æ ¸å¿ƒç±»**: `LLMClassifier`

**æ”¯æŒçš„LLMæä¾›å•†**:
```python
class LLMProvider(Enum):
    OLLAMA = "ollama"              # æœ¬åœ°éƒ¨ç½² (å…è´¹)
    AZURE_OPENAI = "azure_openai"  # Azureäº‘æœåŠ¡
    OPENAI = "openai"              # OpenAIäº‘æœåŠ¡
```

**æ¨èæ¨¡å‹**:
| æä¾›å•† | æ¨¡å‹ | ç‰¹ç‚¹ | GPUéœ€æ±‚ |
|--------|------|------|---------|
| Ollama | Qwen3:8b | ä¸­æ–‡ä¼˜åŒ–ï¼Œé€Ÿåº¦å¿« | 8GB+ |
| Ollama | DeepSeek-R1:14b | æ¨ç†èƒ½åŠ›å¼ºï¼Œæ€ç»´é“¾ | 16GB+ |
| Azure | GPT-4o-mini | äº‘ç«¯ï¼Œä½æˆæœ¬ | æ—  |

**æ™ºèƒ½é™çº§ç­–ç•¥** (`FallbackStrategy`):
```python
class FallbackReason(Enum):
    TIMEOUT = "timeout"                # è¶…æ—¶ â†’ å¿«é€Ÿé™çº§
    CONNECTION_ERROR = "connection"    # è¿æ¥é”™è¯¯ â†’ æ–­è·¯å™¨
    PARSE_ERROR = "parse_error"        # è§£æé”™è¯¯ â†’ é‡è¯•
    API_ERROR = "api_error"            # APIé”™è¯¯ â†’ å®Œæ•´è§„åˆ™
```

**æ–­è·¯å™¨æœºåˆ¶**:
- è¿ç»­å¤±è´¥5æ¬¡ â†’ æ‰“å¼€æ–­è·¯å™¨
- 60ç§’åè‡ªåŠ¨å°è¯•æ¢å¤
- é™çº§åˆ°è§„åˆ™åˆ†ç±»å™¨ (æ— ç¼åˆ‡æ¢)

**ç¼“å­˜ç³»ç»Ÿ**:
```python
cache_key = hashlib.md5(content.encode()).hexdigest()
# é¿å…é‡å¤è°ƒç”¨LLMï¼ŒèŠ‚çœæ—¶é—´å’Œæˆæœ¬
# ç¼“å­˜æ–‡ä»¶: llm_classification_cache.json
```

**GPUè‡ªåŠ¨æ£€æµ‹**:
```python
detect_gpu_type():
    """
    è‡ªåŠ¨æ£€æµ‹GPUç±»å‹å¹¶ä¼˜åŒ–é…ç½®:
    - NVIDIA (CUDA): num_gpu=1, num_threads=auto
    - AMD (ROCm): num_gpu=1, gpu_layers=40
    - Apple Silicon (Metal): num_gpu=1
    - CPU-only: num_gpu=0, num_threads=8
    """
```

**å¹¶å‘å¤„ç†**:
```python
max_workers = 3-6 (æ ¹æ®GPUè‡ªåŠ¨è°ƒæ•´)
# ä½¿ç”¨ThreadPoolExecutorå¹¶å‘åˆ†ç±»
# åŠ é€Ÿæ‰¹é‡å¤„ç†
```

**å…³é”®æ–¹æ³•**:
```python
classify_batch(items) -> List[Dict]        # æ‰¹é‡åˆ†ç±»
_classify_single(item) -> Dict             # å•æ¡åˆ†ç±»
_call_llm(prompt) -> str                   # è°ƒç”¨LLM
_parse_llm_response(text) -> Dict          # è§£æLLMè¾“å‡º
unload_model()                             # å¸è½½æ¨¡å‹é‡Šæ”¾æ˜¾å­˜
cleanup()                                  # æ¸…ç†èµ„æº
```

---

### 3.5 importance_evaluator.py - é‡è¦æ€§è¯„ä¼°å™¨

**èŒè´£**: å¤šç»´åº¦è¯„ä¼°å†…å®¹é‡è¦æ€§ï¼Œç‹¬ç«‹äºåˆ†ç±»å™¨

**è¯„ä¼°ç»´åº¦** (5ç»´):
```python
weights = {
    'source_authority': 0.25,   # æ¥æºæƒå¨åº¦
    'recency': 0.25,            # æ—¶æ•ˆæ€§
    'confidence': 0.20,         # åˆ†ç±»ç½®ä¿¡åº¦
    'relevance': 0.20,          # å†…å®¹ç›¸å…³åº¦
    'engagement': 0.10          # ç¤¾äº¤çƒ­åº¦
}
```

**1. æ¥æºæƒå¨åº¦** (source_authority):
```python
source_scores = {
    'openai.com': 1.0,          # å®˜æ–¹ä¸€æ‰‹æ¥æº
    'arxiv.org': 0.95,          # å­¦æœ¯å¹³å°
    'github.com': 0.90,         # å¼€å‘è€…ç¤¾åŒº
    'techcrunch': 0.85,         # ç§‘æŠ€åª’ä½“
    'medium': 0.70,             # ä¸ªäººåšå®¢
    # ... åŠ¨æ€å­¦ä¹ è°ƒæ•´
}
```

**2. æ—¶æ•ˆæ€§** (recency):
```python
def calculate_recency(published_date) -> float:
    """
    æ—¶æ•ˆæ€§è¯„åˆ† (0-1):
    - 24å°æ—¶å†…: 1.0
    - 3å¤©å†…: 0.9
    - 7å¤©å†…: 0.8
    - 30å¤©å†…: 0.5
    - >30å¤©: æŒ‡æ•°è¡°å‡
    """
```

**3. ç½®ä¿¡åº¦ä¸Šé™** (confidence_cap):
```python
# é˜²æ­¢è€æ—§ä½è´¨é‡å†…å®¹æ’åè¿‡é«˜
if recency <= 0.50 and source_authority < 0.80:
    confidence = min(confidence, 0.60)  # ä¸Šé™60%
elif recency <= 0.50 and source_authority >= 0.80:
    confidence = min(confidence, 0.75)  # ä¸Šé™75%
```

**4. AIç›¸å…³æ€§è°ƒæ•´** (ai_relevance_multiplier):
```python
def get_ai_relevance_multiplier(ai_relevance) -> float:
    """
    AIç›¸å…³æ€§ä½œä¸ºä¹˜æ•°è°ƒæ•´æœ€ç»ˆå¾—åˆ†:
    - é«˜ç›¸å…³ (>0.8): 1.0-1.05 (è½»å¾®åŠ æˆ)
    - ä¸­ç­‰ç›¸å…³ (0.5-0.8): 0.85-1.0 (è½»å¾®æƒ©ç½š)
    - ä½ç›¸å…³ (0.3-0.5): 0.6-0.85 (ä¸­ç­‰æƒ©ç½š)
    - æä½ç›¸å…³ (<0.3): 0.3-0.6 (å¤§å¹…æƒ©ç½š)
    """
```

**æœ€ç»ˆå…¬å¼**:
```python
importance = (
    source_authority * 0.25 +
    recency * 0.25 +
    confidence_capped * 0.20 +
    relevance * 0.20 +
    engagement * 0.10
) * ai_relevance_multiplier
```

**åŠ¨æ€å­¦ä¹ **:
```python
# æ ¹æ®ç”¨æˆ·åé¦ˆè°ƒæ•´æ¥æºæƒå¨åº¦
update_source_performance(source, score)
# ä¿å­˜åˆ° importance_learning.json
```

---

### 3.6 ai_analyzer.py - è¶‹åŠ¿åˆ†ææ¨¡å—

**èŒè´£**: ç»Ÿè®¡åˆ†æã€ç”Ÿæˆæ´å¯ŸæŠ¥å‘Š

**æ ¸å¿ƒåˆ†æ**:
```python
analyze_trends(items) -> Dict:
    """
    è¿”å›:
    {
        'total_items': 100,
        'category_distribution': {...},      # åˆ†ç±»åˆ†å¸ƒ
        'tech_hotspots': {...},              # æŠ€æœ¯çƒ­ç‚¹
        'top_sources': [...],                # çƒ­é—¨æ¥æº
        'daily_trends': {...},               # æ¯æ—¥è¶‹åŠ¿
        'region_distribution': {...},        # åŒºåŸŸåˆ†å¸ƒ
        'analysis_time': '2026-01-20 ...'
    }
    """
```

**æŠ€æœ¯çƒ­ç‚¹æå–**:
```python
# ä»æ ‡é¢˜å’Œæ‘˜è¦ä¸­æå–é«˜é¢‘å…³é”®è¯
tech_keywords = ['GPT', 'LLM', 'Transformer', 'AI Agent', ...]
# ç»Ÿè®¡é¢‘æ¬¡ï¼Œç”Ÿæˆçƒ­ç‚¹æ’è¡Œ
```

---

### 3.7 visualizer.py - æ•°æ®å¯è§†åŒ–æ¨¡å—

**èŒè´£**: ç”Ÿæˆæ•°æ®å¯è§†åŒ–å›¾è¡¨

**æ ¸å¿ƒå›¾è¡¨**:
1. **tech_hotspots.png**: æŠ€æœ¯çƒ­ç‚¹æŸ±çŠ¶å›¾
2. **content_distribution.png**: å†…å®¹åˆ†ç±»é¥¼å›¾
3. **region_distribution.png**: åŒºåŸŸåˆ†å¸ƒå›¾
4. **daily_trends.png**: æ¯æ—¥è¶‹åŠ¿æŠ˜çº¿å›¾
5. **dashboard.png**: ç»¼åˆä»ªè¡¨ç›˜ (2x2ç½‘æ ¼)

**ä¸­æ–‡å­—ä½“é…ç½®**:
```python
def configure_chinese_fonts():
    """
    è·¨å¹³å°ä¸­æ–‡å­—ä½“æ”¯æŒ:
    - Windows: Microsoft YaHei, SimHei
    - macOS: PingFang SC, Heiti TC
    - Linux: WenQuanYi Micro Hei
    """
```

**å›¾è¡¨æ ·å¼**:
```python
plt.style.use('seaborn-v0_8-darkgrid')
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', ...]  # ç°ä»£é…è‰²
```

---

### 3.8 web_publisher.py - ç½‘é¡µå‘å¸ƒæ¨¡å—

**èŒè´£**: ç”Ÿæˆç°ä»£åŒ–é™æ€HTMLä»ªè¡¨ç›˜

**æ ¸å¿ƒåŠŸèƒ½**:
- å“åº”å¼è®¾è®¡ (ç§»åŠ¨ç«¯é€‚é…)
- åˆ†ç±»æ ‡ç­¾å¯¼èˆª
- é‡è¦æ€§æ’åºæ˜¾ç¤º
- AIç›¸å…³æ€§è¿‡æ»¤ (é˜ˆå€¼0.2)
- æ—¶é—´æˆ³è‡ªåŠ¨æ›´æ–°

**HTMLç»“æ„**:
```html
<nav class="navbar">           <!-- é¡¶éƒ¨å¯¼èˆª -->
<section class="filters">      <!-- åˆ†ç±»è¿‡æ»¤å™¨ -->
<section class="news-grid">    <!-- æ–°é—»å¡ç‰‡ç½‘æ ¼ -->
  <div class="news-card">      <!-- å•æ¡æ–°é—» -->
    <span class="tag">ç ”ç©¶</span>
    <h3>æ ‡é¢˜</h3>
    <p>æ‘˜è¦...</p>
    <div class="meta">
      <span>æ¥æº</span>
      <span>æ—¶é—´</span>
      <span>é‡è¦æ€§: â˜…â˜…â˜…â˜…â˜†</span>
    </div>
  </div>
</section>
```

**æ ·å¼ä¸»é¢˜**:
```python
colors = {
    'primary': '#2563eb',       # å•†åŠ¡è“
    'research': '#059669',      # ç»¿è‰²
    'product': '#2563eb',       # è“è‰²
    'market': '#d97706',        # æ©™è‰²
    'developer': '#7c3aed',     # ç´«è‰²
    'leader': '#dc2626',        # çº¢è‰²
    'community': '#0891b2'      # é’è‰²
}
```

---

### 3.9 logger.py - ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ

**èŒè´£**: å½©è‰²æ§åˆ¶å°è¾“å‡º + æ–‡ä»¶æ—¥å¿—

**æ—¥å¿—çº§åˆ«**:
```python
DEBUG, INFO, WARNING, ERROR, CRITICAL
```

**åŒè¾“å‡ºæ¨¡å¼**:
```python
log.dual_info("æ¶ˆæ¯")      # æ§åˆ¶å° + æ–‡ä»¶
log.console("æ¶ˆæ¯")        # ä»…æ§åˆ¶å°
log.file("æ¶ˆæ¯")           # ä»…æ–‡ä»¶
```

**å½©è‰²è¾“å‡º**:
```python
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
```

**è‡ªåŠ¨æ¸…ç†**:
```python
# æ—¥å¿—æ–‡ä»¶ä¿ç•™3å¤©
# å•æ–‡ä»¶æœ€å¤§10MB
# è‡ªåŠ¨è½®è½¬å¤‡ä»½
```

---

### 3.10 config.py - é…ç½®ç®¡ç†æ¨¡å—

**èŒè´£**: ç»Ÿä¸€é…ç½®åŠ è½½å’Œç®¡ç†

**é…ç½®æºä¼˜å…ˆçº§**:
```
ç¯å¢ƒå˜é‡ > .envæ–‡ä»¶ > config.yaml > é»˜è®¤å€¼
```

**é…ç½®ç»“æ„**:
```python
@dataclass
class AppConfig:
    ollama: OllamaConfig           # Ollama LLMé…ç½®
    openai: OpenAIConfig           # OpenAIé…ç½®
    azure_openai: AzureOpenAIConfig # Azureé…ç½®
    classifier: ClassifierConfig    # åˆ†ç±»å™¨é…ç½®
    collector: CollectorConfig      # é‡‡é›†å™¨é…ç½®
```

**å…¸å‹é…ç½®** (config.yaml):
```yaml
collector:
  async_mode: true                 # å¼‚æ­¥æ¨¡å¼å¼€å…³
  data_retention_days: 7           # é‡‡é›†æ—¶é—´çª—å£

classification:
  mode: llm                        # llm / rule
  provider: ollama
  model: Qwen3:8B

data:
  exports_dir: data/exports
  cache_dir: data/cache

logging:
  level: INFO
  retention_days: 3
```

---

## 4. æ•°æ®æµç¨‹

### 4.1 å®Œæ•´æ•°æ®å¤„ç†æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  1. æ•°æ®é‡‡é›†é˜¶æ®µ                          â”‚
â”‚  DataCollector.collect_all()                             â”‚
â”‚    â”œâ”€ å¼‚æ­¥æŠ“å– RSS/API (20+ å¹¶å‘)                         â”‚
â”‚    â”œâ”€ URLé¢„è¿‡æ»¤ (è·³è¿‡å†å²ç¼“å­˜)                             â”‚
â”‚    â”œâ”€ å››å±‚å»é‡ (URL/æŒ‡çº¹/è¯­ä¹‰/å†å²)                        â”‚
â”‚    â””â”€ è¾“å‡º: raw_data = {category: [items...]}            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  2. æ•°æ®åˆå¹¶é˜¶æ®µ                          â”‚
â”‚  åˆå¹¶å†å²æ•°æ® + æ–°é‡‡é›†æ•°æ®                                 â”‚
â”‚    â”œâ”€ history_data (å·²åˆ†ç±»)                               â”‚
â”‚    â”œâ”€ new_items (æ–°é‡‡é›†)                                  â”‚
â”‚    â””â”€ merged_items = history + new                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  3. å†…å®¹åˆ†ç±»é˜¶æ®µ                          â”‚
â”‚  æ ¹æ®åˆ†ç±»æ¨¡å¼é€‰æ‹©åˆ†ç±»å™¨                                    â”‚
â”‚    â”œâ”€ LLMæ¨¡å¼: LLMClassifier.classify_batch()            â”‚
â”‚    â”‚   â”œâ”€ è°ƒç”¨Ollama/Azure LLM                            â”‚
â”‚    â”‚   â”œâ”€ è¯­ä¹‰ç†è§£åˆ†ç±» (6ç»´)                               â”‚
â”‚    â”‚   â”œâ”€ MD5ç¼“å­˜é¿å…é‡å¤è°ƒç”¨                              â”‚
â”‚    â”‚   â””â”€ é™çº§ç­–ç•¥ (å¤±è´¥ â†’ è§„åˆ™åˆ†ç±»)                       â”‚
â”‚    â”‚                                                      â”‚
â”‚    â””â”€ è§„åˆ™æ¨¡å¼: ContentClassifier.classify()             â”‚
â”‚        â”œâ”€ å…³é”®è¯åŒ¹é… (ç ”ç©¶/äº§å“/å¸‚åœº/...)                  â”‚
â”‚        â”œâ”€ AIç›¸å…³æ€§è¯„åˆ†                                     â”‚
â”‚        â””â”€ ImportanceEvaluator.calculate_importance()     â”‚
â”‚            â”œâ”€ æ¥æºæƒå¨åº¦ (25%)                             â”‚
â”‚            â”œâ”€ æ—¶æ•ˆæ€§ (25%)                                 â”‚
â”‚            â”œâ”€ ç½®ä¿¡åº¦ (20%, æœ‰ä¸Šé™)                         â”‚
â”‚            â”œâ”€ å†…å®¹ç›¸å…³åº¦ (20%)                             â”‚
â”‚            â””â”€ ç¤¾äº¤çƒ­åº¦ (10%)                               â”‚
â”‚                                                          â”‚
â”‚  è¾“å‡º: classified_data = [{åˆ†ç±»ç»“æœ, é‡è¦æ€§, ...}]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  4. è¶‹åŠ¿åˆ†æé˜¶æ®µ                          â”‚
â”‚  AIAnalyzer.analyze_trends(data)                         â”‚
â”‚    â”œâ”€ ç»Ÿè®¡åˆ†ç±»åˆ†å¸ƒ                                         â”‚
â”‚    â”œâ”€ æå–æŠ€æœ¯çƒ­ç‚¹                                         â”‚
â”‚    â”œâ”€ åˆ†ææ¯æ—¥è¶‹åŠ¿                                         â”‚
â”‚    â””â”€ è¾“å‡º: trends = {...ç»Ÿè®¡ç»“æœ...}                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  5. æ•°æ®å¯è§†åŒ–é˜¶æ®µ                        â”‚
â”‚  DataVisualizer.visualize_all(trends)                    â”‚
â”‚    â”œâ”€ ç”ŸæˆæŠ€æœ¯çƒ­ç‚¹æŸ±çŠ¶å›¾                                   â”‚
â”‚    â”œâ”€ ç”Ÿæˆåˆ†ç±»åˆ†å¸ƒé¥¼å›¾                                     â”‚
â”‚    â”œâ”€ ç”Ÿæˆæ¯æ—¥è¶‹åŠ¿æŠ˜çº¿å›¾                                   â”‚
â”‚    â”œâ”€ ç”Ÿæˆç»¼åˆä»ªè¡¨ç›˜                                       â”‚
â”‚    â””â”€ è¾“å‡º: chart_files = {PNGæ–‡ä»¶è·¯å¾„}                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  6. ç½‘é¡µå‘å¸ƒé˜¶æ®µ                          â”‚
â”‚  WebPublisher.generate_html_page(data, trends, charts)  â”‚
â”‚    â”œâ”€ è¿‡æ»¤ä½AIç›¸å…³æ€§å†…å®¹ (é˜ˆå€¼0.2)                         â”‚
â”‚    â”œâ”€ æŒ‰é‡è¦æ€§+æ—¶é—´æ’åº                                    â”‚
â”‚    â”œâ”€ ç”ŸæˆHTML (å“åº”å¼è®¾è®¡)                                â”‚
â”‚    â””â”€ è¾“å‡º: index.html                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  7. ç»“æœä¿å­˜é˜¶æ®µ                          â”‚
â”‚  ä¿å­˜æ•°æ®å’ŒæŠ¥å‘Š                                           â”‚
â”‚    â”œâ”€ data/exports/ai_tracker_data_YYYYMMDD_HHMMSS.json  â”‚
â”‚    â”œâ”€ data/exports/ai_tracker_report_YYYYMMDD_HHMMSS.txt â”‚
â”‚    â”œâ”€ visualizations/*.png                               â”‚
â”‚    â””â”€ index.html (æ ¹ç›®å½•)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 å»é‡æœºåˆ¶è¯¦è§£

**èŒè´£åˆ†ç¦»åŸåˆ™**:
- **é‡‡é›†å™¨ (DataCollector)**: è´Ÿè´£æ‰€æœ‰å»é‡å·¥ä½œ
- **åˆ†ç±»å™¨ (Classifier)**: ä»…è´Ÿè´£åˆ†ç±»ç»“æœç¼“å­˜

**å››å±‚å»é‡**:

```
æ–°URL â†’ [1] URLé¢„è¿‡æ»¤ â†’ [2] æŒ‡çº¹å»é‡ â†’ [3] è¯­ä¹‰å»é‡ â†’ [4] å†å²ç¼“å­˜ â†’ è¾“å‡º
         â†“                â†“              â†“              â†“
      è·³è¿‡å·²ç¼“å­˜      MD5å¿«é€Ÿå»é‡    Jaccardç›¸ä¼¼åº¦   æŒä¹…åŒ–ç¼“å­˜
      (é‡‡é›†å‰)       (å†…å­˜æ£€æŸ¥)      (0.8é˜ˆå€¼)    (5000æ¡ä¸Šé™)
```

**å®ç°ç»†èŠ‚**:
```python
def _is_duplicate(self, item: Dict) -> bool:
    """
    å››å±‚å»é‡æ£€æµ‹:
    1. URLé¢„è¿‡æ»¤: æ£€æŸ¥ collection_history_cache
    2. æŒ‡çº¹å»é‡: MD5(URL + æ ‡é¢˜)
    3. è¯­ä¹‰å»é‡: Jaccardç›¸ä¼¼åº¦ > 0.8
    4. å†å²ç¼“å­˜: æŒä¹…åŒ–åˆ°æ–‡ä»¶
    """
    url = item.get('link')
    title = item.get('title', '')
    
    # ç¬¬1å±‚: URLé¢„è¿‡æ»¤
    if url in self.history_cache.get('seen_urls', set()):
        return True
    
    # ç¬¬2å±‚: æŒ‡çº¹å»é‡
    fingerprint = hashlib.md5(f"{url}{title}".encode()).hexdigest()
    if fingerprint in self.seen_fingerprints:
        return True
    
    # ç¬¬3å±‚: è¯­ä¹‰å»é‡
    for seen_title in self.seen_titles:
        if self._jaccard_similarity(title, seen_title) > 0.8:
            return True
    
    # ç¬¬4å±‚: æ›´æ–°ç¼“å­˜
    self.seen_fingerprints.add(fingerprint)
    self.seen_titles.append(title)
    self.history_cache['seen_urls'].add(url)
    
    return False
```

---

## 5. æŠ€æœ¯æ ˆ

### 5.1 æ ¸å¿ƒä¾èµ–

```python
# æ•°æ®é‡‡é›†
requests>=2.31.0              # åŒæ­¥HTTPè¯·æ±‚
aiohttp>=3.9.0                # å¼‚æ­¥HTTPå®¢æˆ·ç«¯
beautifulsoup4>=4.12.0        # HTMLè§£æ
feedparser>=6.0.11            # RSSè§£æ
arxiv>=2.1.3                  # arXiv API

# æ•°æ®å¤„ç†
python-dateutil>=2.8.0        # æ—¥æœŸè§£æ
pytz>=2023.3                  # æ—¶åŒºå¤„ç†

# å¯è§†åŒ–
matplotlib>=3.7.0             # å›¾è¡¨ç”Ÿæˆ

# é…ç½®ç®¡ç†
pyyaml                        # YAMLé…ç½®è§£æ

# AIé›†æˆ (å¯é€‰)
openai>=1.6.0                 # OpenAI/Azure API
# Ollama: æœ¬åœ°éƒ¨ç½²ï¼Œæ— éœ€pipå®‰è£…
```

### 5.2 Pythonç‰ˆæœ¬è¦æ±‚

```python
Python 3.8+

# Python 3.13+ é¢å¤–ä¾èµ–
legacy-cgi>=2.6.1  # feedparseréœ€è¦ (cgiæ¨¡å—å·²ç§»é™¤)
```

### 5.3 å¤–éƒ¨æœåŠ¡

| æœåŠ¡ | ç”¨é€” | æ˜¯å¦å¿…é¡» |
|------|------|---------|
| **Ollama** | æœ¬åœ°LLMæ¨ç† | å¯é€‰ (LLMæ¨¡å¼éœ€è¦) |
| **Azure OpenAI** | äº‘ç«¯LLMæœåŠ¡ | å¯é€‰ (LLMæ¨¡å¼éœ€è¦) |
| **arXiv API** | å­¦æœ¯è®ºæ–‡é‡‡é›† | æ˜¯ |
| **GitHub API** | å¼€æºé¡¹ç›®é‡‡é›† | æ˜¯ (æ— éœ€è®¤è¯) |
| **RSS Feeds** | æ–°é—»é‡‡é›† | æ˜¯ |

---

## 6. å…³é”®è®¾è®¡æ¨¡å¼

### 6.1 ç­–ç•¥æ¨¡å¼ (Strategy Pattern)

**åº”ç”¨åœºæ™¯**: åˆ†ç±»æ¨¡å¼åˆ‡æ¢

```python
class AIWorldTracker:
    def _classify_data(self, items):
        """æ ¹æ®æ¨¡å¼é€‰æ‹©åˆ†ç±»å™¨ (ç­–ç•¥æ¨¡å¼)"""
        if self.classification_mode == 'llm':
            return self.llm_classifier.classify_batch(items)
        else:
            return [self.classifier.classify(item) for item in items]
```

**ä¼˜åŠ¿**:
- è¿è¡Œæ—¶åˆ‡æ¢åˆ†ç±»ç­–ç•¥
- æ— ç¼é™çº§ (LLM â†’ è§„åˆ™)

---

### 6.2 æ¨¡æ¿æ–¹æ³•æ¨¡å¼ (Template Method)

**åº”ç”¨åœºæ™¯**: æ•°æ®é‡‡é›†æµç¨‹

```python
class AIDataCollector:
    async def _collect_all_async(self):
        """æ¨¡æ¿æ–¹æ³•: å®šä¹‰é‡‡é›†æµç¨‹æ¡†æ¶"""
        tasks = []
        
        # 1. é‡‡é›†ç ”ç©¶è®ºæ–‡ (arXiv)
        tasks.extend([self._fetch_arxiv_async(cat) for cat in ...])
        
        # 2. é‡‡é›†RSSæ–°é—»
        tasks.extend([self._fetch_rss_feed_async(url) for url in ...])
        
        # 3. é‡‡é›†GitHubè¶‹åŠ¿
        tasks.append(self._fetch_github_trending_async())
        
        # 4. å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 5. åˆå¹¶ç»“æœ
        return self._merge_results(results)
```

---

### 6.3 å•ä¾‹æ¨¡å¼ (Singleton)

**åº”ç”¨åœºæ™¯**: æ—¥å¿—ç®¡ç†å™¨

```python
class AITrackerLogger:
    _instance: Optional['AITrackerLogger'] = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
```

**ä¼˜åŠ¿**:
- å…¨å±€å”¯ä¸€æ—¥å¿—å®ä¾‹
- ç»Ÿä¸€é…ç½®ç®¡ç†

---

### 6.4 è£…é¥°å™¨æ¨¡å¼ (Decorator)

**åº”ç”¨åœºæ™¯**: ç¼“å­˜è£…é¥°

```python
def cache_result(cache_dict):
    """ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(self, item):
            key = hashlib.md5(str(item).encode()).hexdigest()
            if key in cache_dict:
                return cache_dict[key]
            result = func(self, item)
            cache_dict[key] = result
            return result
        return wrapper
    return decorator
```

---

### 6.5 å·¥å‚æ¨¡å¼ (Factory)

**åº”ç”¨åœºæ™¯**: LLMæä¾›å•†åˆ›å»º

```python
def _create_llm_provider(provider: str, config):
    """å·¥å‚æ–¹æ³•: æ ¹æ®provideråˆ›å»ºå¯¹åº”çš„LLMå®¢æˆ·ç«¯"""
    if provider == 'ollama':
        return OllamaClient(config.ollama)
    elif provider == 'azure_openai':
        return AzureOpenAIClient(config.azure_openai)
    elif provider == 'openai':
        return OpenAIClient(config.openai)
    else:
        raise ValueError(f"Unknown provider: {provider}")
```

---

### 6.6 æ–­è·¯å™¨æ¨¡å¼ (Circuit Breaker)

**åº”ç”¨åœºæ™¯**: LLMé™çº§ç­–ç•¥

```python
class FallbackStrategy:
    def should_use_llm(self) -> bool:
        """æ–­è·¯å™¨æ£€æŸ¥"""
        if not self.circuit_breaker_open:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å…³é—­æ–­è·¯å™¨
        elapsed = time.time() - self.circuit_breaker_open_time
        if elapsed > 60:  # 60ç§’åå°è¯•æ¢å¤
            self.circuit_breaker_open = False
            return True
        
        return False
```

**ä¼˜åŠ¿**:
- é˜²æ­¢é›ªå´©æ•ˆåº”
- è‡ªåŠ¨æ¢å¤æœºåˆ¶

---

## 7. æ€§èƒ½ä¼˜åŒ–

### 7.1 å¼‚æ­¥å¹¶å‘ä¼˜åŒ–

**ä¼˜åŒ–å‰** (åŒæ­¥æ¨¡å¼):
```python
# ä¸²è¡Œé‡‡é›†ï¼Œæ¯ä¸ªè¯·æ±‚é˜»å¡
for url in rss_feeds:
    data = requests.get(url)  # é˜»å¡
    results.append(data)
# æ€»è€—æ—¶: ~147ç§’
```

**ä¼˜åŒ–å** (å¼‚æ­¥æ¨¡å¼):
```python
# å¹¶å‘é‡‡é›†ï¼Œ20+å¹¶å‘
async with aiohttp.ClientSession() as session:
    tasks = [self._fetch_rss_async(session, url) for url in rss_feeds]
    results = await asyncio.gather(*tasks, return_exceptions=True)
# æ€»è€—æ—¶: ~32ç§’ (78%åŠ é€Ÿ)
```

**æ€§èƒ½å¯¹æ¯”**:
| æŒ‡æ ‡ | åŒæ­¥æ¨¡å¼ | å¼‚æ­¥æ¨¡å¼ | æå‡ |
|------|---------|---------|------|
| é‡‡é›†æ—¶é—´ | 147s | 32s | **78%** |
| è¯·æ±‚é€Ÿç‡ | 0.14 req/s | 3.0 req/s | **21x** |
| å¹¶å‘æ•° | 6 | 20+ | **3x** |

---

### 7.2 URLé¢„è¿‡æ»¤ä¼˜åŒ–

**ä¼˜åŒ–å‰**:
```python
# å…ˆé‡‡é›†ï¼Œå†å»é‡
data = fetch_url(url)         # ç½‘ç»œè¯·æ±‚
if is_duplicate(data):        # äº‹åæ£€æŸ¥
    return None
```

**ä¼˜åŒ–å**:
```python
# å…ˆæ£€æŸ¥ç¼“å­˜ï¼Œå†é‡‡é›†
if url in history_cache:      # å†…å­˜æ£€æŸ¥ (å¾®ç§’çº§)
    return None
data = fetch_url(url)         # è·³è¿‡å·²ç¼“å­˜URL
```

**æ”¶ç›Š**:
- å‡å°‘14%+æ— æ•ˆç½‘ç»œè¯·æ±‚
- èŠ‚çœå¸¦å®½å’Œæ—¶é—´

---

### 7.3 MD5ç¼“å­˜ä¼˜åŒ–

**LLMåˆ†ç±»ç¼“å­˜**:
```python
# é¿å…é‡å¤è°ƒç”¨LLM (è€—æ—¶5-15ç§’/æ¡)
cache_key = hashlib.md5(content.encode()).hexdigest()
if cache_key in self.cache:
    return self.cache[cache_key]  # å‘½ä¸­ç¼“å­˜ (å¾®ç§’çº§)

result = self._call_llm(content)  # æœªå‘½ä¸­æ‰è°ƒç”¨
self.cache[cache_key] = result
```

**å…¸å‹åœºæ™¯**:
- 100æ¡æ–°é—»ï¼Œ70%å·²åˆ†ç±» â†’ èŠ‚çœ700ç§’

---

### 7.4 å¹¶å‘å¤„ç†ä¼˜åŒ–

**LLMå¹¶å‘åˆ†ç±»**:
```python
# æ ¹æ®GPUæ€§èƒ½è‡ªåŠ¨è°ƒæ•´å¹¶å‘æ•°
max_workers = 3 if gpu_type == 'nvidia' else 6

with ThreadPoolExecutor(max_workers=max_workers) as executor:
    futures = [executor.submit(self._classify_single, item) 
               for item in items]
    results = [f.result() for f in as_completed(futures)]
```

**æ€§èƒ½æå‡**:
- å•çº¿ç¨‹: 10æ¡/åˆ†é’Ÿ
- 6çº¿ç¨‹: 40æ¡/åˆ†é’Ÿ (4xåŠ é€Ÿ)

---

### 7.5 å†…å­˜ä¼˜åŒ–

**é™åˆ¶ç¼“å­˜å¤§å°**:
```python
# å†å²ç¼“å­˜ä¸Šé™5000æ¡
if len(self.history_cache['seen_urls']) > 5000:
    # ä¿ç•™æœ€æ–°3000æ¡
    self.history_cache['seen_urls'] = set(list(...)[-3000:])
```

**èµ„æºæ¸…ç†**:
```python
def cleanup(self):
    """æ¸…ç†èµ„æº"""
    # 1. å¸è½½LLMæ¨¡å‹ (é‡Šæ”¾æ˜¾å­˜)
    if self.llm_classifier:
        self.llm_classifier.unload_model()
    
    # 2. ä¿å­˜ç¼“å­˜åˆ°ç£ç›˜
    self._save_caches()
    
    # 3. å…³é—­HTTPä¼šè¯
    self._close_sessions()
```

---

## 8. æ‰©å±•æ€§åˆ†æ

### 8.1 æ•°æ®æºæ‰©å±•

**å½“å‰æ”¯æŒ**:
- arXiv (å­¦æœ¯è®ºæ–‡)
- GitHub (å¼€æºé¡¹ç›®)
- RSSæ–°é—» (ç§‘æŠ€åª’ä½“)
- é¢†è¢–åšå®¢

**æ‰©å±•æ–¹å¼**:
```python
# 1. åœ¨ data_collector.py æ·»åŠ æ–°æ•°æ®æº
RSS_FEEDS['new_category'] = ['url1', 'url2', ...]

# 2. å®ç°é‡‡é›†æ–¹æ³•
async def _fetch_new_source_async(self):
    """é‡‡é›†æ–°æ•°æ®æº"""
    pass

# 3. åœ¨ _collect_all_async() ä¸­è°ƒç”¨
tasks.append(self._fetch_new_source_async())
```

**æ˜“æ‰©å±•æ€§**: â­â­â­â­â­ (5/5)

---

### 8.2 åˆ†ç±»ç»´åº¦æ‰©å±•

**å½“å‰ç»´åº¦**:
ç ”ç©¶ã€äº§å“ã€å¸‚åœºã€å¼€å‘è€…ã€é¢†è¢–ã€ç¤¾åŒº (6ç±»)

**æ‰©å±•æ–¹å¼**:
```python
# 1. åœ¨ content_classifier.py æ·»åŠ æ–°å…³é”®è¯
self.new_category_keywords = {
    'keyword1': 4,
    'keyword2': 3,
    ...
}

# 2. åœ¨ _classify_content_type() æ·»åŠ åˆ†ç±»é€»è¾‘
if self._has_keywords(text, self.new_category_keywords):
    scores['new_category'] += weight
```

**æ˜“æ‰©å±•æ€§**: â­â­â­â­ (4/5)

---

### 8.3 LLMæä¾›å•†æ‰©å±•

**å½“å‰æ”¯æŒ**:
- Ollama (æœ¬åœ°)
- Azure OpenAI
- OpenAI

**æ‰©å±•æ–¹å¼**:
```python
# 1. åœ¨ llm_classifier.py æ·»åŠ æ–°æä¾›å•†
class LLMProvider(Enum):
    NEW_PROVIDER = "new_provider"

# 2. å®ç°å®¢æˆ·ç«¯ç±»
class NewProviderClient:
    def call(self, prompt):
        # å®ç°APIè°ƒç”¨
        pass

# 3. åœ¨å·¥å‚æ–¹æ³•ä¸­æ³¨å†Œ
def _create_client(provider):
    if provider == 'new_provider':
        return NewProviderClient()
```

**æ˜“æ‰©å±•æ€§**: â­â­â­â­ (4/5)

---

### 8.4 å¯è§†åŒ–å›¾è¡¨æ‰©å±•

**å½“å‰å›¾è¡¨**:
æŠ€æœ¯çƒ­ç‚¹ã€åˆ†ç±»åˆ†å¸ƒã€åŒºåŸŸåˆ†å¸ƒã€æ¯æ—¥è¶‹åŠ¿ã€ç»¼åˆä»ªè¡¨ç›˜

**æ‰©å±•æ–¹å¼**:
```python
# åœ¨ visualizer.py æ·»åŠ æ–°å›¾è¡¨æ–¹æ³•
def plot_new_chart(self, data):
    """ç”Ÿæˆæ–°å›¾è¡¨"""
    plt.figure(figsize=(10, 6))
    # ... ç»˜å›¾é€»è¾‘
    filepath = os.path.join(self.output_dir, 'new_chart.png')
    plt.savefig(filepath)
    return filepath

# åœ¨ visualize_all() ä¸­è°ƒç”¨
def visualize_all(self, trends):
    chart_files = {}
    chart_files['new_chart'] = self.plot_new_chart(trends)
    return chart_files
```

**æ˜“æ‰©å±•æ€§**: â­â­â­â­â­ (5/5)

---

### 8.5 å›½é™…åŒ–æ‰©å±•

**å½“å‰è¯­è¨€**:
- ä¸­æ–‡ (zh)
- è‹±æ–‡ (en)

**æ‰©å±•æ–¹å¼**:
```python
# 1. åœ¨ i18n.py æ·»åŠ æ–°è¯­è¨€ç¿»è¯‘
TRANSLATIONS = {
    'new_lang': {
        'key1': 'translation1',
        'key2': 'translation2',
        ...
    }
}

# 2. è°ƒç”¨ set_language('new_lang')
```

**æ˜“æ‰©å±•æ€§**: â­â­â­â­â­ (5/5)

---

## 9. æ€»ç»“ä¸å»ºè®®

### 9.1 æ¶æ„ä¼˜åŠ¿

âœ… **æ¨¡å—åŒ–è®¾è®¡**: æ¯ä¸ªæ¨¡å—èŒè´£æ¸…æ™°ï¼Œæ¾è€¦åˆ  
âœ… **é«˜æ€§èƒ½**: å¼‚æ­¥å¹¶å‘é‡‡é›†ï¼Œ78%æ€§èƒ½æå‡  
âœ… **æ™ºèƒ½åˆ†ç±»**: LLMè¯­ä¹‰ç†è§£ + è§„åˆ™åˆ†ç±»åŒæ¨¡å¼  
âœ… **çµæ´»é…ç½®**: YAMLé…ç½® + ç¯å¢ƒå˜é‡æ”¯æŒ  
âœ… **æ˜“æ‰©å±•**: è‰¯å¥½çš„æ‰©å±•ç‚¹è®¾è®¡  
âœ… **å¯è§‚æµ‹**: ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿï¼ŒåŒè¾“å‡ºæ¨¡å¼  
âœ… **èµ„æºç®¡ç†**: å®Œå–„çš„æ¸…ç†æœºåˆ¶  

---

### 9.2 å¾…ä¼˜åŒ–ç‚¹

âš ï¸ **æµ‹è¯•è¦†ç›–ç‡**: å½“å‰45%ï¼Œå»ºè®®æå‡åˆ°80%+  
âš ï¸ **APIæ–‡æ¡£**: éƒ¨åˆ†æ¨¡å—ç¼ºå°‘å®Œæ•´çš„APIæ–‡æ¡£  
âš ï¸ **å¼‚å¸¸å¤„ç†**: éƒ¨åˆ†è¾¹ç•Œæƒ…å†µå¤„ç†ä¸å¤Ÿç»†è‡´  
âš ï¸ **é…ç½®éªŒè¯**: ç¼ºå°‘é…ç½®æ–‡ä»¶schemaéªŒè¯  

---

### 9.3 å­¦ä¹ å»ºè®®

**åˆå­¦è€…** (å­¦ä¹ ä»£ç ç»“æ„):
1. å…ˆè¯» `TheWorldOfAI.py` äº†è§£ä¸»æµç¨‹
2. å†è¯» `data_collector.py` äº†è§£å¼‚æ­¥é‡‡é›†
3. æœ€åè¯» `content_classifier.py` äº†è§£åˆ†ç±»é€»è¾‘

**è¿›é˜¶è€…** (æ·±å…¥ç†è§£):
1. ç ”ç©¶ `llm_classifier.py` çš„é™çº§ç­–ç•¥
2. åˆ†æ `importance_evaluator.py` çš„è¯„åˆ†ç®—æ³•
3. ç†è§£ `async_collector` çš„å¹¶å‘æ§åˆ¶

**è´¡çŒ®è€…** (å‚ä¸å¼€å‘):
1. é˜…è¯» `docs/` ä¸‹çš„æŠ€æœ¯æ–‡æ¡£
2. æŸ¥çœ‹ `CHANGELOG.md` äº†è§£å†å²æ¼”è¿›
3. å‚è€ƒ `tests/` ä¸‹çš„æµ‹è¯•ç”¨ä¾‹

---

### 9.4 å¿«é€Ÿä¸Šæ‰‹å‘½ä»¤

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/legendyz/ai-world-tracker.git
cd ai-world-tracker

# åˆ‡æ¢åˆ°å¼€å‘åˆ†æ”¯
git checkout ai-world-tracker-v3-developing

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# (å¯é€‰) å®‰è£…Ollamaå¹¶æ‹‰å–æ¨¡å‹
ollama pull qwen3:8b

# è¿è¡Œç¨‹åº
python TheWorldOfAI.py

# æˆ–è‡ªåŠ¨æ¨¡å¼
python TheWorldOfAI.py --auto
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026-01-20  
**ç»´æŠ¤è€…**: AI World Tracker Team
